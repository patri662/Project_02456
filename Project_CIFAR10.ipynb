{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a827966b",
   "metadata": {},
   "source": [
    "# Imports\n",
    "\n",
    "NumPy will be used for almost everything, but also import a few other libraries to read the data and make visualizations.\n",
    "\n",
    "#### CIFAR-10 Dataset\n",
    "Images of size 32x32 and 3 channels because they are color images.\n",
    "\n",
    "Each row of the CVS has 3073 columns: 1 column for the label + 3072 columns for pixel values (32x32).\n",
    "\n",
    "It has 10 classes:\n",
    "- 0 = airplane\n",
    "- 1 = automobile\n",
    "- 2 = bird\n",
    "- 3 = cat\n",
    "- 4 = deer\n",
    "- 5 = dog\n",
    "- 6 = frog\n",
    "- 7 = horse\n",
    "- 8 = ship\n",
    "- 9 = truck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97768c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 50000\n",
      "Train cols: 3073\n",
      "Test rows: 10000\n",
      "Test cols: 3072\n",
      "Training set: (50000, 3072) (50000,)\n",
      "Test set: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(\"train_CIFAR.csv\")\n",
    "test_df  = pd.read_csv(\"test_CIFAR.csv\")\n",
    "\n",
    "# Check data \n",
    "print(\"Train rows:\", len(train_df))\n",
    "print(\"Train cols:\", len(train_df.columns))\n",
    "print(\"Test rows:\", len(test_df))\n",
    "print(\"Test cols:\", len(test_df.columns))\n",
    "\n",
    "# Extract labels and features\n",
    "y_train = train_df.iloc[:, -1].to_numpy()\n",
    "X_train = train_df.iloc[:, :-1].to_numpy()\n",
    "X_test  = test_df.to_numpy()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "X_test  = X_test.astype(np.float32) / 255.0\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc7cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0 1 2 3 4 5 6 7 8 9]\n",
      "Number of samples per label:\n",
      "Class 0 (airplane): 5000 samples\n",
      "Class 1 (automobile): 5000 samples\n",
      "Class 2 (bird): 5000 samples\n",
      "Class 3 (cat): 5000 samples\n",
      "Class 4 (deer): 5000 samples\n",
      "Class 5 (dog): 5000 samples\n",
      "Class 6 (frog): 5000 samples\n",
      "Class 7 (horse): 5000 samples\n",
      "Class 8 (ship): 5000 samples\n",
      "Class 9 (truck): 5000 samples\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel intensity statistics:\n",
      "  min=0.000, max=1.000\n",
      "  mean=0.473, std=0.252\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 label names\n",
    "cifar10_labels = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"\n",
    "]\n",
    "\n",
    "# dataset info\n",
    "print(\"Unique labels:\", np.unique(y_train))\n",
    "print(\"Number of samples per label:\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"Class {u} ({cifar10_labels[u]}): {c} samples\")\n",
    "\n",
    "# Plot one sample per label\n",
    "plt.figure(figsize=(12, 5))\n",
    "for label in range(10):\n",
    "    idx = np.where(y_train == label)[0][0]\n",
    "    img = X_train[idx].reshape(32, 32, 3)\n",
    "    \n",
    "    plt.subplot(2, 5, label + 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"{cifar10_labels[label]}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"One Example per Class (CIFAR-10)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Compute pixel-level statistics\n",
    "print(\"Pixel intensity statistics:\")\n",
    "print(f\"  min={X_train.min():.3f}, max={X_train.max():.3f}\")\n",
    "print(f\"  mean={X_train.mean():.3f}, std={X_train.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61aa0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (45000, 3072), (45000,)\n",
      "Validation set: (5000, 3072), (5000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Prepare Train / Validation Split\n",
    "split_ratio = 0.9\n",
    "n_total = len(X_train)\n",
    "split_idx = int(n_total * split_ratio)\n",
    "\n",
    "#  make it random\n",
    "perm = np.random.permutation(n_total)\n",
    "X_train, y_train = X_train[perm], y_train[perm]\n",
    "\n",
    "# Split\n",
    "X_val = X_train[split_idx:]\n",
    "y_val = y_train[split_idx:]\n",
    "X_train = X_train[:split_idx]\n",
    "y_train = y_train[:split_idx]\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a5b05",
   "metadata": {},
   "source": [
    "# One-Hot Encoding for Labels\n",
    "The output layer of the network consists of 10 neurons, each representing one of the ten possible numbers. To ensure consistency in dimensionality across labels in the dataset and facilitate calculations of loss and other metrics, I will one-hot encode the labels. This will generate an array of length 10 for each label, where all elements are set to 0 except for the index corresponding to the label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228d6999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label: (2, 'bird') | One-hot encoded label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (9, 'truck') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Original label: (2, 'bird') | One-hot encoded label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (0, 'airplane') | One-hot encoded label: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (2, 'bird') | One-hot encoded label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (4, 'deer') | One-hot encoded label: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Original label: (3, 'cat') | One-hot encoded label: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "--------------------------------------------------------------\n",
      "Original label: (9, 'truck') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Original label: (2, 'bird') | One-hot encoded label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (5, 'dog') | One-hot encoded label: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Original label: (4, 'deer') | One-hot encoded label: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (8, 'ship') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (4, 'deer') | One-hot encoded label: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Original label: (0, 'airplane') | One-hot encoded label: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y_train_samples = y_train[:10]\n",
    "y_val_samples = y_val[:10]\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = np.eye(num_classes)[y_train]\n",
    "y_val = np.eye(num_classes)[y_val]\n",
    "\n",
    "\n",
    "y_train_onehot_samples = y_train[:10]\n",
    "for y, y_onehot in zip(y_train_samples, y_train_onehot_samples):\n",
    "    label_name = cifar10_labels[int(y)]\n",
    "    print(f\"Original label: {y,label_name} | One-hot encoded label: {y_onehot}\")\n",
    "print('--------------------------------------------------------------')\n",
    "y_val_onehot_samples = y_val[:10]\n",
    "for y, y_onehot_val in zip(y_val_samples, y_val_onehot_samples):\n",
    "    label_name = cifar10_labels[int(y)]\n",
    "    print(f\"Original label: {y,label_name} | One-hot encoded label: {y_onehot_val}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523c1d37",
   "metadata": {},
   "source": [
    "# Creating a Dataloader\n",
    "I've implemented a generator functions that returns a batch of data. It is a highly simplified version of dataloader classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ce2f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch X shape: (64, 3072) Batch y shape: (64, 10)\n",
      "Labels in this batch: [0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_batch(X, y, batch_size):\n",
    "    n_batches = X.shape[0] // batch_size\n",
    "    for i in range(n_batches):\n",
    "        X_batch = X[i*batch_size:(i+1)*batch_size]\n",
    "        y_batch = y[i*batch_size:(i+1)*batch_size]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "# Try function\n",
    "batch_size = 64\n",
    "for Xb, yb in get_batch(X_train, y_train, batch_size):\n",
    "    print(\"Batch X shape:\", Xb.shape, \"Batch y shape:\", yb.shape)\n",
    "    print(\"Labels in this batch:\", np.unique(yb))\n",
    "    # Show the first image of this batch\n",
    "    plt.imshow(Xb[0].reshape(32, 32, 3))\n",
    "    plt.title(f\"Label: {yb[0]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    break  # remove this to loop through all batches\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4dee9e",
   "metadata": {},
   "source": [
    "Add random shufling per epoch, as we will need that to train a network with randomized batches each epoch, so digits are not seen in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4044da2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: (128, 3072) (128, 10)\n",
      "Labels in this batch: [0. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_batch(X, y, batch_size, shuffle=True):\n",
    "    idx = np.arange(X.shape[0])\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    for i in range(0, X.shape[0] - batch_size + 1, batch_size):\n",
    "        batch_idx = idx[i:i+batch_size]\n",
    "        yield X[batch_idx], y[batch_idx]\n",
    "\n",
    "# Test function -> when run multiple times, output changes (above never changes)\n",
    "batch_size = 128\n",
    "for Xb, yb in get_batch(X_train, y_train, batch_size, shuffle=True): # set shuffle to True\n",
    "    print(\"Batch:\", Xb.shape, yb.shape)\n",
    "    print(\"Labels in this batch:\", np.unique(yb))\n",
    "    # Show the first image of this batch\n",
    "    plt.imshow(Xb[0].reshape(32, 32, 3))\n",
    "    plt.title(f\"Label: {yb[0]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    break  # remove this to loop through all batches\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7247e99b",
   "metadata": {},
   "source": [
    "# Activation Functions\n",
    "Activation functions are mathematical functions applied to the output of each neuron in a neural network's hidden layers. They introduce non-linearity to the network, enabling it to learn complex patterns in data. Without activation functions, neural networks would essentially reduce to linear transformations, which limits their ability to learn complex relationships in data.\n",
    "\n",
    "I've used two different activations functions in my network architecture, Rectified Linear Unit (ReLU) and SoftMax. The former is used in the hidden layer, and the latter is applied to the output layer. \n",
    "\n",
    "ReLU sets all negative values to zero and leaves positive values unchanged. For a given input x, is defined as\n",
    "$$\n",
    "ReLU(x) = max(0,x)\n",
    "$$\n",
    "\n",
    "SoftMax is commonly used in the output layer of a neural network. It converts the raw output scores into probabilities, ensuring that the sum of the probabilities across all classes equals one. It is defined as\n",
    "$$\n",
    "p_i = \\frac{e^{z_i}}{\\sum e^{z_j}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77a825c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax output:\n",
      " [[0.63806635 0.23473149 0.0954347  0.03176745]\n",
      " [0.11035682 0.81543273 0.04958652 0.02462393]\n",
      " [0.10189196 0.08342208 0.75288537 0.06180059]]\n",
      "Row sums (should be 1): [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# ReLU\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "# ReLU derivative for backpropagation\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)\n",
    "\n",
    "# SoftMax\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Test ReLUs\n",
    "x = np.linspace(-5, 5, 100) # Input range\n",
    "\n",
    "# Apply ReLU and its derivative\n",
    "y = relu(x)\n",
    "dy = relu_derivative(x)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x, y, label='ReLU(x)')\n",
    "plt.title(\"ReLU Function\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(x, dy, color='orange', label=\"ReLU'(x)\")\n",
    "plt.title(\"ReLU Derivative\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test SoftMax\n",
    "logits = np.array([\n",
    "    [2.0, 1.0, 0.1, -1.0],\n",
    "    [1.0, 3.0, 0.2, -0.5],\n",
    "    [0.5, 0.3, 2.5, 0.0]\n",
    "]) # Input logits for 3 samples  4 classes\n",
    "\n",
    "probs = softmax(logits)\n",
    "print(\"Softmax output:\\n\", probs)\n",
    "print(\"Row sums (should be 1):\", np.sum(probs, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa0c2e",
   "metadata": {},
   "source": [
    "# Forward Pass\n",
    "\n",
    "This image explains the mathematical operations involved in forward and backward pass.\n",
    "\n",
    "![Forward_Backward_Pass.png](attachment:Forward_Backward_Pass.png)\n",
    "\n",
    "##### Input and Hidden Layer\n",
    "\n",
    "Starting from the bottom, we have the input values, so the flattened input images denoted as $x=a^0$. \n",
    "\\\n",
    "We also have the weights that connect the input layer to the first and only hidden layer $w^1$, as well as the bias of the hidden layer $b^1$. Then, we calculate the first weighted sum $z^1$ as\n",
    "$$\n",
    "a^0 = x\n",
    "$$\n",
    "$$\n",
    "z^1 = w^1*a^0 + b^1\n",
    "$$ \n",
    "The weighted sum is passed through an activation function\n",
    "$$\n",
    "a^1 = f(z^1) = ReLU(z^1)\n",
    "$$\n",
    "\n",
    "##### Hidden and Output Layer\n",
    "\n",
    "The output from the activation function of the hidden layer is used as input for the next layer and it repeats as many times as layers in the network.\n",
    "$$\n",
    "z^2 = w^2a^1+b^2\n",
    "$$\n",
    "$$\n",
    "a^2 = SoftMax(z^2)\n",
    "$$\n",
    "The output layer is special, as the SoftMax function is applied. Therefore, the output of this activation function $a^2$ is the prediction of the network, usually denoted as $\\hat{y}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131a0e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 shape: (5, 128)\n",
      "a1 shape: (5, 128)\n",
      "z2 shape: (5, 10)\n",
      "a2 shape: (5, 10)\n",
      "Row sums of a2 (should be 1): [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# For 2 layers network\n",
    "def forward(X, W1, b1, W2, b2):\n",
    "    z1 = X @ W1 + b1\n",
    "    a1 = relu(z1)\n",
    "    z2 = a1 @ W2 + b2\n",
    "    a2 = softmax(z2)\n",
    "    return z1, a1, z2, a2\n",
    "\n",
    "# Test forward pass\n",
    "X_sample = np.random.rand(5, 784)  # 5 samples, 784 features\n",
    "\n",
    "# Layer sizes\n",
    "input_size = 784\n",
    "hidden_size = 128\n",
    "output_size = 10\n",
    "\n",
    "# initial weights & biases\n",
    "W1 = np.random.randn(input_size, hidden_size) * 0.01\n",
    "b1 = np.zeros((1, hidden_size))\n",
    "W2 = np.random.randn(hidden_size, output_size) * 0.01\n",
    "b2 = np.zeros((1, output_size))\n",
    "\n",
    "# Forward pass\n",
    "z1, a1, z2, a2 = forward(X_sample, W1, b1, W2, b2)\n",
    "\n",
    "print(\"z1 shape:\", z1.shape)\n",
    "print(\"a1 shape:\", a1.shape)\n",
    "print(\"z2 shape:\", z2.shape)\n",
    "print(\"a2 shape:\", a2.shape)\n",
    "print(\"Row sums of a2 (should be 1):\", np.sum(a2, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026757b3",
   "metadata": {},
   "source": [
    "But now, we want to make it flexible, so the user can choose the number of hidden layers, as well as the number of hiden units per layer by setting that up in a list.\n",
    "\n",
    "Then, weights and biases will be stored in lists to loop them dynamically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0e9073f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: z.shape=(5, 128), a.shape=(5, 128)\n",
      "Layer 2: z.shape=(5, 82), a.shape=(5, 82)\n",
      "Layer 3: z.shape=(5, 64), a.shape=(5, 64)\n",
      "Layer 4: z.shape=(5, 10), a.shape=(5, 10)\n"
     ]
    }
   ],
   "source": [
    "# Loop over the sizes of the network that are send in a list\n",
    "def init_network(layer_sizes):\n",
    "    \"\"\"\n",
    "    layer_sizes: list of layer sizes that form network including input and output.\n",
    "    Example: [784, 128, 64, 10] = input -> 128 -> 64 -> output\n",
    "    With this list, the user is defining both: \n",
    "    - number of hidden layers (lenght of list)\n",
    "    - number of hidden units (numbers in list)\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        W = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2. / layer_sizes[i])\n",
    "        b = np.zeros((1, layer_sizes[i+1]))\n",
    "        params.append((W, b))\n",
    "    return params\n",
    "\n",
    "# Forward pass\n",
    "def forward_flexible(X, params):\n",
    "    \"\"\"\n",
    "    params: list of (W, b) tuples for each layer\n",
    "    Returns: (activations, pre_activations)\n",
    "    \"\"\"\n",
    "    activations = [X]\n",
    "    pre_activations = []\n",
    "    \n",
    "    for i, (W, b) in enumerate(params):\n",
    "        z = activations[-1] @ W + b\n",
    "        pre_activations.append(z)\n",
    "        \n",
    "        # Apply ReLU for hidden layers, Softmax for last\n",
    "        if i < len(params) - 1:\n",
    "            a = relu(z)\n",
    "        else:\n",
    "            a = softmax(z)\n",
    "        activations.append(a)\n",
    "        \n",
    "    return pre_activations, activations\n",
    "\n",
    "\n",
    "# Test it\n",
    "# Architecture: input  128  64  output(10)\n",
    "layer_sizes = [784, 128, 82, 64, 10]\n",
    "params = init_network(layer_sizes)\n",
    "\n",
    "# Forward pass\n",
    "X_sample = np.random.rand(5, 784)\n",
    "pre_acts, acts = forward_flexible(X_sample, params)\n",
    "\n",
    "for i, (z, a) in enumerate(zip(pre_acts, acts[1:])):\n",
    "    print(f\"Layer {i+1}: z.shape={z.shape}, a.shape={a.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5100f32",
   "metadata": {},
   "source": [
    "# Optimizers\n",
    "Implement SGD, Adam and Momentum Optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89727b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_optimizer_states(params, optimizer='sgd'):\n",
    "    \"\"\"Initialize optimizer-specific states.\"\"\"\n",
    "    if optimizer == 'momentum':\n",
    "        v = [ (np.zeros_like(W), np.zeros_like(b)) for W, b in params ]\n",
    "        return {'v': v}\n",
    "    elif optimizer == 'adam':\n",
    "        m = [ (np.zeros_like(W), np.zeros_like(b)) for W, b in params ]\n",
    "        v = [ (np.zeros_like(W), np.zeros_like(b)) for W, b in params ]\n",
    "        return {'m': m, 'v': v, 't': 0}\n",
    "    else:\n",
    "        return {}  # SGD has no state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb28d7",
   "metadata": {},
   "source": [
    "# Update Parameters\n",
    "To update the parameters, i.e. the weights and biases, we first need to define a learning rate $\\alpha$. \n",
    "\\\n",
    "The learning rate is a hyperparameter that determines the step size at which the model's parameters are updated during the training process. We'll use the optimization algorithms gradient descent to minimize the loss function. The learning rate controls the size of the steps taken in the direction opposite to the gradient of the loss function. Defined as\n",
    "$$\n",
    "\\theta_{new} = \\theta_{old} - \\alpha*C\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e139fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 2 layers network\n",
    "\n",
    "def update_parameters(W1, b1, W2, b2, dW1, db1, dW2, db2, learning_rate):\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n",
    "    return W1, b1, W2, b2\n",
    "\n",
    "\n",
    "# Flexible network\n",
    "def update_parameters_flexible(params, grads, learning_rate, optimizer='sgd', opt_state=None, beta1=0.9, beta2=0.999, eps=1e-8, momentum=0.9):\n",
    "    \"\"\"Update parameters according to selected optimizer.\"\"\"\n",
    "    new_params = []\n",
    "\n",
    "    if optimizer == 'sgd':\n",
    "        for (W, b), (dW, db) in zip(params, grads):\n",
    "            W -= learning_rate * dW\n",
    "            b -= learning_rate * db\n",
    "            new_params.append((W, b))\n",
    "\n",
    "    elif optimizer == 'momentum':\n",
    "        for i, ((W, b), (dW, db)) in enumerate(zip(params, grads)):\n",
    "            vW, vb = opt_state['v'][i]\n",
    "            vW = momentum * vW - learning_rate * dW\n",
    "            vb = momentum * vb - learning_rate * db\n",
    "            W += vW\n",
    "            b += vb\n",
    "            new_params.append((W, b))\n",
    "            opt_state['v'][i] = (vW, vb)\n",
    "\n",
    "    elif optimizer == 'adam':\n",
    "        opt_state['t'] += 1\n",
    "        t = opt_state['t']\n",
    "\n",
    "        for i, ((W, b), (dW, db)) in enumerate(zip(params, grads)):\n",
    "            mW, mb = opt_state['m'][i]\n",
    "            vW, vb = opt_state['v'][i]\n",
    "\n",
    "            # Update biased first moment estimate\n",
    "            mW = beta1 * mW + (1 - beta1) * dW\n",
    "            mb = beta1 * mb + (1 - beta1) * db\n",
    "            # Update biased second raw moment estimate\n",
    "            vW = beta2 * vW + (1 - beta2) * (dW ** 2)\n",
    "            vb = beta2 * vb + (1 - beta2) * (db ** 2)\n",
    "            # Bias correction\n",
    "            mW_hat = mW / (1 - beta1 ** t)\n",
    "            mb_hat = mb / (1 - beta1 ** t)\n",
    "            vW_hat = vW / (1 - beta2 ** t)\n",
    "            vb_hat = vb / (1 - beta2 ** t)\n",
    "            # Update parameters\n",
    "            W -= learning_rate * mW_hat / (np.sqrt(vW_hat) + eps)\n",
    "            b -= learning_rate * mb_hat / (np.sqrt(vb_hat) + eps)\n",
    "\n",
    "            opt_state['m'][i] = (mW, mb)\n",
    "            opt_state['v'][i] = (vW, vb)\n",
    "            new_params.append((W, b))\n",
    "\n",
    "    return new_params, opt_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583b5d79",
   "metadata": {},
   "source": [
    "# Weight Initialization\n",
    "While it's possible to start training with random weights and biases, it is generally a good idea to use a better method to set the initial parameter values as it leads to faster convergence.\n",
    "\n",
    "Different types can be implemented: \\\n",
    "    - He Initialization: better for ReLU activations\n",
    "    $$\n",
    "    std = \\sqrt{2/n_{in}}\n",
    "    $$\n",
    "    - Xavier Initialization: better for tanh/sigmoid activations\n",
    "    $$\n",
    "    std = \\sqrt{1/n_{in}}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b14d1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W shape (784, 128), b shape (1, 128)\n",
      "Layer 2: W shape (128, 64), b shape (1, 64)\n",
      "Layer 3: W shape (64, 10), b shape (1, 10)\n",
      "------------------------------------\n",
      "Layer 1: W shape (784, 128), b shape (1, 128)\n",
      "Layer 2: W shape (128, 64), b shape (1, 64)\n",
      "Layer 3: W shape (64, 10), b shape (1, 10)\n"
     ]
    }
   ],
   "source": [
    "# for a flexible network and lets chose between the 2 methods\n",
    "def init_weights_flexible(layer_sizes, method='he'):\n",
    "    \"\"\"\n",
    "    layer_sizes: list of layer sizes, e.g. [784, 128, 64, 10]\n",
    "    method: 'he' or 'xavier'\n",
    "    \n",
    "    Returns:\n",
    "        params: list of (W, b) pairs\n",
    "    \"\"\"\n",
    "    params = []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        in_dim = layer_sizes[i]\n",
    "        out_dim = layer_sizes[i + 1]\n",
    "\n",
    "        if method.lower() == 'he':\n",
    "            scale = np.sqrt(2. / in_dim)\n",
    "        elif method.lower() == 'xavier':\n",
    "            scale = np.sqrt(1. / in_dim)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown initialization method. Use 'he' or 'xavier'.\")\n",
    "\n",
    "        W = np.random.randn(in_dim, out_dim) * scale\n",
    "        b = np.zeros((1, out_dim))\n",
    "        params.append((W, b))\n",
    "\n",
    "    return params\n",
    "\n",
    "# Test it\n",
    "# He initialization\n",
    "params_he = init_weights_flexible([784, 128, 64, 10], method='he')\n",
    "\n",
    "# Xavier initialization\n",
    "params_xavier = init_weights_flexible([784, 128, 64, 10], method='xavier')\n",
    "\n",
    "# Check layer shapes\n",
    "for i, (W, b) in enumerate(params_he):\n",
    "    print(f\"Layer {i+1}: W shape {W.shape}, b shape {b.shape}\")\n",
    "\n",
    "print('------------------------------------')\n",
    "\n",
    "# Check layer shapes\n",
    "for i, (W, b) in enumerate(params_xavier):\n",
    "    print(f\"Layer {i+1}: W shape {W.shape}, b shape {b.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480005d",
   "metadata": {},
   "source": [
    "# Loss functions\n",
    "\n",
    "In the previous section, we calculated the output $a^2 = \\hat{y}$. This value alongside the ground truth label $y$ is run through a loss function. \n",
    "\\\n",
    "Ideally, at each iteration the value of the loss function should decrease, indicating the model's improving ability to learn. There are multiple options to use.\n",
    "\n",
    "\\\n",
    "The Mean Squared Error function (MSE) is defined as\n",
    "$$\n",
    "Loss = \\frac{1}{2}(a_k-y_k)^2\n",
    "$$\n",
    "\n",
    "The Cross Entropy Loss defines as\n",
    "$$\n",
    "Loss = -\\sum y_k log(a_k)\n",
    "$$\n",
    "\n",
    "We will also get the gradients of the loss functions needed for backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7b43fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3777215373227323\n",
      "dA shape: (4, 10)\n"
     ]
    }
   ],
   "source": [
    "# Loss Functions \n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\"Mean Squared Error (for regression or optional classification).\"\"\"\n",
    "    loss = np.mean(np.sum((y_true - y_pred) ** 2, axis=1) / 2.0)\n",
    "    dA = (y_pred - y_true) / y_true.shape[0]\n",
    "    return loss, dA\n",
    "\n",
    "def cross_entropy_loss(y_true, y_pred, eps=1e-12):\n",
    "    \"\"\"Categorical Cross-Entropy (for one-hot labels).\"\"\"\n",
    "    y_pred_clipped = np.clip(y_pred, eps, 1 - eps)\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=1))\n",
    "    dA = (y_pred - y_true) / y_true.shape[0]\n",
    "    return loss, dA\n",
    "\n",
    "\n",
    "# Test it\n",
    "y_true = np.eye(10)[np.array([3, 1, 4, 0])]   # one-hot labels\n",
    "y_pred = np.random.rand(4, 10)\n",
    "y_pred = np.exp(y_pred) / np.sum(np.exp(y_pred), axis=1, keepdims=True)  # softmax normalize\n",
    "\n",
    "\n",
    "# Compute loss and gradient\n",
    "loss, dA = cross_entropy_loss(y_true, y_pred)\n",
    "print(\"Loss:\", loss)\n",
    "print(\"dA shape:\", dA.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68357568",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "\n",
    "Add dropout for some training loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a570d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout \n",
    "def apply_dropout(a, dropout_rate):\n",
    "    if dropout_rate <= 0: return a, np.ones_like(a)\n",
    "    mask = (np.random.rand(*a.shape) > dropout_rate).astype(np.float32)\n",
    "    return a * mask / (1 - dropout_rate), mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf92d3e",
   "metadata": {},
   "source": [
    "# Accuracy Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48f53f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(np.argmax(y_true, axis=1) == np.argmax(y_pred, axis=1))\n",
    "\n",
    "# Test it\n",
    "acc = accuracy(y_true, y_pred)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b836a7d4",
   "metadata": {},
   "source": [
    "# Backward Pass\n",
    "\n",
    "To calculate the changes that we need to make to the network parameters, we need to calculate the gradients of the network.  This is called backpropagation.\n",
    "\n",
    "But we want to make it flexible, so the user can choose the number of hidden layers, as well as the number of hiden units per layer by setting that up in a list.\n",
    "\n",
    "Then, weights and biases will be stored in lists to loop them dynamically.\n",
    "\n",
    "The pass gets the dA from the Loss Function as a parameter of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74e5b572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1: W (784, 128), dW (784, 128), b (1, 128), db (1, 128)\n",
      "Layer 2: W (128, 64), dW (128, 64), b (1, 64), db (1, 64)\n",
      "Layer 3: W (64, 10), dW (64, 10), b (1, 10), db (1, 10)\n"
     ]
    }
   ],
   "source": [
    "def backward_flexible(X, y, params, pre_acts, acts, dA_last=None):\n",
    "    \"\"\"\n",
    "    Compute backward pass for arbitrary number of layers.\n",
    "    X: input data (batch)\n",
    "    y: one-hot encoded labels\n",
    "    params: list of (W, b) pairs\n",
    "    pre_acts: list of z values from forward pass\n",
    "    acts: list of activations (len = len(params)+1)\n",
    "    Returns: list of (dW, db) pairs\n",
    "    \"\"\"\n",
    "    grads = [None] * len(params)\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # --- Output layer gradient -> dA from loss functions ---\n",
    "    delta = dA_last if dA_last is not None else (acts[-1] - y)\n",
    "    grads[-1] = (\n",
    "        acts[-2].T @ delta / m,\n",
    "        np.sum(delta, axis=0, keepdims=True) / m\n",
    "    )\n",
    "    \n",
    "    # --- Backprop through hidden layers ---\n",
    "    for l in reversed(range(len(params) - 1)):\n",
    "        W_next, _ = params[l + 1]\n",
    "        z = pre_acts[l]\n",
    "        delta = (delta @ W_next.T) * relu_derivative(z)\n",
    "        dW = acts[l].T @ delta / m\n",
    "        db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "        grads[l] = (dW, db)\n",
    "    \n",
    "    return grads\n",
    "\n",
    "# Try it\n",
    "layer_sizes = [784, 128, 64, 10]\n",
    "params = init_network(layer_sizes)\n",
    "\n",
    "# forward\n",
    "X_sample = np.random.rand(5, 784)\n",
    "y_sample = np.eye(10)[np.random.randint(0, 10, size=5)]  # one-hot labels\n",
    "pre_acts, acts = forward_flexible(X_sample, params)\n",
    "\n",
    "# backward\n",
    "grads = backward_flexible(X_sample, y_sample, params, pre_acts, acts)\n",
    "\n",
    "# dimensions\n",
    "for i, ((W, b), (dW, db)) in enumerate(zip(params, grads)):\n",
    "    print(f\"Layer {i+1}: W {W.shape}, dW {dW.shape}, b {b.shape}, db {db.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8762708d",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "A simple training loop that executes the previous function for forward and backward pass. Additionally, I have previously defined a function to get batches of data for training. I will use mini-batch gradient descent to update the weights and biases for each batch.\n",
    "\n",
    "Furthermore, I have created a dictionary to collect accuracies and losses at each step. This will enable us to monitor the model's learning progress throughout training, and I will visualize the results at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aed8a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    X_train, y_train,\n",
    "    X_val=None, y_val=None,\n",
    "    layer_sizes=[784, 128, 64, 10],\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    learning_rate=0.01,\n",
    "    init_method='he',\n",
    "    loss_name='cross_entropy',\n",
    "    optimizer='sgd',        \n",
    "    momentum=0.9           \n",
    "):\n",
    "    # Initialize weights\n",
    "    params = init_weights_flexible(layer_sizes, method=init_method)\n",
    "    loss_fn = get_loss_function(loss_name)\n",
    "    opt_state = init_optimizer_states(params, optimizer)\n",
    "\n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "\n",
    "    n_samples = X_train.shape[0]\n",
    "    n_batches = n_samples // batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        perm = np.random.permutation(n_samples)\n",
    "        X_train = X_train[perm]\n",
    "        y_train = y_train[perm]\n",
    "\n",
    "        epoch_loss, epoch_acc = 0, 0\n",
    "\n",
    "        for i in tqdm(range(n_batches), desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            start, end = i * batch_size, (i + 1) * batch_size\n",
    "            X_batch, y_batch = X_train[start:end], y_train[start:end]\n",
    "\n",
    "            # Forward\n",
    "            pre_acts, acts = forward_flexible(X_batch, params)\n",
    "            y_pred = acts[-1]\n",
    "\n",
    "            # Loss and accuracy\n",
    "            loss, dA = loss_fn(y_batch, y_pred)\n",
    "            acc = accuracy(y_batch, y_pred)\n",
    "\n",
    "            # Backward\n",
    "            grads = backward_flexible(X_batch, y_batch, params, pre_acts, acts, dA_last=dA)\n",
    "\n",
    "            # Update parameters\n",
    "            params, opt_state = update_parameters_flexible(\n",
    "                params, grads, learning_rate,\n",
    "                optimizer=optimizer, opt_state=opt_state, momentum=momentum\n",
    "            )\n",
    "\n",
    "            epoch_loss += loss\n",
    "            epoch_acc += acc\n",
    "\n",
    "        # Epoch metrics\n",
    "        avg_loss = epoch_loss / n_batches\n",
    "        avg_acc = epoch_acc / n_batches\n",
    "        history['train_loss'].append(avg_loss)\n",
    "        history['train_acc'].append(avg_acc)\n",
    "\n",
    "\n",
    "        # Validation\n",
    "        if X_val is not None and y_val is not None:\n",
    "            _, val_acts = forward_flexible(X_val, params)\n",
    "            y_val_pred = val_acts[-1]\n",
    "            val_loss, _ = loss_fn(y_val, y_val_pred)\n",
    "            val_acc = accuracy(y_val, y_val_pred)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            print(f\"Epoch {epoch+1}: loss={avg_loss:.4f}, acc={avg_acc:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}: loss={avg_loss:.4f}, acc={avg_acc:.4f}\")\n",
    "\n",
    "\n",
    "        # WandB Metrics for each epoch\n",
    "        wandb.log({\n",
    "        \"train_loss\": avg_loss,\n",
    "        \"train_acc\": avg_acc,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"epoch\": epoch + 1\n",
    "        })\n",
    "\n",
    "    return params, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb986f",
   "metadata": {},
   "source": [
    "# Plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0662de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot loss and accuracy curves for training and validation\"\"\"\n",
    "    epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # ---- LOSS ----\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], label='Train Loss', marker='o')\n",
    "    if history['val_loss']:\n",
    "        plt.plot(epochs, history['val_loss'], label='Val Loss', marker='x')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # ---- ACCURACY ----\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history['train_acc'], label='Train Accuracy', marker='o')\n",
    "    if history['val_acc']:\n",
    "        plt.plot(epochs, history['val_acc'], label='Val Accuracy', marker='x')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950d3d18",
   "metadata": {},
   "source": [
    "# WandB with CIFAR10 Dataset\n",
    "\n",
    "Track sweeps with CIFAR10 to have different runs using different configurations of hyperparameters.\n",
    "All steps from above are joined and implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e7c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train rows: 50000\n",
      "Train cols: 3073\n",
      "Test rows: 10000\n",
      "Test cols: 3072\n",
      "Training set: (50000, 3072) (50000,)\n",
      "Test set: (10000, 3072)\n",
      "Train set: (45000, 3072), (45000,)\n",
      "Validation set: (5000, 3072), (5000,)\n",
      "Original label: (4, 'deer') | One-hot encoded label: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "Original label: (8, 'ship') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Original label: (0, 'airplane') | One-hot encoded label: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (6, 'frog') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Original label: (1, 'automobile') | One-hot encoded label: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (2, 'bird') | One-hot encoded label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (5, 'dog') | One-hot encoded label: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "Original label: (5, 'dog') | One-hot encoded label: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "--------------------------------------------------------------\n",
      "Original label: (8, 'ship') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Original label: (2, 'bird') | One-hot encoded label: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (3, 'cat') | One-hot encoded label: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (6, 'frog') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      "Original label: (8, 'ship') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      "Original label: (9, 'truck') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "Original label: (3, 'cat') | One-hot encoded label: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (7, 'horse') | One-hot encoded label: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      "Original label: (4, 'deer') | One-hot encoded label: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# Load CSVs\n",
    "train_df = pd.read_csv(\"train_CIFAR.csv\")\n",
    "test_df  = pd.read_csv(\"test_CIFAR.csv\")\n",
    "\n",
    "# Check data \n",
    "print(\"Train rows:\", len(train_df))\n",
    "print(\"Train cols:\", len(train_df.columns))\n",
    "print(\"Test rows:\", len(test_df))\n",
    "print(\"Test cols:\", len(test_df.columns))\n",
    "\n",
    "# Extract labels and features\n",
    "y_train = train_df.iloc[:, -1].to_numpy()\n",
    "X_train = train_df.iloc[:, :-1].to_numpy()\n",
    "X_test  = test_df.to_numpy()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "X_train = X_train.astype(np.float32) / 255.0\n",
    "X_test  = X_test.astype(np.float32) / 255.0\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set:\", X_test.shape)\n",
    "\n",
    "# Prepare Train / Validation Split\n",
    "split_ratio = 0.9\n",
    "n_total = len(X_train)\n",
    "split_idx = int(n_total * split_ratio)\n",
    "\n",
    "# Shuffle\n",
    "perm = np.random.permutation(n_total)\n",
    "X_train, y_train = X_train[perm], y_train[perm]\n",
    "\n",
    "# Split\n",
    "X_val = X_train[split_idx:]\n",
    "y_val = y_train[split_idx:]\n",
    "X_train = X_train[:split_idx]\n",
    "y_train = y_train[:split_idx]\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "\n",
    "y_train_samples = y_train[:10]\n",
    "y_val_samples = y_val[:10]\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "y_train = np.eye(num_classes)[y_train]\n",
    "y_val = np.eye(num_classes)[y_val]\n",
    "\n",
    "cifar10_labels = [\n",
    "    \"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "    \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "y_train_onehot_samples = y_train[:10]\n",
    "for y, y_onehot in zip(y_train_samples, y_train_onehot_samples):\n",
    "    label_name = cifar10_labels[int(y)]\n",
    "    print(f\"Original label: {y,label_name} | One-hot encoded label: {y_onehot}\")\n",
    "print('--------------------------------------------------------------')\n",
    "y_val_onehot_samples = y_val[:10]\n",
    "for y, y_onehot_val in zip(y_val_samples, y_val_onehot_samples):\n",
    "    label_name = cifar10_labels[int(y)]\n",
    "    print(f\"Original label: {y,label_name} | One-hot encoded label: {y_onehot_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b5f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: wupcovnp\n",
      "Sweep URL: https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: abh643z9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06376056209599626\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33ms243323\u001b[0m (\u001b[33ms243323-danmarks-tekniske-universitet-dtu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_170035-abh643z9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/abh643z9' target=\"_blank\">desert-sweep-1</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/abh643z9' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/abh643z9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=3.6123, train_acc=0.1027, val_loss=3.3894, val_acc=0.0982\n",
      "Epoch 2: train_loss=3.1074, train_acc=0.0989, val_loss=2.5031, val_acc=0.1028\n",
      "Epoch 3: train_loss=2.5500, train_acc=0.1001, val_loss=3.1360, val_acc=0.0990\n",
      "Epoch 4: train_loss=2.5975, train_acc=0.0990, val_loss=3.0963, val_acc=0.0990\n",
      "Epoch 5: train_loss=2.7871, train_acc=0.1012, val_loss=2.7127, val_acc=0.1028\n",
      "Epoch 6: train_loss=2.6486, train_acc=0.0996, val_loss=3.8606, val_acc=0.0990\n",
      "Epoch 7: train_loss=2.6696, train_acc=0.1005, val_loss=2.7064, val_acc=0.0980\n",
      "Epoch 8: train_loss=2.7182, train_acc=0.0997, val_loss=4.6796, val_acc=0.1066\n",
      "Epoch 9: train_loss=4.2595, train_acc=0.1013, val_loss=2.5377, val_acc=0.0980\n",
      "Epoch 10: train_loss=2.5680, train_acc=0.1005, val_loss=2.8694, val_acc=0.1000\n",
      "Epoch 11: train_loss=2.5924, train_acc=0.1011, val_loss=2.5668, val_acc=0.1000\n",
      "Epoch 12: train_loss=2.6581, train_acc=0.1022, val_loss=2.6956, val_acc=0.1028\n",
      "Epoch 13: train_loss=2.6532, train_acc=0.1002, val_loss=2.7446, val_acc=0.0998\n",
      "Epoch 14: train_loss=2.6846, train_acc=0.0997, val_loss=2.8220, val_acc=0.0984\n",
      "Epoch 15: train_loss=2.6485, train_acc=0.1007, val_loss=3.0436, val_acc=0.1028\n",
      "Epoch 16: train_loss=2.6617, train_acc=0.0987, val_loss=2.4377, val_acc=0.0980\n",
      "Epoch 17: train_loss=2.6781, train_acc=0.0992, val_loss=2.3873, val_acc=0.0990\n",
      "Epoch 18: train_loss=2.6845, train_acc=0.0994, val_loss=2.5325, val_acc=0.0984\n",
      "Epoch 19: train_loss=2.6106, train_acc=0.1015, val_loss=3.3874, val_acc=0.1066\n",
      "Epoch 20: train_loss=2.6538, train_acc=0.0984, val_loss=2.6227, val_acc=0.0998\n",
      "Epoch 21: train_loss=2.6385, train_acc=0.1015, val_loss=2.8438, val_acc=0.1028\n",
      "Epoch 22: train_loss=2.7008, train_acc=0.0990, val_loss=2.4948, val_acc=0.0998\n",
      "Epoch 23: train_loss=2.6623, train_acc=0.1006, val_loss=2.8258, val_acc=0.0990\n",
      "Epoch 24: train_loss=2.6480, train_acc=0.0993, val_loss=2.6993, val_acc=0.1066\n",
      "Epoch 25: train_loss=2.7328, train_acc=0.1024, val_loss=2.9854, val_acc=0.0980\n",
      "Epoch 26: train_loss=2.6154, train_acc=0.0998, val_loss=2.4807, val_acc=0.1028\n",
      "Epoch 27: train_loss=2.7099, train_acc=0.1009, val_loss=2.7160, val_acc=0.0990\n",
      "Epoch 28: train_loss=2.6777, train_acc=0.1012, val_loss=2.7567, val_acc=0.0974\n",
      "Epoch 29: train_loss=2.6610, train_acc=0.1016, val_loss=2.6046, val_acc=0.0980\n",
      "Epoch 30: train_loss=2.6616, train_acc=0.1011, val_loss=3.0031, val_acc=0.1000\n",
      "Epoch 31: train_loss=2.6714, train_acc=0.0984, val_loss=2.9655, val_acc=0.1000\n",
      "Epoch 32: train_loss=2.6449, train_acc=0.1003, val_loss=2.5475, val_acc=0.0990\n",
      "Epoch 33: train_loss=2.6512, train_acc=0.1022, val_loss=2.7948, val_acc=0.1000\n",
      "Epoch 34: train_loss=2.6976, train_acc=0.1004, val_loss=2.7832, val_acc=0.0974\n",
      "Epoch 35: train_loss=2.6688, train_acc=0.0996, val_loss=2.6943, val_acc=0.0974\n",
      "Epoch 36: train_loss=2.6461, train_acc=0.1023, val_loss=2.8771, val_acc=0.0984\n",
      "Epoch 37: train_loss=2.6896, train_acc=0.1012, val_loss=2.5658, val_acc=0.0980\n",
      "Epoch 38: train_loss=2.6842, train_acc=0.1007, val_loss=2.6454, val_acc=0.1028\n",
      "Epoch 39: train_loss=2.6594, train_acc=0.1007, val_loss=3.2320, val_acc=0.0974\n",
      "Epoch 40: train_loss=2.7141, train_acc=0.0975, val_loss=2.7383, val_acc=0.0974\n",
      "Epoch 41: train_loss=2.7097, train_acc=0.0981, val_loss=2.5511, val_acc=0.0990\n",
      "Epoch 42: train_loss=2.6355, train_acc=0.1019, val_loss=2.6462, val_acc=0.0980\n",
      "Epoch 43: train_loss=2.6723, train_acc=0.0990, val_loss=2.9067, val_acc=0.0990\n",
      "Epoch 44: train_loss=2.6720, train_acc=0.1015, val_loss=3.0207, val_acc=0.0974\n",
      "Epoch 45: train_loss=2.6593, train_acc=0.1000, val_loss=2.8071, val_acc=0.0974\n",
      "Epoch 46: train_loss=2.7117, train_acc=0.1013, val_loss=3.4478, val_acc=0.1028\n",
      "Epoch 47: train_loss=2.6881, train_acc=0.1003, val_loss=2.7937, val_acc=0.1028\n",
      "Epoch 48: train_loss=2.6437, train_acc=0.0995, val_loss=2.6639, val_acc=0.1066\n",
      "Epoch 49: train_loss=2.6635, train_acc=0.1003, val_loss=2.6698, val_acc=0.1066\n",
      "Epoch 50: train_loss=2.6719, train_acc=0.1004, val_loss=3.2685, val_acc=0.0974\n",
      "Epoch 51: train_loss=2.6434, train_acc=0.1008, val_loss=3.7095, val_acc=0.1028\n",
      "Epoch 52: train_loss=2.7473, train_acc=0.1010, val_loss=2.9988, val_acc=0.1028\n",
      "Epoch 53: train_loss=2.6844, train_acc=0.1005, val_loss=2.9180, val_acc=0.0990\n",
      "Epoch 54: train_loss=2.6327, train_acc=0.1004, val_loss=2.8750, val_acc=0.1066\n",
      "Epoch 55: train_loss=2.6688, train_acc=0.1012, val_loss=2.6640, val_acc=0.0980\n",
      "Epoch 56: train_loss=2.7022, train_acc=0.1018, val_loss=2.7023, val_acc=0.0980\n",
      "Epoch 57: train_loss=2.6804, train_acc=0.0983, val_loss=2.5975, val_acc=0.0984\n",
      "Epoch 58: train_loss=2.6611, train_acc=0.1025, val_loss=2.5417, val_acc=0.0990\n",
      "Epoch 59: train_loss=2.6539, train_acc=0.1002, val_loss=2.6058, val_acc=0.1000\n",
      "Epoch 60: train_loss=2.6788, train_acc=0.0998, val_loss=2.7529, val_acc=0.0980\n",
      "Epoch 61: train_loss=2.7057, train_acc=0.1001, val_loss=2.6588, val_acc=0.1000\n",
      "Epoch 62: train_loss=2.6814, train_acc=0.1017, val_loss=3.0701, val_acc=0.0990\n",
      "Epoch 63: train_loss=2.7205, train_acc=0.0993, val_loss=2.8524, val_acc=0.0980\n",
      "Epoch 64: train_loss=2.6823, train_acc=0.1027, val_loss=2.5390, val_acc=0.1000\n",
      "Epoch 65: train_loss=2.6535, train_acc=0.1006, val_loss=2.9417, val_acc=0.0980\n",
      "Epoch 66: train_loss=2.6550, train_acc=0.1018, val_loss=2.8583, val_acc=0.0974\n",
      "Epoch 67: train_loss=2.7810, train_acc=0.1017, val_loss=3.0162, val_acc=0.0998\n",
      "Epoch 68: train_loss=2.6802, train_acc=0.1013, val_loss=2.8615, val_acc=0.0980\n",
      "Epoch 69: train_loss=2.6548, train_acc=0.1017, val_loss=2.8467, val_acc=0.0984\n",
      "Epoch 70: train_loss=2.6821, train_acc=0.1018, val_loss=2.5773, val_acc=0.1028\n",
      "Epoch 71: train_loss=2.7321, train_acc=0.0953, val_loss=2.6242, val_acc=0.0990\n",
      "Epoch 72: train_loss=2.7119, train_acc=0.0983, val_loss=2.8318, val_acc=0.0980\n",
      "Epoch 73: train_loss=2.6672, train_acc=0.0982, val_loss=2.7162, val_acc=0.0974\n",
      "Epoch 74: train_loss=2.6398, train_acc=0.0999, val_loss=2.4011, val_acc=0.0980\n",
      "Epoch 75: train_loss=2.6733, train_acc=0.0987, val_loss=2.8862, val_acc=0.0984\n",
      "Epoch 76: train_loss=2.6660, train_acc=0.0992, val_loss=2.7870, val_acc=0.1028\n",
      "Epoch 77: train_loss=2.7034, train_acc=0.1008, val_loss=2.7153, val_acc=0.0998\n",
      "Epoch 78: train_loss=2.6929, train_acc=0.1005, val_loss=3.1386, val_acc=0.0984\n",
      "Epoch 79: train_loss=2.6920, train_acc=0.1007, val_loss=2.7134, val_acc=0.1028\n",
      "Epoch 80: train_loss=2.6180, train_acc=0.1019, val_loss=3.0419, val_acc=0.1000\n",
      "Epoch 81: train_loss=2.6829, train_acc=0.1009, val_loss=2.5587, val_acc=0.0990\n",
      "Epoch 82: train_loss=2.6584, train_acc=0.0999, val_loss=2.5312, val_acc=0.0998\n",
      "Epoch 83: train_loss=2.6509, train_acc=0.1008, val_loss=2.7807, val_acc=0.0974\n",
      "Epoch 84: train_loss=2.7069, train_acc=0.0991, val_loss=2.8351, val_acc=0.0984\n",
      "Epoch 85: train_loss=2.7142, train_acc=0.1024, val_loss=3.3785, val_acc=0.0990\n",
      "Epoch 86: train_loss=2.6596, train_acc=0.0983, val_loss=2.8113, val_acc=0.0974\n",
      "Epoch 87: train_loss=2.6701, train_acc=0.1021, val_loss=3.0453, val_acc=0.0998\n",
      "Epoch 88: train_loss=2.6639, train_acc=0.1010, val_loss=2.5593, val_acc=0.1066\n",
      "Epoch 89: train_loss=2.6637, train_acc=0.1008, val_loss=2.7472, val_acc=0.0980\n",
      "Epoch 90: train_loss=2.7167, train_acc=0.0989, val_loss=2.6351, val_acc=0.0990\n",
      "Epoch 91: train_loss=2.6772, train_acc=0.0995, val_loss=2.6682, val_acc=0.0990\n",
      "Epoch 92: train_loss=2.7041, train_acc=0.1008, val_loss=3.5775, val_acc=0.0980\n",
      "Epoch 93: train_loss=2.6583, train_acc=0.0976, val_loss=2.5244, val_acc=0.0998\n",
      "Epoch 94: train_loss=2.6928, train_acc=0.1002, val_loss=2.5053, val_acc=0.1066\n",
      "Epoch 95: train_loss=2.6606, train_acc=0.1025, val_loss=2.7463, val_acc=0.0990\n",
      "Epoch 96: train_loss=2.7007, train_acc=0.0993, val_loss=2.5868, val_acc=0.0980\n",
      "Epoch 97: train_loss=2.6703, train_acc=0.0995, val_loss=2.7376, val_acc=0.0998\n",
      "Epoch 98: train_loss=2.6826, train_acc=0.0977, val_loss=2.4499, val_acc=0.0998\n",
      "Epoch 99: train_loss=2.6748, train_acc=0.0991, val_loss=2.8748, val_acc=0.1028\n",
      "Epoch 100: train_loss=2.7694, train_acc=0.0987, val_loss=2.6061, val_acc=0.0990\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>l2_loss</td><td>0.00833</td></tr><tr><td>train_acc</td><td>0.09875</td></tr><tr><td>train_loss</td><td>2.76935</td></tr><tr><td>val_acc</td><td>0.099</td></tr><tr><td>val_loss</td><td>2.60608</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">desert-sweep-1</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/abh643z9' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/abh643z9</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_170035-abh643z9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w6bvknbs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08155387124096189\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_181134-w6bvknbs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/w6bvknbs' target=\"_blank\">stellar-sweep-2</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/w6bvknbs' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/w6bvknbs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.0170, train_acc=0.3006, val_loss=1.7908, val_acc=0.3516\n",
      "Epoch 2: train_loss=1.8149, train_acc=0.3668, val_loss=1.7090, val_acc=0.3792\n",
      "Epoch 3: train_loss=1.7430, train_acc=0.3886, val_loss=1.7111, val_acc=0.3924\n",
      "Epoch 4: train_loss=1.7059, train_acc=0.3976, val_loss=1.7575, val_acc=0.3602\n",
      "Epoch 5: train_loss=1.6973, train_acc=0.4000, val_loss=1.6678, val_acc=0.4008\n",
      "Epoch 6: train_loss=1.6658, train_acc=0.4075, val_loss=1.6680, val_acc=0.3874\n",
      "Epoch 7: train_loss=1.6543, train_acc=0.4153, val_loss=1.6222, val_acc=0.4160\n",
      "Epoch 8: train_loss=1.6412, train_acc=0.4175, val_loss=1.6272, val_acc=0.4092\n",
      "Epoch 9: train_loss=1.6296, train_acc=0.4231, val_loss=1.6403, val_acc=0.4022\n",
      "Epoch 10: train_loss=1.6273, train_acc=0.4223, val_loss=1.5905, val_acc=0.4304\n",
      "Epoch 11: train_loss=1.6146, train_acc=0.4258, val_loss=1.6388, val_acc=0.4192\n",
      "Epoch 12: train_loss=1.6125, train_acc=0.4268, val_loss=1.5929, val_acc=0.4330\n",
      "Epoch 13: train_loss=1.6101, train_acc=0.4304, val_loss=1.5939, val_acc=0.4350\n",
      "Epoch 14: train_loss=1.6032, train_acc=0.4295, val_loss=1.6458, val_acc=0.4130\n",
      "Epoch 15: train_loss=1.6059, train_acc=0.4309, val_loss=1.6567, val_acc=0.4036\n",
      "Epoch 16: train_loss=1.6077, train_acc=0.4294, val_loss=1.6469, val_acc=0.4066\n",
      "Epoch 17: train_loss=1.5989, train_acc=0.4338, val_loss=1.6343, val_acc=0.4096\n",
      "Epoch 18: train_loss=1.5976, train_acc=0.4357, val_loss=1.6237, val_acc=0.4110\n",
      "Epoch 19: train_loss=1.6016, train_acc=0.4324, val_loss=1.6386, val_acc=0.3952\n",
      "Epoch 20: train_loss=1.6011, train_acc=0.4354, val_loss=1.6412, val_acc=0.4126\n",
      "Epoch 21: train_loss=1.5959, train_acc=0.4349, val_loss=1.5838, val_acc=0.4348\n",
      "Epoch 22: train_loss=1.5917, train_acc=0.4382, val_loss=1.5990, val_acc=0.4342\n",
      "Epoch 23: train_loss=1.5976, train_acc=0.4353, val_loss=1.6434, val_acc=0.4186\n",
      "Epoch 24: train_loss=1.5978, train_acc=0.4355, val_loss=1.6911, val_acc=0.3878\n",
      "Epoch 25: train_loss=1.5948, train_acc=0.4353, val_loss=1.5853, val_acc=0.4386\n",
      "Epoch 26: train_loss=1.5966, train_acc=0.4329, val_loss=1.8541, val_acc=0.3454\n",
      "Epoch 27: train_loss=1.5894, train_acc=0.4381, val_loss=1.6051, val_acc=0.4282\n",
      "Epoch 28: train_loss=1.5889, train_acc=0.4351, val_loss=1.6201, val_acc=0.4002\n",
      "Epoch 29: train_loss=1.6025, train_acc=0.4300, val_loss=1.5781, val_acc=0.4246\n",
      "Epoch 30: train_loss=1.5949, train_acc=0.4356, val_loss=1.7524, val_acc=0.3830\n",
      "Epoch 31: train_loss=1.6197, train_acc=0.4275, val_loss=1.5871, val_acc=0.4254\n",
      "Epoch 32: train_loss=1.5991, train_acc=0.4311, val_loss=1.5826, val_acc=0.4248\n",
      "Epoch 33: train_loss=1.5876, train_acc=0.4375, val_loss=1.6070, val_acc=0.4296\n",
      "Epoch 34: train_loss=1.5973, train_acc=0.4353, val_loss=1.5640, val_acc=0.4304\n",
      "Epoch 35: train_loss=1.5859, train_acc=0.4401, val_loss=1.5702, val_acc=0.4364\n",
      "Epoch 36: train_loss=1.5924, train_acc=0.4369, val_loss=1.5932, val_acc=0.4294\n",
      "Epoch 37: train_loss=1.5898, train_acc=0.4379, val_loss=1.6931, val_acc=0.3808\n",
      "Epoch 38: train_loss=1.5896, train_acc=0.4388, val_loss=1.6552, val_acc=0.3974\n",
      "Epoch 39: train_loss=1.5862, train_acc=0.4373, val_loss=1.6404, val_acc=0.4022\n",
      "Epoch 40: train_loss=1.5977, train_acc=0.4325, val_loss=1.6144, val_acc=0.4204\n",
      "Epoch 41: train_loss=1.5970, train_acc=0.4322, val_loss=1.5580, val_acc=0.4432\n",
      "Epoch 42: train_loss=1.5901, train_acc=0.4359, val_loss=1.5641, val_acc=0.4386\n",
      "Epoch 43: train_loss=1.5829, train_acc=0.4384, val_loss=1.6531, val_acc=0.4008\n",
      "Epoch 44: train_loss=1.6079, train_acc=0.4302, val_loss=1.5784, val_acc=0.4250\n",
      "Epoch 45: train_loss=1.6045, train_acc=0.4312, val_loss=1.6629, val_acc=0.3894\n",
      "Epoch 46: train_loss=1.6093, train_acc=0.4307, val_loss=1.6325, val_acc=0.4164\n",
      "Epoch 47: train_loss=1.5994, train_acc=0.4342, val_loss=1.5696, val_acc=0.4330\n",
      "Epoch 48: train_loss=1.5921, train_acc=0.4361, val_loss=1.6775, val_acc=0.3970\n",
      "Epoch 49: train_loss=1.6065, train_acc=0.4323, val_loss=1.5705, val_acc=0.4372\n",
      "Epoch 50: train_loss=1.5976, train_acc=0.4316, val_loss=1.6092, val_acc=0.4296\n",
      "Epoch 51: train_loss=1.5969, train_acc=0.4331, val_loss=1.5615, val_acc=0.4402\n",
      "Epoch 52: train_loss=1.5903, train_acc=0.4369, val_loss=1.5897, val_acc=0.4238\n",
      "Epoch 53: train_loss=1.5904, train_acc=0.4358, val_loss=1.5367, val_acc=0.4488\n",
      "Epoch 54: train_loss=1.5812, train_acc=0.4391, val_loss=1.6828, val_acc=0.3862\n",
      "Epoch 55: train_loss=1.5818, train_acc=0.4375, val_loss=1.6344, val_acc=0.4126\n",
      "Epoch 56: train_loss=1.5839, train_acc=0.4392, val_loss=1.7234, val_acc=0.3506\n",
      "Epoch 57: train_loss=1.5979, train_acc=0.4355, val_loss=1.6443, val_acc=0.3898\n",
      "Epoch 58: train_loss=1.5858, train_acc=0.4388, val_loss=1.6702, val_acc=0.4126\n",
      "Epoch 59: train_loss=1.5842, train_acc=0.4383, val_loss=1.6248, val_acc=0.4076\n",
      "Epoch 60: train_loss=1.5853, train_acc=0.4388, val_loss=1.7159, val_acc=0.3840\n",
      "Epoch 61: train_loss=1.5835, train_acc=0.4381, val_loss=1.6056, val_acc=0.4118\n",
      "Epoch 62: train_loss=1.6013, train_acc=0.4299, val_loss=1.5566, val_acc=0.4448\n",
      "Epoch 63: train_loss=1.5860, train_acc=0.4356, val_loss=1.6117, val_acc=0.4090\n",
      "Epoch 64: train_loss=1.5859, train_acc=0.4374, val_loss=1.5739, val_acc=0.4292\n",
      "Epoch 65: train_loss=1.5848, train_acc=0.4382, val_loss=1.5813, val_acc=0.4364\n",
      "Epoch 66: train_loss=1.5853, train_acc=0.4347, val_loss=1.5911, val_acc=0.4406\n",
      "Epoch 67: train_loss=1.5857, train_acc=0.4385, val_loss=1.6295, val_acc=0.4114\n",
      "Epoch 68: train_loss=1.5834, train_acc=0.4378, val_loss=1.5470, val_acc=0.4442\n",
      "Epoch 69: train_loss=1.5838, train_acc=0.4382, val_loss=1.6761, val_acc=0.4138\n",
      "Epoch 70: train_loss=1.5857, train_acc=0.4354, val_loss=1.5923, val_acc=0.4250\n",
      "Epoch 71: train_loss=1.5792, train_acc=0.4394, val_loss=1.6101, val_acc=0.4240\n",
      "Epoch 72: train_loss=1.5742, train_acc=0.4405, val_loss=1.6955, val_acc=0.3992\n",
      "Epoch 73: train_loss=1.5922, train_acc=0.4357, val_loss=1.5681, val_acc=0.4350\n",
      "Epoch 74: train_loss=1.5815, train_acc=0.4412, val_loss=1.5490, val_acc=0.4522\n",
      "Epoch 75: train_loss=1.5838, train_acc=0.4404, val_loss=1.5896, val_acc=0.4218\n",
      "Epoch 76: train_loss=1.5798, train_acc=0.4390, val_loss=1.6834, val_acc=0.4026\n",
      "Epoch 77: train_loss=1.5882, train_acc=0.4381, val_loss=1.6646, val_acc=0.3956\n",
      "Epoch 78: train_loss=1.5810, train_acc=0.4385, val_loss=1.5798, val_acc=0.4328\n",
      "Epoch 79: train_loss=1.5815, train_acc=0.4400, val_loss=1.7567, val_acc=0.3816\n",
      "Epoch 80: train_loss=1.5981, train_acc=0.4342, val_loss=1.5803, val_acc=0.4320\n",
      "Epoch 81: train_loss=1.5860, train_acc=0.4365, val_loss=1.6288, val_acc=0.4156\n",
      "Epoch 82: train_loss=1.6020, train_acc=0.4317, val_loss=1.5524, val_acc=0.4402\n",
      "Epoch 83: train_loss=1.5926, train_acc=0.4330, val_loss=1.6039, val_acc=0.4392\n",
      "Epoch 84: train_loss=1.5853, train_acc=0.4362, val_loss=1.5786, val_acc=0.4252\n",
      "Epoch 85: train_loss=1.5896, train_acc=0.4354, val_loss=1.5611, val_acc=0.4408\n",
      "Epoch 86: train_loss=1.5878, train_acc=0.4339, val_loss=1.5665, val_acc=0.4324\n",
      "Epoch 87: train_loss=1.5824, train_acc=0.4397, val_loss=1.5955, val_acc=0.4184\n",
      "Epoch 88: train_loss=1.5793, train_acc=0.4423, val_loss=1.5783, val_acc=0.4282\n",
      "Epoch 89: train_loss=1.5841, train_acc=0.4395, val_loss=1.6211, val_acc=0.4124\n",
      "Epoch 90: train_loss=1.5768, train_acc=0.4403, val_loss=1.5665, val_acc=0.4340\n",
      "Epoch 91: train_loss=1.5762, train_acc=0.4421, val_loss=1.5517, val_acc=0.4406\n",
      "Epoch 92: train_loss=1.5805, train_acc=0.4398, val_loss=1.6024, val_acc=0.4204\n",
      "Epoch 93: train_loss=1.5772, train_acc=0.4419, val_loss=1.7013, val_acc=0.3946\n",
      "Epoch 94: train_loss=1.5802, train_acc=0.4440, val_loss=1.5535, val_acc=0.4444\n",
      "Epoch 95: train_loss=1.5787, train_acc=0.4408, val_loss=1.6119, val_acc=0.4166\n",
      "Epoch 96: train_loss=1.5885, train_acc=0.4374, val_loss=1.5749, val_acc=0.4282\n",
      "Epoch 97: train_loss=1.5822, train_acc=0.4366, val_loss=1.5525, val_acc=0.4552\n",
      "Epoch 98: train_loss=1.5836, train_acc=0.4409, val_loss=1.5573, val_acc=0.4436\n",
      "Epoch 99: train_loss=1.5797, train_acc=0.4401, val_loss=1.5703, val_acc=0.4350\n",
      "Epoch 100: train_loss=1.5796, train_acc=0.4397, val_loss=1.5647, val_acc=0.4360\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>l2_loss</td><td>0.02468</td></tr><tr><td>train_acc</td><td>0.43968</td></tr><tr><td>train_loss</td><td>1.57959</td></tr><tr><td>val_acc</td><td>0.436</td></tr><tr><td>val_loss</td><td>1.56473</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stellar-sweep-2</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/w6bvknbs' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/w6bvknbs</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_181134-w6bvknbs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gmo6iya8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03946342475844395\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_184219-gmo6iya8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gmo6iya8' target=\"_blank\">icy-sweep-3</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gmo6iya8' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gmo6iya8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.2699, train_acc=0.1709, val_loss=2.2241, val_acc=0.2084\n",
      "Epoch 2: train_loss=2.2124, train_acc=0.2282, val_loss=2.1760, val_acc=0.2430\n",
      "Epoch 3: train_loss=2.1666, train_acc=0.2586, val_loss=2.1334, val_acc=0.2694\n",
      "Epoch 4: train_loss=2.1265, train_acc=0.2762, val_loss=2.0967, val_acc=0.2698\n",
      "Epoch 5: train_loss=2.0916, train_acc=0.2857, val_loss=2.0639, val_acc=0.2804\n",
      "Epoch 6: train_loss=2.0618, train_acc=0.2960, val_loss=2.0363, val_acc=0.2978\n",
      "Epoch 7: train_loss=2.0366, train_acc=0.3043, val_loss=2.0139, val_acc=0.3044\n",
      "Epoch 8: train_loss=2.0147, train_acc=0.3153, val_loss=1.9941, val_acc=0.3086\n",
      "Epoch 9: train_loss=1.9953, train_acc=0.3201, val_loss=1.9764, val_acc=0.3152\n",
      "Epoch 10: train_loss=1.9783, train_acc=0.3276, val_loss=1.9610, val_acc=0.3192\n",
      "Epoch 11: train_loss=1.9628, train_acc=0.3316, val_loss=1.9473, val_acc=0.3240\n",
      "Epoch 12: train_loss=1.9488, train_acc=0.3362, val_loss=1.9342, val_acc=0.3320\n",
      "Epoch 13: train_loss=1.9361, train_acc=0.3402, val_loss=1.9223, val_acc=0.3362\n",
      "Epoch 14: train_loss=1.9244, train_acc=0.3446, val_loss=1.9115, val_acc=0.3368\n",
      "Epoch 15: train_loss=1.9137, train_acc=0.3492, val_loss=1.9010, val_acc=0.3410\n",
      "Epoch 16: train_loss=1.9034, train_acc=0.3502, val_loss=1.8930, val_acc=0.3440\n",
      "Epoch 17: train_loss=1.8940, train_acc=0.3544, val_loss=1.8838, val_acc=0.3460\n",
      "Epoch 18: train_loss=1.8852, train_acc=0.3573, val_loss=1.8753, val_acc=0.3458\n",
      "Epoch 19: train_loss=1.8771, train_acc=0.3591, val_loss=1.8681, val_acc=0.3466\n",
      "Epoch 20: train_loss=1.8695, train_acc=0.3610, val_loss=1.8608, val_acc=0.3512\n",
      "Epoch 21: train_loss=1.8623, train_acc=0.3628, val_loss=1.8554, val_acc=0.3506\n",
      "Epoch 22: train_loss=1.8557, train_acc=0.3643, val_loss=1.8482, val_acc=0.3550\n",
      "Epoch 23: train_loss=1.8490, train_acc=0.3678, val_loss=1.8420, val_acc=0.3576\n",
      "Epoch 24: train_loss=1.8429, train_acc=0.3681, val_loss=1.8360, val_acc=0.3572\n",
      "Epoch 25: train_loss=1.8370, train_acc=0.3708, val_loss=1.8310, val_acc=0.3570\n",
      "Epoch 26: train_loss=1.8310, train_acc=0.3712, val_loss=1.8261, val_acc=0.3618\n",
      "Epoch 27: train_loss=1.8257, train_acc=0.3737, val_loss=1.8208, val_acc=0.3614\n",
      "Epoch 28: train_loss=1.8203, train_acc=0.3747, val_loss=1.8163, val_acc=0.3618\n",
      "Epoch 29: train_loss=1.8150, train_acc=0.3767, val_loss=1.8108, val_acc=0.3634\n",
      "Epoch 30: train_loss=1.8103, train_acc=0.3781, val_loss=1.8050, val_acc=0.3630\n",
      "Epoch 31: train_loss=1.8053, train_acc=0.3787, val_loss=1.8026, val_acc=0.3636\n",
      "Epoch 32: train_loss=1.8004, train_acc=0.3808, val_loss=1.7966, val_acc=0.3700\n",
      "Epoch 33: train_loss=1.7957, train_acc=0.3825, val_loss=1.7928, val_acc=0.3674\n",
      "Epoch 34: train_loss=1.7912, train_acc=0.3825, val_loss=1.7889, val_acc=0.3694\n",
      "Epoch 35: train_loss=1.7868, train_acc=0.3845, val_loss=1.7839, val_acc=0.3712\n",
      "Epoch 36: train_loss=1.7823, train_acc=0.3870, val_loss=1.7796, val_acc=0.3732\n",
      "Epoch 37: train_loss=1.7781, train_acc=0.3890, val_loss=1.7758, val_acc=0.3722\n",
      "Epoch 38: train_loss=1.7735, train_acc=0.3895, val_loss=1.7724, val_acc=0.3744\n",
      "Epoch 39: train_loss=1.7699, train_acc=0.3917, val_loss=1.7676, val_acc=0.3738\n",
      "Epoch 40: train_loss=1.7657, train_acc=0.3930, val_loss=1.7645, val_acc=0.3756\n",
      "Epoch 41: train_loss=1.7619, train_acc=0.3933, val_loss=1.7607, val_acc=0.3776\n",
      "Epoch 42: train_loss=1.7581, train_acc=0.3965, val_loss=1.7565, val_acc=0.3758\n",
      "Epoch 43: train_loss=1.7541, train_acc=0.3958, val_loss=1.7540, val_acc=0.3760\n",
      "Epoch 44: train_loss=1.7503, train_acc=0.3963, val_loss=1.7496, val_acc=0.3798\n",
      "Epoch 45: train_loss=1.7463, train_acc=0.3991, val_loss=1.7487, val_acc=0.3804\n",
      "Epoch 46: train_loss=1.7432, train_acc=0.4004, val_loss=1.7426, val_acc=0.3832\n",
      "Epoch 47: train_loss=1.7396, train_acc=0.4007, val_loss=1.7391, val_acc=0.3862\n",
      "Epoch 48: train_loss=1.7363, train_acc=0.4026, val_loss=1.7373, val_acc=0.3796\n",
      "Epoch 49: train_loss=1.7326, train_acc=0.4032, val_loss=1.7326, val_acc=0.3848\n",
      "Epoch 50: train_loss=1.7295, train_acc=0.4042, val_loss=1.7290, val_acc=0.3850\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.40421</td></tr><tr><td>train_loss</td><td>1.72951</td></tr><tr><td>val_acc</td><td>0.385</td></tr><tr><td>val_loss</td><td>1.72895</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">icy-sweep-3</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gmo6iya8' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gmo6iya8</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_184219-gmo6iya8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t7uce4v6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.012297581646995327\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_184621-t7uce4v6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t7uce4v6' target=\"_blank\">zany-sweep-4</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t7uce4v6' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t7uce4v6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.6349, train_acc=0.1015, val_loss=2.3515, val_acc=0.0974\n",
      "Epoch 2: train_loss=2.4116, train_acc=0.1018, val_loss=2.3969, val_acc=0.1028\n",
      "Epoch 3: train_loss=2.3864, train_acc=0.1172, val_loss=2.3263, val_acc=0.1068\n",
      "Epoch 4: train_loss=2.3787, train_acc=0.1164, val_loss=2.2829, val_acc=0.1516\n",
      "Epoch 5: train_loss=2.3960, train_acc=0.1111, val_loss=2.3617, val_acc=0.1000\n",
      "Epoch 6: train_loss=2.3867, train_acc=0.1153, val_loss=2.2945, val_acc=0.1162\n",
      "Epoch 7: train_loss=2.3946, train_acc=0.1136, val_loss=2.3159, val_acc=0.1468\n",
      "Epoch 8: train_loss=2.3851, train_acc=0.1171, val_loss=2.3615, val_acc=0.1066\n",
      "Epoch 9: train_loss=2.3933, train_acc=0.1091, val_loss=2.2860, val_acc=0.1198\n",
      "Epoch 10: train_loss=2.4047, train_acc=0.1095, val_loss=2.2819, val_acc=0.1450\n",
      "Epoch 11: train_loss=2.4016, train_acc=0.1074, val_loss=2.2933, val_acc=0.1422\n",
      "Epoch 12: train_loss=2.4095, train_acc=0.1064, val_loss=2.3236, val_acc=0.1022\n",
      "Epoch 13: train_loss=2.4102, train_acc=0.1047, val_loss=2.3799, val_acc=0.0990\n",
      "Epoch 14: train_loss=2.4604, train_acc=0.1002, val_loss=2.3587, val_acc=0.0990\n",
      "Epoch 15: train_loss=2.4305, train_acc=0.1010, val_loss=2.3485, val_acc=0.0990\n",
      "Epoch 16: train_loss=2.3981, train_acc=0.1070, val_loss=2.3702, val_acc=0.1216\n",
      "Epoch 17: train_loss=2.4410, train_acc=0.0995, val_loss=2.3568, val_acc=0.0998\n",
      "Epoch 18: train_loss=2.4187, train_acc=0.1005, val_loss=2.3554, val_acc=0.0998\n",
      "Epoch 19: train_loss=2.4270, train_acc=0.0992, val_loss=2.4358, val_acc=0.0984\n",
      "Epoch 20: train_loss=2.4222, train_acc=0.1006, val_loss=2.4216, val_acc=0.1028\n",
      "Epoch 21: train_loss=2.4311, train_acc=0.1019, val_loss=2.3549, val_acc=0.1066\n",
      "Epoch 22: train_loss=2.4094, train_acc=0.0995, val_loss=2.4577, val_acc=0.1000\n",
      "Epoch 23: train_loss=2.4280, train_acc=0.0990, val_loss=2.3949, val_acc=0.0998\n",
      "Epoch 24: train_loss=2.4284, train_acc=0.0996, val_loss=2.3642, val_acc=0.0980\n",
      "Epoch 25: train_loss=2.4123, train_acc=0.1012, val_loss=2.3958, val_acc=0.0990\n",
      "Epoch 26: train_loss=2.4244, train_acc=0.1003, val_loss=2.3856, val_acc=0.1000\n",
      "Epoch 27: train_loss=2.4276, train_acc=0.1037, val_loss=2.3924, val_acc=0.1028\n",
      "Epoch 28: train_loss=2.4344, train_acc=0.0968, val_loss=2.3593, val_acc=0.0998\n",
      "Epoch 29: train_loss=2.4252, train_acc=0.1002, val_loss=2.3410, val_acc=0.0984\n",
      "Epoch 30: train_loss=2.4259, train_acc=0.1003, val_loss=2.3827, val_acc=0.0984\n",
      "Epoch 31: train_loss=2.4150, train_acc=0.0991, val_loss=2.3440, val_acc=0.0988\n",
      "Epoch 32: train_loss=2.4156, train_acc=0.1044, val_loss=2.4403, val_acc=0.0984\n",
      "Epoch 33: train_loss=2.4360, train_acc=0.1002, val_loss=2.3617, val_acc=0.0996\n",
      "Epoch 34: train_loss=2.4396, train_acc=0.1002, val_loss=2.3514, val_acc=0.0984\n",
      "Epoch 35: train_loss=2.4316, train_acc=0.1009, val_loss=2.3245, val_acc=0.0990\n",
      "Epoch 36: train_loss=2.4210, train_acc=0.0983, val_loss=2.3441, val_acc=0.0980\n",
      "Epoch 37: train_loss=2.4107, train_acc=0.1004, val_loss=2.3570, val_acc=0.1028\n",
      "Epoch 38: train_loss=2.4215, train_acc=0.1013, val_loss=2.3607, val_acc=0.0990\n",
      "Epoch 39: train_loss=2.4289, train_acc=0.1013, val_loss=2.4015, val_acc=0.0974\n",
      "Epoch 40: train_loss=2.4195, train_acc=0.0988, val_loss=2.3595, val_acc=0.0990\n",
      "Epoch 41: train_loss=2.4315, train_acc=0.0999, val_loss=2.3748, val_acc=0.1000\n",
      "Epoch 42: train_loss=2.4233, train_acc=0.1002, val_loss=2.3225, val_acc=0.0974\n",
      "Epoch 43: train_loss=2.4156, train_acc=0.1002, val_loss=2.3531, val_acc=0.0980\n",
      "Epoch 44: train_loss=2.4309, train_acc=0.1048, val_loss=2.3945, val_acc=0.0990\n",
      "Epoch 45: train_loss=2.4298, train_acc=0.0993, val_loss=2.3694, val_acc=0.0990\n",
      "Epoch 46: train_loss=2.4176, train_acc=0.1009, val_loss=2.4170, val_acc=0.1066\n",
      "Epoch 47: train_loss=2.4290, train_acc=0.0997, val_loss=2.3762, val_acc=0.1028\n",
      "Epoch 48: train_loss=2.4204, train_acc=0.1008, val_loss=2.3496, val_acc=0.0974\n",
      "Epoch 49: train_loss=2.4340, train_acc=0.1002, val_loss=2.3513, val_acc=0.0998\n",
      "Epoch 50: train_loss=2.4307, train_acc=0.0998, val_loss=2.3561, val_acc=0.1408\n",
      "Epoch 51: train_loss=2.4369, train_acc=0.0982, val_loss=2.4306, val_acc=0.1028\n",
      "Epoch 52: train_loss=2.4076, train_acc=0.1007, val_loss=2.3774, val_acc=0.1028\n",
      "Epoch 53: train_loss=2.4201, train_acc=0.0975, val_loss=2.3772, val_acc=0.1028\n",
      "Epoch 54: train_loss=2.4486, train_acc=0.0994, val_loss=2.4317, val_acc=0.1028\n",
      "Epoch 55: train_loss=2.4150, train_acc=0.0993, val_loss=2.3508, val_acc=0.0990\n",
      "Epoch 56: train_loss=2.4497, train_acc=0.0995, val_loss=2.3934, val_acc=0.0990\n",
      "Epoch 57: train_loss=2.4233, train_acc=0.0999, val_loss=2.3698, val_acc=0.0992\n",
      "Epoch 58: train_loss=2.4279, train_acc=0.0997, val_loss=2.3832, val_acc=0.1066\n",
      "Epoch 59: train_loss=2.4317, train_acc=0.1010, val_loss=2.3586, val_acc=0.0974\n",
      "Epoch 60: train_loss=2.4157, train_acc=0.1030, val_loss=2.3267, val_acc=0.1000\n",
      "Epoch 61: train_loss=2.4109, train_acc=0.0989, val_loss=2.3555, val_acc=0.0990\n",
      "Epoch 62: train_loss=2.4298, train_acc=0.1005, val_loss=2.3661, val_acc=0.0990\n",
      "Epoch 63: train_loss=2.4107, train_acc=0.0982, val_loss=2.3884, val_acc=0.1000\n",
      "Epoch 64: train_loss=2.4269, train_acc=0.1003, val_loss=2.3547, val_acc=0.0984\n",
      "Epoch 65: train_loss=2.4133, train_acc=0.1011, val_loss=2.3926, val_acc=0.1000\n",
      "Epoch 66: train_loss=2.4049, train_acc=0.1015, val_loss=2.3497, val_acc=0.1066\n",
      "Epoch 67: train_loss=2.4210, train_acc=0.1022, val_loss=2.3762, val_acc=0.0984\n",
      "Epoch 68: train_loss=2.4328, train_acc=0.0994, val_loss=2.3479, val_acc=0.1000\n",
      "Epoch 69: train_loss=2.4182, train_acc=0.0993, val_loss=2.3877, val_acc=0.0990\n",
      "Epoch 70: train_loss=2.4233, train_acc=0.1026, val_loss=2.4551, val_acc=0.0970\n",
      "Epoch 71: train_loss=2.4453, train_acc=0.0998, val_loss=2.3754, val_acc=0.0990\n",
      "Epoch 72: train_loss=2.4449, train_acc=0.1011, val_loss=2.3951, val_acc=0.0990\n",
      "Epoch 73: train_loss=2.4379, train_acc=0.0995, val_loss=2.3780, val_acc=0.0990\n",
      "Epoch 74: train_loss=2.4120, train_acc=0.0987, val_loss=2.4010, val_acc=0.0998\n",
      "Epoch 75: train_loss=2.4377, train_acc=0.1007, val_loss=2.3801, val_acc=0.1066\n",
      "Epoch 76: train_loss=2.4104, train_acc=0.1005, val_loss=2.3674, val_acc=0.0980\n",
      "Epoch 77: train_loss=2.4163, train_acc=0.1015, val_loss=2.4648, val_acc=0.0980\n",
      "Epoch 78: train_loss=2.4350, train_acc=0.1008, val_loss=2.3617, val_acc=0.0990\n",
      "Epoch 79: train_loss=2.4095, train_acc=0.1015, val_loss=2.3453, val_acc=0.0998\n",
      "Epoch 80: train_loss=2.4107, train_acc=0.1012, val_loss=2.3545, val_acc=0.0990\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>l2_loss</td><td>0.00059</td></tr><tr><td>train_acc</td><td>0.10119</td></tr><tr><td>train_loss</td><td>2.41066</td></tr><tr><td>val_acc</td><td>0.099</td></tr><tr><td>val_loss</td><td>2.35451</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-sweep-4</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t7uce4v6' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t7uce4v6</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_184621-t7uce4v6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aflcdzsn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08156188822625067\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_192124-aflcdzsn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aflcdzsn' target=\"_blank\">denim-sweep-5</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aflcdzsn' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aflcdzsn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=6.7136, train_acc=0.0998, val_loss=19.1940, val_acc=0.0980\n",
      "Epoch 2: train_loss=6.4557, train_acc=0.0997, val_loss=7.9137, val_acc=0.0990\n",
      "Epoch 3: train_loss=5.8592, train_acc=0.0993, val_loss=18.8267, val_acc=0.1066\n",
      "Epoch 4: train_loss=6.1174, train_acc=0.0997, val_loss=18.2424, val_acc=0.0984\n",
      "Epoch 5: train_loss=6.0333, train_acc=0.0963, val_loss=11.5831, val_acc=0.0990\n",
      "Epoch 6: train_loss=5.7520, train_acc=0.1017, val_loss=11.2594, val_acc=0.0990\n",
      "Epoch 7: train_loss=5.9691, train_acc=0.0975, val_loss=17.1205, val_acc=0.1000\n",
      "Epoch 8: train_loss=5.9227, train_acc=0.1008, val_loss=8.7840, val_acc=0.1028\n",
      "Epoch 9: train_loss=5.9331, train_acc=0.1002, val_loss=10.3918, val_acc=0.0974\n",
      "Epoch 10: train_loss=6.1674, train_acc=0.0957, val_loss=9.9850, val_acc=0.0980\n",
      "Epoch 11: train_loss=5.6394, train_acc=0.1003, val_loss=8.5561, val_acc=0.1066\n",
      "Epoch 12: train_loss=5.9732, train_acc=0.1010, val_loss=7.2219, val_acc=0.0990\n",
      "Epoch 13: train_loss=5.8647, train_acc=0.1010, val_loss=14.0066, val_acc=0.0984\n",
      "Epoch 14: train_loss=5.8453, train_acc=0.0998, val_loss=17.1767, val_acc=0.0980\n",
      "Epoch 15: train_loss=6.0967, train_acc=0.0993, val_loss=10.1596, val_acc=0.0998\n",
      "Epoch 16: train_loss=5.9340, train_acc=0.0988, val_loss=9.0680, val_acc=0.0990\n",
      "Epoch 17: train_loss=5.7552, train_acc=0.0998, val_loss=17.3453, val_acc=0.1028\n",
      "Epoch 18: train_loss=5.9836, train_acc=0.1011, val_loss=10.2780, val_acc=0.1066\n",
      "Epoch 19: train_loss=5.7296, train_acc=0.0999, val_loss=10.1966, val_acc=0.1066\n",
      "Epoch 20: train_loss=5.9540, train_acc=0.1014, val_loss=8.5872, val_acc=0.0974\n",
      "Epoch 21: train_loss=5.9588, train_acc=0.0997, val_loss=13.9993, val_acc=0.0990\n",
      "Epoch 22: train_loss=5.9723, train_acc=0.1006, val_loss=8.9512, val_acc=0.1028\n",
      "Epoch 23: train_loss=5.7811, train_acc=0.0978, val_loss=7.7626, val_acc=0.0990\n",
      "Epoch 24: train_loss=6.0223, train_acc=0.1026, val_loss=9.2693, val_acc=0.1066\n",
      "Epoch 25: train_loss=5.8141, train_acc=0.1002, val_loss=13.1468, val_acc=0.0980\n",
      "Epoch 26: train_loss=6.0239, train_acc=0.1013, val_loss=9.6671, val_acc=0.1000\n",
      "Epoch 27: train_loss=5.7206, train_acc=0.0997, val_loss=12.1641, val_acc=0.0990\n",
      "Epoch 28: train_loss=6.0515, train_acc=0.1014, val_loss=8.4585, val_acc=0.0984\n",
      "Epoch 29: train_loss=5.7995, train_acc=0.1018, val_loss=9.7793, val_acc=0.0990\n",
      "Epoch 30: train_loss=5.9776, train_acc=0.1013, val_loss=10.9084, val_acc=0.1028\n",
      "Epoch 31: train_loss=5.7345, train_acc=0.0994, val_loss=9.8289, val_acc=0.0984\n",
      "Epoch 32: train_loss=5.9026, train_acc=0.0991, val_loss=16.6745, val_acc=0.1028\n",
      "Epoch 33: train_loss=5.9577, train_acc=0.0994, val_loss=11.9156, val_acc=0.0974\n",
      "Epoch 34: train_loss=5.8598, train_acc=0.1011, val_loss=12.2650, val_acc=0.1028\n",
      "Epoch 35: train_loss=5.8050, train_acc=0.1023, val_loss=11.3059, val_acc=0.1000\n",
      "Epoch 36: train_loss=5.9454, train_acc=0.1014, val_loss=9.7288, val_acc=0.1066\n",
      "Epoch 37: train_loss=5.8272, train_acc=0.1002, val_loss=13.5989, val_acc=0.1000\n",
      "Epoch 38: train_loss=6.0006, train_acc=0.0992, val_loss=19.4275, val_acc=0.0974\n",
      "Epoch 39: train_loss=5.9586, train_acc=0.0994, val_loss=20.0124, val_acc=0.0980\n",
      "Epoch 40: train_loss=6.2068, train_acc=0.1013, val_loss=12.5962, val_acc=0.0974\n",
      "Epoch 41: train_loss=5.8111, train_acc=0.1021, val_loss=7.6419, val_acc=0.1066\n",
      "Epoch 42: train_loss=6.0339, train_acc=0.1002, val_loss=6.4630, val_acc=0.1028\n",
      "Epoch 43: train_loss=5.9001, train_acc=0.0971, val_loss=10.6411, val_acc=0.1066\n",
      "Epoch 44: train_loss=5.9713, train_acc=0.1022, val_loss=15.0184, val_acc=0.1028\n",
      "Epoch 45: train_loss=6.0123, train_acc=0.0977, val_loss=7.4345, val_acc=0.1028\n",
      "Epoch 46: train_loss=5.7334, train_acc=0.1015, val_loss=11.8465, val_acc=0.0990\n",
      "Epoch 47: train_loss=5.9667, train_acc=0.0992, val_loss=8.7045, val_acc=0.0990\n",
      "Epoch 48: train_loss=5.9925, train_acc=0.0992, val_loss=9.1535, val_acc=0.0984\n",
      "Epoch 49: train_loss=5.9409, train_acc=0.0997, val_loss=11.7435, val_acc=0.0974\n",
      "Epoch 50: train_loss=5.8857, train_acc=0.1024, val_loss=11.6123, val_acc=0.0990\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>l2_loss</td><td>0.02364</td></tr><tr><td>train_acc</td><td>0.10242</td></tr><tr><td>train_loss</td><td>5.88566</td></tr><tr><td>val_acc</td><td>0.099</td></tr><tr><td>val_loss</td><td>11.61227</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">denim-sweep-5</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aflcdzsn' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aflcdzsn</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_192124-aflcdzsn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nctciwf8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.033531736465977104\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_213212-nctciwf8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/nctciwf8' target=\"_blank\">brisk-sweep-6</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/nctciwf8' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/nctciwf8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.3798, train_acc=0.1226, val_loss=2.2140, val_acc=0.1936\n",
      "Epoch 2: train_loss=2.2658, train_acc=0.1590, val_loss=2.1670, val_acc=0.2212\n",
      "Epoch 3: train_loss=2.2185, train_acc=0.1803, val_loss=2.1323, val_acc=0.2398\n",
      "Epoch 4: train_loss=2.1847, train_acc=0.1977, val_loss=2.0970, val_acc=0.2630\n",
      "Epoch 5: train_loss=2.1587, train_acc=0.2094, val_loss=2.0700, val_acc=0.2826\n",
      "Epoch 6: train_loss=2.1340, train_acc=0.2228, val_loss=2.0488, val_acc=0.2824\n",
      "Epoch 7: train_loss=2.1133, train_acc=0.2304, val_loss=2.0319, val_acc=0.2842\n",
      "Epoch 8: train_loss=2.0953, train_acc=0.2358, val_loss=2.0016, val_acc=0.3062\n",
      "Epoch 9: train_loss=2.0814, train_acc=0.2400, val_loss=1.9896, val_acc=0.3100\n",
      "Epoch 10: train_loss=2.0644, train_acc=0.2532, val_loss=1.9756, val_acc=0.3236\n",
      "Epoch 11: train_loss=2.0515, train_acc=0.2557, val_loss=1.9594, val_acc=0.3146\n",
      "Epoch 12: train_loss=2.0423, train_acc=0.2600, val_loss=1.9491, val_acc=0.3206\n",
      "Epoch 13: train_loss=2.0321, train_acc=0.2637, val_loss=1.9389, val_acc=0.3302\n",
      "Epoch 14: train_loss=2.0182, train_acc=0.2705, val_loss=1.9291, val_acc=0.3282\n",
      "Epoch 15: train_loss=2.0134, train_acc=0.2734, val_loss=1.9234, val_acc=0.3292\n",
      "Epoch 16: train_loss=2.0030, train_acc=0.2754, val_loss=1.9109, val_acc=0.3342\n",
      "Epoch 17: train_loss=1.9936, train_acc=0.2807, val_loss=1.9145, val_acc=0.3222\n",
      "Epoch 18: train_loss=1.9870, train_acc=0.2835, val_loss=1.9047, val_acc=0.3432\n",
      "Epoch 19: train_loss=1.9804, train_acc=0.2851, val_loss=1.8932, val_acc=0.3480\n",
      "Epoch 20: train_loss=1.9745, train_acc=0.2871, val_loss=1.8888, val_acc=0.3504\n",
      "Epoch 21: train_loss=1.9678, train_acc=0.2917, val_loss=1.8837, val_acc=0.3430\n",
      "Epoch 22: train_loss=1.9601, train_acc=0.2944, val_loss=1.8750, val_acc=0.3498\n",
      "Epoch 23: train_loss=1.9523, train_acc=0.2972, val_loss=1.8736, val_acc=0.3456\n",
      "Epoch 24: train_loss=1.9456, train_acc=0.3026, val_loss=1.8644, val_acc=0.3512\n",
      "Epoch 25: train_loss=1.9420, train_acc=0.3037, val_loss=1.8569, val_acc=0.3496\n",
      "Epoch 26: train_loss=1.9391, train_acc=0.3059, val_loss=1.8593, val_acc=0.3406\n",
      "Epoch 27: train_loss=1.9338, train_acc=0.3071, val_loss=1.8517, val_acc=0.3518\n",
      "Epoch 28: train_loss=1.9269, train_acc=0.3124, val_loss=1.8473, val_acc=0.3572\n",
      "Epoch 29: train_loss=1.9231, train_acc=0.3115, val_loss=1.8435, val_acc=0.3564\n",
      "Epoch 30: train_loss=1.9175, train_acc=0.3138, val_loss=1.8412, val_acc=0.3534\n",
      "Epoch 31: train_loss=1.9132, train_acc=0.3163, val_loss=1.8319, val_acc=0.3624\n",
      "Epoch 32: train_loss=1.9083, train_acc=0.3181, val_loss=1.8277, val_acc=0.3644\n",
      "Epoch 33: train_loss=1.9053, train_acc=0.3179, val_loss=1.8199, val_acc=0.3654\n",
      "Epoch 34: train_loss=1.9016, train_acc=0.3204, val_loss=1.8203, val_acc=0.3630\n",
      "Epoch 35: train_loss=1.8970, train_acc=0.3206, val_loss=1.8194, val_acc=0.3590\n",
      "Epoch 36: train_loss=1.8915, train_acc=0.3245, val_loss=1.8164, val_acc=0.3606\n",
      "Epoch 37: train_loss=1.8882, train_acc=0.3242, val_loss=1.8153, val_acc=0.3648\n",
      "Epoch 38: train_loss=1.8885, train_acc=0.3242, val_loss=1.8044, val_acc=0.3652\n",
      "Epoch 39: train_loss=1.8824, train_acc=0.3278, val_loss=1.8029, val_acc=0.3664\n",
      "Epoch 40: train_loss=1.8786, train_acc=0.3302, val_loss=1.7984, val_acc=0.3720\n",
      "Epoch 41: train_loss=1.8773, train_acc=0.3280, val_loss=1.7921, val_acc=0.3726\n",
      "Epoch 42: train_loss=1.8702, train_acc=0.3328, val_loss=1.7939, val_acc=0.3690\n",
      "Epoch 43: train_loss=1.8680, train_acc=0.3354, val_loss=1.7900, val_acc=0.3716\n",
      "Epoch 44: train_loss=1.8647, train_acc=0.3326, val_loss=1.7885, val_acc=0.3720\n",
      "Epoch 45: train_loss=1.8656, train_acc=0.3354, val_loss=1.7975, val_acc=0.3688\n",
      "Epoch 46: train_loss=1.8605, train_acc=0.3372, val_loss=1.7826, val_acc=0.3768\n",
      "Epoch 47: train_loss=1.8596, train_acc=0.3391, val_loss=1.7792, val_acc=0.3696\n",
      "Epoch 48: train_loss=1.8553, train_acc=0.3390, val_loss=1.7775, val_acc=0.3772\n",
      "Epoch 49: train_loss=1.8514, train_acc=0.3413, val_loss=1.7717, val_acc=0.3782\n",
      "Epoch 50: train_loss=1.8465, train_acc=0.3435, val_loss=1.7777, val_acc=0.3698\n",
      "Epoch 51: train_loss=1.8416, train_acc=0.3475, val_loss=1.7659, val_acc=0.3802\n",
      "Epoch 52: train_loss=1.8401, train_acc=0.3465, val_loss=1.7595, val_acc=0.3810\n",
      "Epoch 53: train_loss=1.8370, train_acc=0.3471, val_loss=1.7618, val_acc=0.3830\n",
      "Epoch 54: train_loss=1.8363, train_acc=0.3474, val_loss=1.7590, val_acc=0.3818\n",
      "Epoch 55: train_loss=1.8332, train_acc=0.3493, val_loss=1.7582, val_acc=0.3852\n",
      "Epoch 56: train_loss=1.8304, train_acc=0.3497, val_loss=1.7508, val_acc=0.3784\n",
      "Epoch 57: train_loss=1.8271, train_acc=0.3505, val_loss=1.7590, val_acc=0.3794\n",
      "Epoch 58: train_loss=1.8236, train_acc=0.3520, val_loss=1.7460, val_acc=0.3850\n",
      "Epoch 59: train_loss=1.8252, train_acc=0.3550, val_loss=1.7550, val_acc=0.3832\n",
      "Epoch 60: train_loss=1.8189, train_acc=0.3556, val_loss=1.7504, val_acc=0.3814\n",
      "Epoch 61: train_loss=1.8187, train_acc=0.3566, val_loss=1.7458, val_acc=0.3878\n",
      "Epoch 62: train_loss=1.8179, train_acc=0.3549, val_loss=1.7374, val_acc=0.3858\n",
      "Epoch 63: train_loss=1.8111, train_acc=0.3589, val_loss=1.7442, val_acc=0.3836\n",
      "Epoch 64: train_loss=1.8130, train_acc=0.3589, val_loss=1.7293, val_acc=0.3910\n",
      "Epoch 65: train_loss=1.8065, train_acc=0.3589, val_loss=1.7373, val_acc=0.3874\n",
      "Epoch 66: train_loss=1.8062, train_acc=0.3618, val_loss=1.7255, val_acc=0.3940\n",
      "Epoch 67: train_loss=1.8037, train_acc=0.3615, val_loss=1.7231, val_acc=0.3932\n",
      "Epoch 68: train_loss=1.7994, train_acc=0.3646, val_loss=1.7259, val_acc=0.3954\n",
      "Epoch 69: train_loss=1.8022, train_acc=0.3618, val_loss=1.7303, val_acc=0.3880\n",
      "Epoch 70: train_loss=1.7990, train_acc=0.3626, val_loss=1.7246, val_acc=0.3956\n",
      "Epoch 71: train_loss=1.7992, train_acc=0.3628, val_loss=1.7176, val_acc=0.3950\n",
      "Epoch 72: train_loss=1.7925, train_acc=0.3659, val_loss=1.7118, val_acc=0.4014\n",
      "Epoch 73: train_loss=1.7913, train_acc=0.3710, val_loss=1.7158, val_acc=0.3972\n",
      "Epoch 74: train_loss=1.7926, train_acc=0.3658, val_loss=1.7125, val_acc=0.4032\n",
      "Epoch 75: train_loss=1.7900, train_acc=0.3631, val_loss=1.7125, val_acc=0.3952\n",
      "Epoch 76: train_loss=1.7848, train_acc=0.3677, val_loss=1.7080, val_acc=0.3970\n",
      "Epoch 77: train_loss=1.7830, train_acc=0.3680, val_loss=1.7142, val_acc=0.3928\n",
      "Epoch 78: train_loss=1.7776, train_acc=0.3700, val_loss=1.7085, val_acc=0.3932\n",
      "Epoch 79: train_loss=1.7820, train_acc=0.3694, val_loss=1.7010, val_acc=0.4032\n",
      "Epoch 80: train_loss=1.7787, train_acc=0.3737, val_loss=1.6988, val_acc=0.4030\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>l2_loss</td><td>0.04693</td></tr><tr><td>train_acc</td><td>0.37371</td></tr><tr><td>train_loss</td><td>1.77874</td></tr><tr><td>val_acc</td><td>0.403</td></tr><tr><td>val_loss</td><td>1.6988</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">brisk-sweep-6</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/nctciwf8' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/nctciwf8</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_213212-nctciwf8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: t18q9j1e with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04441295241342425\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_214406-t18q9j1e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t18q9j1e' target=\"_blank\">solar-sweep-7</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t18q9j1e' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t18q9j1e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.4569, train_acc=0.1713, val_loss=2.1105, val_acc=0.2250\n",
      "Epoch 2: train_loss=2.2790, train_acc=0.2454, val_loss=2.0402, val_acc=0.2390\n",
      "Epoch 3: train_loss=2.1978, train_acc=0.2815, val_loss=2.0758, val_acc=0.2518\n",
      "Epoch 4: train_loss=2.1504, train_acc=0.2981, val_loss=1.9467, val_acc=0.2994\n",
      "Epoch 5: train_loss=2.1159, train_acc=0.3148, val_loss=1.9703, val_acc=0.2764\n",
      "Epoch 6: train_loss=2.0877, train_acc=0.3270, val_loss=1.9451, val_acc=0.3058\n",
      "Epoch 7: train_loss=2.0689, train_acc=0.3356, val_loss=2.0393, val_acc=0.2674\n",
      "Epoch 8: train_loss=2.0511, train_acc=0.3405, val_loss=2.0362, val_acc=0.2490\n",
      "Epoch 9: train_loss=2.0377, train_acc=0.3423, val_loss=1.9239, val_acc=0.2958\n",
      "Epoch 10: train_loss=2.0212, train_acc=0.3493, val_loss=1.9118, val_acc=0.2966\n",
      "Epoch 11: train_loss=2.0118, train_acc=0.3520, val_loss=1.8713, val_acc=0.3366\n",
      "Epoch 12: train_loss=1.9997, train_acc=0.3561, val_loss=1.8672, val_acc=0.3222\n",
      "Epoch 13: train_loss=1.9906, train_acc=0.3600, val_loss=1.9224, val_acc=0.3020\n",
      "Epoch 14: train_loss=1.9767, train_acc=0.3657, val_loss=2.0606, val_acc=0.2584\n",
      "Epoch 15: train_loss=1.9681, train_acc=0.3700, val_loss=1.8145, val_acc=0.3408\n",
      "Epoch 16: train_loss=1.9593, train_acc=0.3718, val_loss=1.8297, val_acc=0.3360\n",
      "Epoch 17: train_loss=1.9552, train_acc=0.3732, val_loss=1.7882, val_acc=0.3554\n",
      "Epoch 18: train_loss=1.9444, train_acc=0.3760, val_loss=1.9397, val_acc=0.2958\n",
      "Epoch 19: train_loss=1.9379, train_acc=0.3789, val_loss=1.8830, val_acc=0.3212\n",
      "Epoch 20: train_loss=1.9313, train_acc=0.3799, val_loss=1.8033, val_acc=0.3614\n",
      "Epoch 21: train_loss=1.9238, train_acc=0.3804, val_loss=1.7960, val_acc=0.3558\n",
      "Epoch 22: train_loss=1.9176, train_acc=0.3860, val_loss=1.8932, val_acc=0.3258\n",
      "Epoch 23: train_loss=1.9127, train_acc=0.3884, val_loss=1.9448, val_acc=0.2984\n",
      "Epoch 24: train_loss=1.9093, train_acc=0.3870, val_loss=1.9322, val_acc=0.3040\n",
      "Epoch 25: train_loss=1.9035, train_acc=0.3870, val_loss=1.7448, val_acc=0.3850\n",
      "Epoch 26: train_loss=1.8960, train_acc=0.3917, val_loss=1.8483, val_acc=0.3284\n",
      "Epoch 27: train_loss=1.8927, train_acc=0.3911, val_loss=1.8976, val_acc=0.3154\n",
      "Epoch 28: train_loss=1.8872, train_acc=0.3929, val_loss=1.7860, val_acc=0.3666\n",
      "Epoch 29: train_loss=1.8832, train_acc=0.3972, val_loss=1.7888, val_acc=0.3710\n",
      "Epoch 30: train_loss=1.8773, train_acc=0.3949, val_loss=2.0277, val_acc=0.2548\n",
      "Epoch 31: train_loss=1.8729, train_acc=0.3984, val_loss=1.8966, val_acc=0.3398\n",
      "Epoch 32: train_loss=1.8694, train_acc=0.3984, val_loss=1.7614, val_acc=0.3660\n",
      "Epoch 33: train_loss=1.8649, train_acc=0.3982, val_loss=1.7522, val_acc=0.3788\n",
      "Epoch 34: train_loss=1.8614, train_acc=0.4008, val_loss=1.8954, val_acc=0.3056\n",
      "Epoch 35: train_loss=1.8584, train_acc=0.4013, val_loss=1.7588, val_acc=0.3604\n",
      "Epoch 36: train_loss=1.8536, train_acc=0.4033, val_loss=1.8026, val_acc=0.3402\n",
      "Epoch 37: train_loss=1.8501, train_acc=0.4040, val_loss=1.7736, val_acc=0.3598\n",
      "Epoch 38: train_loss=1.8486, train_acc=0.4014, val_loss=1.7874, val_acc=0.3570\n",
      "Epoch 39: train_loss=1.8438, train_acc=0.4081, val_loss=1.7496, val_acc=0.3680\n",
      "Epoch 40: train_loss=1.8375, train_acc=0.4057, val_loss=1.7631, val_acc=0.3622\n",
      "Epoch 41: train_loss=1.8367, train_acc=0.4080, val_loss=1.8915, val_acc=0.3264\n",
      "Epoch 42: train_loss=1.8365, train_acc=0.4069, val_loss=1.7747, val_acc=0.3582\n",
      "Epoch 43: train_loss=1.8325, train_acc=0.4081, val_loss=1.8779, val_acc=0.3042\n",
      "Epoch 44: train_loss=1.8289, train_acc=0.4075, val_loss=1.9066, val_acc=0.3224\n",
      "Epoch 45: train_loss=1.8267, train_acc=0.4101, val_loss=1.8075, val_acc=0.3448\n",
      "Epoch 46: train_loss=1.8206, train_acc=0.4106, val_loss=1.7476, val_acc=0.3872\n",
      "Epoch 47: train_loss=1.8193, train_acc=0.4089, val_loss=1.7028, val_acc=0.3906\n",
      "Epoch 48: train_loss=1.8144, train_acc=0.4106, val_loss=1.7119, val_acc=0.3886\n",
      "Epoch 49: train_loss=1.8149, train_acc=0.4115, val_loss=2.0155, val_acc=0.2974\n",
      "Epoch 50: train_loss=1.8117, train_acc=0.4138, val_loss=1.7303, val_acc=0.3842\n",
      "Epoch 51: train_loss=1.8087, train_acc=0.4133, val_loss=1.9878, val_acc=0.2720\n",
      "Epoch 52: train_loss=1.8058, train_acc=0.4138, val_loss=1.8094, val_acc=0.3718\n",
      "Epoch 53: train_loss=1.8021, train_acc=0.4129, val_loss=1.7237, val_acc=0.3858\n",
      "Epoch 54: train_loss=1.8003, train_acc=0.4137, val_loss=1.7783, val_acc=0.3548\n",
      "Epoch 55: train_loss=1.7967, train_acc=0.4149, val_loss=1.8230, val_acc=0.3194\n",
      "Epoch 56: train_loss=1.7959, train_acc=0.4139, val_loss=1.8436, val_acc=0.3368\n",
      "Epoch 57: train_loss=1.7932, train_acc=0.4146, val_loss=1.8581, val_acc=0.3320\n",
      "Epoch 58: train_loss=1.7916, train_acc=0.4176, val_loss=1.7920, val_acc=0.3610\n",
      "Epoch 59: train_loss=1.7877, train_acc=0.4189, val_loss=1.7708, val_acc=0.3576\n",
      "Epoch 60: train_loss=1.7860, train_acc=0.4193, val_loss=1.7038, val_acc=0.4032\n",
      "Epoch 61: train_loss=1.7827, train_acc=0.4177, val_loss=1.7210, val_acc=0.3876\n",
      "Epoch 62: train_loss=1.7807, train_acc=0.4194, val_loss=1.7646, val_acc=0.3632\n",
      "Epoch 63: train_loss=1.7787, train_acc=0.4189, val_loss=1.7502, val_acc=0.3864\n",
      "Epoch 64: train_loss=1.7781, train_acc=0.4203, val_loss=1.7849, val_acc=0.3664\n",
      "Epoch 65: train_loss=1.7750, train_acc=0.4189, val_loss=1.9084, val_acc=0.3106\n",
      "Epoch 66: train_loss=1.7740, train_acc=0.4207, val_loss=1.6824, val_acc=0.3990\n",
      "Epoch 67: train_loss=1.7704, train_acc=0.4189, val_loss=1.8508, val_acc=0.3480\n",
      "Epoch 68: train_loss=1.7700, train_acc=0.4206, val_loss=1.7201, val_acc=0.3758\n",
      "Epoch 69: train_loss=1.7672, train_acc=0.4212, val_loss=1.7111, val_acc=0.3888\n",
      "Epoch 70: train_loss=1.7647, train_acc=0.4224, val_loss=1.7584, val_acc=0.3672\n",
      "Epoch 71: train_loss=1.7631, train_acc=0.4194, val_loss=1.7172, val_acc=0.3820\n",
      "Epoch 72: train_loss=1.7594, train_acc=0.4221, val_loss=1.6722, val_acc=0.4040\n",
      "Epoch 73: train_loss=1.7567, train_acc=0.4245, val_loss=1.8233, val_acc=0.3646\n",
      "Epoch 74: train_loss=1.7578, train_acc=0.4232, val_loss=1.7038, val_acc=0.3842\n",
      "Epoch 75: train_loss=1.7535, train_acc=0.4247, val_loss=1.8548, val_acc=0.3330\n",
      "Epoch 76: train_loss=1.7566, train_acc=0.4212, val_loss=1.7394, val_acc=0.3752\n",
      "Epoch 77: train_loss=1.7535, train_acc=0.4240, val_loss=2.0775, val_acc=0.2490\n",
      "Epoch 78: train_loss=1.7511, train_acc=0.4248, val_loss=1.7382, val_acc=0.3826\n",
      "Epoch 79: train_loss=1.7489, train_acc=0.4238, val_loss=1.7678, val_acc=0.3544\n",
      "Epoch 80: train_loss=1.7464, train_acc=0.4255, val_loss=1.7495, val_acc=0.3666\n",
      "Epoch 81: train_loss=1.7481, train_acc=0.4237, val_loss=1.7516, val_acc=0.3702\n",
      "Epoch 82: train_loss=1.7443, train_acc=0.4256, val_loss=1.9087, val_acc=0.3136\n",
      "Epoch 83: train_loss=1.7429, train_acc=0.4266, val_loss=1.6972, val_acc=0.3904\n",
      "Epoch 84: train_loss=1.7424, train_acc=0.4248, val_loss=1.6796, val_acc=0.4040\n",
      "Epoch 85: train_loss=1.7378, train_acc=0.4255, val_loss=1.6777, val_acc=0.4050\n",
      "Epoch 86: train_loss=1.7371, train_acc=0.4268, val_loss=1.7838, val_acc=0.3672\n",
      "Epoch 87: train_loss=1.7354, train_acc=0.4281, val_loss=1.8670, val_acc=0.3346\n",
      "Epoch 88: train_loss=1.7349, train_acc=0.4250, val_loss=1.7587, val_acc=0.3748\n",
      "Epoch 89: train_loss=1.7327, train_acc=0.4281, val_loss=1.7171, val_acc=0.3826\n",
      "Epoch 90: train_loss=1.7313, train_acc=0.4284, val_loss=1.7110, val_acc=0.3854\n",
      "Epoch 91: train_loss=1.7296, train_acc=0.4274, val_loss=1.6678, val_acc=0.4100\n",
      "Epoch 92: train_loss=1.7265, train_acc=0.4270, val_loss=1.8750, val_acc=0.3224\n",
      "Epoch 93: train_loss=1.7293, train_acc=0.4284, val_loss=1.7065, val_acc=0.3880\n",
      "Epoch 94: train_loss=1.7255, train_acc=0.4285, val_loss=1.6844, val_acc=0.4028\n",
      "Epoch 95: train_loss=1.7226, train_acc=0.4291, val_loss=1.8047, val_acc=0.3318\n",
      "Epoch 96: train_loss=1.7240, train_acc=0.4285, val_loss=1.7299, val_acc=0.3710\n",
      "Epoch 97: train_loss=1.7207, train_acc=0.4296, val_loss=1.7336, val_acc=0.3830\n",
      "Epoch 98: train_loss=1.7199, train_acc=0.4295, val_loss=1.6912, val_acc=0.3980\n",
      "Epoch 99: train_loss=1.7198, train_acc=0.4284, val_loss=1.7104, val_acc=0.3850\n",
      "Epoch 100: train_loss=1.7162, train_acc=0.4283, val_loss=1.7999, val_acc=0.3690\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>l2_loss</td><td>0.61091</td></tr><tr><td>train_acc</td><td>0.42834</td></tr><tr><td>train_loss</td><td>1.71621</td></tr><tr><td>val_acc</td><td>0.369</td></tr><tr><td>val_loss</td><td>1.7999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-7</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t18q9j1e' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/t18q9j1e</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_214406-t18q9j1e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aylfnilq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0661663503948968\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_223725-aylfnilq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aylfnilq' target=\"_blank\">devoted-sweep-8</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aylfnilq' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aylfnilq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.2872, train_acc=0.1386, val_loss=2.2245, val_acc=0.2150\n",
      "Epoch 2: train_loss=2.2296, train_acc=0.1776, val_loss=2.1778, val_acc=0.2324\n",
      "Epoch 3: train_loss=2.1864, train_acc=0.1980, val_loss=2.1366, val_acc=0.2372\n",
      "Epoch 4: train_loss=2.1494, train_acc=0.2108, val_loss=2.0957, val_acc=0.2644\n",
      "Epoch 5: train_loss=2.1150, train_acc=0.2247, val_loss=2.0642, val_acc=0.2504\n",
      "Epoch 6: train_loss=2.0898, train_acc=0.2319, val_loss=2.0272, val_acc=0.2908\n",
      "Epoch 7: train_loss=2.0632, train_acc=0.2476, val_loss=2.0259, val_acc=0.2524\n",
      "Epoch 8: train_loss=2.0439, train_acc=0.2555, val_loss=1.9962, val_acc=0.2854\n",
      "Epoch 9: train_loss=2.0252, train_acc=0.2647, val_loss=1.9768, val_acc=0.2950\n",
      "Epoch 10: train_loss=2.0118, train_acc=0.2701, val_loss=1.9538, val_acc=0.3248\n",
      "Epoch 11: train_loss=1.9943, train_acc=0.2782, val_loss=1.9377, val_acc=0.3230\n",
      "Epoch 12: train_loss=1.9832, train_acc=0.2851, val_loss=1.9397, val_acc=0.3104\n",
      "Epoch 13: train_loss=1.9714, train_acc=0.2863, val_loss=1.9217, val_acc=0.3302\n",
      "Epoch 14: train_loss=1.9614, train_acc=0.2945, val_loss=1.9095, val_acc=0.3258\n",
      "Epoch 15: train_loss=1.9548, train_acc=0.2981, val_loss=1.8913, val_acc=0.3382\n",
      "Epoch 16: train_loss=1.9427, train_acc=0.3022, val_loss=1.8881, val_acc=0.3294\n",
      "Epoch 17: train_loss=1.9335, train_acc=0.3069, val_loss=1.8862, val_acc=0.3258\n",
      "Epoch 18: train_loss=1.9265, train_acc=0.3119, val_loss=1.8739, val_acc=0.3414\n",
      "Epoch 19: train_loss=1.9166, train_acc=0.3174, val_loss=1.9030, val_acc=0.3160\n",
      "Epoch 20: train_loss=1.9100, train_acc=0.3194, val_loss=1.8631, val_acc=0.3404\n",
      "Epoch 21: train_loss=1.9008, train_acc=0.3217, val_loss=1.9133, val_acc=0.3174\n",
      "Epoch 22: train_loss=1.8940, train_acc=0.3257, val_loss=1.8457, val_acc=0.3526\n",
      "Epoch 23: train_loss=1.8881, train_acc=0.3276, val_loss=1.8546, val_acc=0.3406\n",
      "Epoch 24: train_loss=1.8794, train_acc=0.3327, val_loss=1.8319, val_acc=0.3454\n",
      "Epoch 25: train_loss=1.8739, train_acc=0.3359, val_loss=1.8257, val_acc=0.3584\n",
      "Epoch 26: train_loss=1.8661, train_acc=0.3358, val_loss=1.8395, val_acc=0.3450\n",
      "Epoch 27: train_loss=1.8642, train_acc=0.3380, val_loss=1.8247, val_acc=0.3522\n",
      "Epoch 28: train_loss=1.8547, train_acc=0.3415, val_loss=1.8118, val_acc=0.3556\n",
      "Epoch 29: train_loss=1.8530, train_acc=0.3423, val_loss=1.8004, val_acc=0.3664\n",
      "Epoch 30: train_loss=1.8455, train_acc=0.3433, val_loss=1.7896, val_acc=0.3674\n",
      "Epoch 31: train_loss=1.8383, train_acc=0.3496, val_loss=1.7951, val_acc=0.3604\n",
      "Epoch 32: train_loss=1.8344, train_acc=0.3471, val_loss=1.8064, val_acc=0.3510\n",
      "Epoch 33: train_loss=1.8292, train_acc=0.3524, val_loss=1.7886, val_acc=0.3636\n",
      "Epoch 34: train_loss=1.8242, train_acc=0.3520, val_loss=1.7731, val_acc=0.3758\n",
      "Epoch 35: train_loss=1.8212, train_acc=0.3515, val_loss=1.7708, val_acc=0.3660\n",
      "Epoch 36: train_loss=1.8164, train_acc=0.3551, val_loss=1.7674, val_acc=0.3790\n",
      "Epoch 37: train_loss=1.8141, train_acc=0.3543, val_loss=1.7723, val_acc=0.3724\n",
      "Epoch 38: train_loss=1.8055, train_acc=0.3589, val_loss=1.7905, val_acc=0.3558\n",
      "Epoch 39: train_loss=1.8046, train_acc=0.3596, val_loss=1.7614, val_acc=0.3734\n",
      "Epoch 40: train_loss=1.7973, train_acc=0.3646, val_loss=1.7469, val_acc=0.3816\n",
      "Epoch 41: train_loss=1.7963, train_acc=0.3629, val_loss=1.7512, val_acc=0.3784\n",
      "Epoch 42: train_loss=1.7920, train_acc=0.3681, val_loss=1.7353, val_acc=0.3846\n",
      "Epoch 43: train_loss=1.7857, train_acc=0.3675, val_loss=1.7647, val_acc=0.3672\n",
      "Epoch 44: train_loss=1.7804, train_acc=0.3720, val_loss=1.7371, val_acc=0.3822\n",
      "Epoch 45: train_loss=1.7802, train_acc=0.3682, val_loss=1.7288, val_acc=0.3868\n",
      "Epoch 46: train_loss=1.7766, train_acc=0.3697, val_loss=1.7745, val_acc=0.3642\n",
      "Epoch 47: train_loss=1.7700, train_acc=0.3720, val_loss=1.7755, val_acc=0.3724\n",
      "Epoch 48: train_loss=1.7677, train_acc=0.3726, val_loss=1.7329, val_acc=0.3782\n",
      "Epoch 49: train_loss=1.7625, train_acc=0.3781, val_loss=1.7270, val_acc=0.3762\n",
      "Epoch 50: train_loss=1.7619, train_acc=0.3798, val_loss=1.7132, val_acc=0.3866\n",
      "Epoch 51: train_loss=1.7573, train_acc=0.3812, val_loss=1.7300, val_acc=0.3858\n",
      "Epoch 52: train_loss=1.7574, train_acc=0.3768, val_loss=1.7031, val_acc=0.3956\n",
      "Epoch 53: train_loss=1.7496, train_acc=0.3799, val_loss=1.7442, val_acc=0.3738\n",
      "Epoch 54: train_loss=1.7481, train_acc=0.3813, val_loss=1.7156, val_acc=0.3912\n",
      "Epoch 55: train_loss=1.7470, train_acc=0.3815, val_loss=1.7167, val_acc=0.3872\n",
      "Epoch 56: train_loss=1.7460, train_acc=0.3820, val_loss=1.7451, val_acc=0.3712\n",
      "Epoch 57: train_loss=1.7393, train_acc=0.3839, val_loss=1.6963, val_acc=0.3972\n",
      "Epoch 58: train_loss=1.7357, train_acc=0.3886, val_loss=1.6970, val_acc=0.3968\n",
      "Epoch 59: train_loss=1.7337, train_acc=0.3888, val_loss=1.6937, val_acc=0.4024\n",
      "Epoch 60: train_loss=1.7311, train_acc=0.3906, val_loss=1.6824, val_acc=0.4098\n",
      "Epoch 61: train_loss=1.7277, train_acc=0.3919, val_loss=1.7006, val_acc=0.4070\n",
      "Epoch 62: train_loss=1.7289, train_acc=0.3919, val_loss=1.7795, val_acc=0.3694\n",
      "Epoch 63: train_loss=1.7243, train_acc=0.3900, val_loss=1.7439, val_acc=0.3812\n",
      "Epoch 64: train_loss=1.7201, train_acc=0.3903, val_loss=1.6727, val_acc=0.4070\n",
      "Epoch 65: train_loss=1.7197, train_acc=0.3919, val_loss=1.6666, val_acc=0.4096\n",
      "Epoch 66: train_loss=1.7134, train_acc=0.3942, val_loss=1.6727, val_acc=0.4060\n",
      "Epoch 67: train_loss=1.7104, train_acc=0.3969, val_loss=1.6877, val_acc=0.4058\n",
      "Epoch 68: train_loss=1.7099, train_acc=0.3959, val_loss=1.6810, val_acc=0.3988\n",
      "Epoch 69: train_loss=1.7049, train_acc=0.3989, val_loss=1.6765, val_acc=0.3986\n",
      "Epoch 70: train_loss=1.7064, train_acc=0.3988, val_loss=1.6525, val_acc=0.4078\n",
      "Epoch 71: train_loss=1.7016, train_acc=0.3995, val_loss=1.6609, val_acc=0.4172\n",
      "Epoch 72: train_loss=1.6992, train_acc=0.3999, val_loss=1.6615, val_acc=0.4148\n",
      "Epoch 73: train_loss=1.6973, train_acc=0.4012, val_loss=1.6738, val_acc=0.4094\n",
      "Epoch 74: train_loss=1.6956, train_acc=0.4009, val_loss=1.6577, val_acc=0.4118\n",
      "Epoch 75: train_loss=1.6917, train_acc=0.4024, val_loss=1.7270, val_acc=0.3954\n",
      "Epoch 76: train_loss=1.6906, train_acc=0.4033, val_loss=1.6710, val_acc=0.4008\n",
      "Epoch 77: train_loss=1.6870, train_acc=0.4072, val_loss=1.6614, val_acc=0.4102\n",
      "Epoch 78: train_loss=1.6825, train_acc=0.4047, val_loss=1.6536, val_acc=0.4034\n",
      "Epoch 79: train_loss=1.6828, train_acc=0.4067, val_loss=1.6341, val_acc=0.4202\n",
      "Epoch 80: train_loss=1.6806, train_acc=0.4073, val_loss=1.6767, val_acc=0.4020\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>l2_loss</td><td>0.00255</td></tr><tr><td>train_acc</td><td>0.40727</td></tr><tr><td>train_loss</td><td>1.6806</td></tr><tr><td>val_acc</td><td>0.402</td></tr><tr><td>val_loss</td><td>1.6767</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">devoted-sweep-8</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aylfnilq' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/aylfnilq</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_223725-aylfnilq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fz7zu9qg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08300586681098852\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_225017-fz7zu9qg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/fz7zu9qg' target=\"_blank\">glorious-sweep-9</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/fz7zu9qg' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/fz7zu9qg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.3227, train_acc=0.1192, val_loss=2.2485, val_acc=0.1804\n",
      "Epoch 2: train_loss=2.2739, train_acc=0.1470, val_loss=2.2005, val_acc=0.2166\n",
      "Epoch 3: train_loss=2.2299, train_acc=0.1756, val_loss=2.1599, val_acc=0.2450\n",
      "Epoch 4: train_loss=2.1934, train_acc=0.1959, val_loss=2.1250, val_acc=0.2650\n",
      "Epoch 5: train_loss=2.1569, train_acc=0.2153, val_loss=2.0956, val_acc=0.2692\n",
      "Epoch 6: train_loss=2.1297, train_acc=0.2260, val_loss=2.0699, val_acc=0.2758\n",
      "Epoch 7: train_loss=2.1040, train_acc=0.2417, val_loss=2.0476, val_acc=0.2882\n",
      "Epoch 8: train_loss=2.0843, train_acc=0.2497, val_loss=2.0286, val_acc=0.2926\n",
      "Epoch 9: train_loss=2.0635, train_acc=0.2580, val_loss=2.0111, val_acc=0.2988\n",
      "Epoch 10: train_loss=2.0478, train_acc=0.2668, val_loss=1.9954, val_acc=0.3040\n",
      "Epoch 11: train_loss=2.0329, train_acc=0.2728, val_loss=1.9814, val_acc=0.3074\n",
      "Epoch 12: train_loss=2.0181, train_acc=0.2795, val_loss=1.9702, val_acc=0.3090\n",
      "Epoch 13: train_loss=2.0034, train_acc=0.2852, val_loss=1.9581, val_acc=0.3184\n",
      "Epoch 14: train_loss=1.9925, train_acc=0.2905, val_loss=1.9474, val_acc=0.3190\n",
      "Epoch 15: train_loss=1.9815, train_acc=0.2931, val_loss=1.9387, val_acc=0.3224\n",
      "Epoch 16: train_loss=1.9718, train_acc=0.3003, val_loss=1.9299, val_acc=0.3254\n",
      "Epoch 17: train_loss=1.9621, train_acc=0.3033, val_loss=1.9223, val_acc=0.3266\n",
      "Epoch 18: train_loss=1.9561, train_acc=0.3025, val_loss=1.9153, val_acc=0.3332\n",
      "Epoch 19: train_loss=1.9468, train_acc=0.3096, val_loss=1.9102, val_acc=0.3304\n",
      "Epoch 20: train_loss=1.9398, train_acc=0.3118, val_loss=1.9021, val_acc=0.3286\n",
      "Epoch 21: train_loss=1.9344, train_acc=0.3139, val_loss=1.8964, val_acc=0.3370\n",
      "Epoch 22: train_loss=1.9276, train_acc=0.3179, val_loss=1.8916, val_acc=0.3368\n",
      "Epoch 23: train_loss=1.9256, train_acc=0.3180, val_loss=1.8867, val_acc=0.3396\n",
      "Epoch 24: train_loss=1.9176, train_acc=0.3219, val_loss=1.8818, val_acc=0.3394\n",
      "Epoch 25: train_loss=1.9146, train_acc=0.3228, val_loss=1.8771, val_acc=0.3414\n",
      "Epoch 26: train_loss=1.9086, train_acc=0.3244, val_loss=1.8731, val_acc=0.3432\n",
      "Epoch 27: train_loss=1.9028, train_acc=0.3278, val_loss=1.8697, val_acc=0.3434\n",
      "Epoch 28: train_loss=1.9003, train_acc=0.3280, val_loss=1.8655, val_acc=0.3440\n",
      "Epoch 29: train_loss=1.8953, train_acc=0.3334, val_loss=1.8632, val_acc=0.3422\n",
      "Epoch 30: train_loss=1.8918, train_acc=0.3316, val_loss=1.8588, val_acc=0.3452\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>l2_loss</td><td>0.00063</td></tr><tr><td>train_acc</td><td>0.33157</td></tr><tr><td>train_loss</td><td>1.89182</td></tr><tr><td>val_acc</td><td>0.3452</td></tr><tr><td>val_loss</td><td>1.85883</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">glorious-sweep-9</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/fz7zu9qg' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/fz7zu9qg</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_225017-fz7zu9qg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: joyskwq3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.03595133413350204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_225923-joyskwq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/joyskwq3' target=\"_blank\">gentle-sweep-10</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/joyskwq3' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/joyskwq3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.6247, train_acc=0.1006, val_loss=2.3045, val_acc=0.0980\n",
      "Epoch 2: train_loss=2.3112, train_acc=0.0997, val_loss=2.3048, val_acc=0.0990\n",
      "Epoch 3: train_loss=2.3113, train_acc=0.0989, val_loss=2.3036, val_acc=0.0974\n",
      "Epoch 4: train_loss=2.3114, train_acc=0.1005, val_loss=2.3042, val_acc=0.1066\n",
      "Epoch 5: train_loss=2.3114, train_acc=0.1005, val_loss=2.3044, val_acc=0.0988\n",
      "Epoch 6: train_loss=2.3115, train_acc=0.1006, val_loss=2.3047, val_acc=0.0974\n",
      "Epoch 7: train_loss=2.3115, train_acc=0.1007, val_loss=2.3040, val_acc=0.0990\n",
      "Epoch 8: train_loss=2.3115, train_acc=0.0993, val_loss=2.3041, val_acc=0.0988\n",
      "Epoch 9: train_loss=2.3115, train_acc=0.0996, val_loss=2.3059, val_acc=0.0984\n",
      "Epoch 10: train_loss=2.3116, train_acc=0.0982, val_loss=2.3043, val_acc=0.0990\n",
      "Epoch 11: train_loss=2.3117, train_acc=0.0967, val_loss=2.3046, val_acc=0.0998\n",
      "Epoch 12: train_loss=2.3115, train_acc=0.0989, val_loss=2.3030, val_acc=0.1000\n",
      "Epoch 13: train_loss=2.3118, train_acc=0.0972, val_loss=2.3083, val_acc=0.0984\n",
      "Epoch 14: train_loss=2.3118, train_acc=0.0981, val_loss=2.3053, val_acc=0.0984\n",
      "Epoch 15: train_loss=2.3117, train_acc=0.0989, val_loss=2.3057, val_acc=0.0998\n",
      "Epoch 16: train_loss=2.3114, train_acc=0.1011, val_loss=2.3051, val_acc=0.0990\n",
      "Epoch 17: train_loss=2.3116, train_acc=0.0995, val_loss=2.3033, val_acc=0.0990\n",
      "Epoch 18: train_loss=2.3115, train_acc=0.0991, val_loss=2.3042, val_acc=0.0980\n",
      "Epoch 19: train_loss=2.3117, train_acc=0.0993, val_loss=2.3047, val_acc=0.0998\n",
      "Epoch 20: train_loss=2.3116, train_acc=0.0997, val_loss=2.3067, val_acc=0.1000\n",
      "Epoch 21: train_loss=2.3119, train_acc=0.1007, val_loss=2.3040, val_acc=0.1000\n",
      "Epoch 22: train_loss=2.3116, train_acc=0.1005, val_loss=2.3052, val_acc=0.0998\n",
      "Epoch 23: train_loss=2.3115, train_acc=0.0982, val_loss=2.3060, val_acc=0.0980\n",
      "Epoch 24: train_loss=2.3117, train_acc=0.0987, val_loss=2.3050, val_acc=0.0974\n",
      "Epoch 25: train_loss=2.3115, train_acc=0.0984, val_loss=2.3048, val_acc=0.1028\n",
      "Epoch 26: train_loss=2.3117, train_acc=0.1008, val_loss=2.3052, val_acc=0.0980\n",
      "Epoch 27: train_loss=2.3118, train_acc=0.0983, val_loss=2.3042, val_acc=0.0984\n",
      "Epoch 28: train_loss=2.3113, train_acc=0.1002, val_loss=2.3039, val_acc=0.0984\n",
      "Epoch 29: train_loss=2.3120, train_acc=0.0972, val_loss=2.3046, val_acc=0.0984\n",
      "Epoch 30: train_loss=2.3117, train_acc=0.0977, val_loss=2.3044, val_acc=0.0980\n",
      "Epoch 31: train_loss=2.3119, train_acc=0.0997, val_loss=2.3048, val_acc=0.1000\n",
      "Epoch 32: train_loss=2.3116, train_acc=0.1030, val_loss=2.3042, val_acc=0.0988\n",
      "Epoch 33: train_loss=2.3117, train_acc=0.1022, val_loss=2.3040, val_acc=0.1000\n",
      "Epoch 34: train_loss=2.3109, train_acc=0.1029, val_loss=2.3045, val_acc=0.0990\n",
      "Epoch 35: train_loss=2.3113, train_acc=0.1023, val_loss=2.3074, val_acc=0.0984\n",
      "Epoch 36: train_loss=2.3120, train_acc=0.1003, val_loss=2.3038, val_acc=0.0980\n",
      "Epoch 37: train_loss=2.3115, train_acc=0.1006, val_loss=2.3040, val_acc=0.0998\n",
      "Epoch 38: train_loss=2.3116, train_acc=0.0988, val_loss=2.3059, val_acc=0.0980\n",
      "Epoch 39: train_loss=2.3112, train_acc=0.1005, val_loss=2.3052, val_acc=0.0974\n",
      "Epoch 40: train_loss=2.3115, train_acc=0.1000, val_loss=2.3055, val_acc=0.0998\n",
      "Epoch 41: train_loss=2.3117, train_acc=0.0984, val_loss=2.3047, val_acc=0.1066\n",
      "Epoch 42: train_loss=2.3117, train_acc=0.1023, val_loss=2.3052, val_acc=0.0998\n",
      "Epoch 43: train_loss=2.3112, train_acc=0.1005, val_loss=2.3033, val_acc=0.1066\n",
      "Epoch 44: train_loss=2.3121, train_acc=0.0984, val_loss=2.3059, val_acc=0.0980\n",
      "Epoch 45: train_loss=2.3116, train_acc=0.0970, val_loss=2.3037, val_acc=0.1066\n",
      "Epoch 46: train_loss=2.3115, train_acc=0.1002, val_loss=2.3045, val_acc=0.1066\n",
      "Epoch 47: train_loss=2.3113, train_acc=0.1008, val_loss=2.3046, val_acc=0.0984\n",
      "Epoch 48: train_loss=2.3115, train_acc=0.0997, val_loss=2.3057, val_acc=0.0974\n",
      "Epoch 49: train_loss=2.3115, train_acc=0.0996, val_loss=2.3034, val_acc=0.0980\n",
      "Epoch 50: train_loss=2.3113, train_acc=0.1023, val_loss=2.3050, val_acc=0.0974\n",
      "Epoch 51: train_loss=2.3112, train_acc=0.1026, val_loss=2.3071, val_acc=0.0984\n",
      "Epoch 52: train_loss=2.3112, train_acc=0.1025, val_loss=2.3073, val_acc=0.0984\n",
      "Epoch 53: train_loss=2.3114, train_acc=0.1014, val_loss=2.3050, val_acc=0.0998\n",
      "Epoch 54: train_loss=2.3114, train_acc=0.1025, val_loss=2.3055, val_acc=0.0980\n",
      "Epoch 55: train_loss=2.3120, train_acc=0.0992, val_loss=2.3032, val_acc=0.1028\n",
      "Epoch 56: train_loss=2.3114, train_acc=0.1005, val_loss=2.3050, val_acc=0.0998\n",
      "Epoch 57: train_loss=2.3120, train_acc=0.0983, val_loss=2.3067, val_acc=0.0990\n",
      "Epoch 58: train_loss=2.3116, train_acc=0.1003, val_loss=2.3076, val_acc=0.0990\n",
      "Epoch 59: train_loss=2.3116, train_acc=0.1006, val_loss=2.3051, val_acc=0.1066\n",
      "Epoch 60: train_loss=2.3113, train_acc=0.0986, val_loss=2.3064, val_acc=0.0984\n",
      "Epoch 61: train_loss=2.3118, train_acc=0.0973, val_loss=2.3049, val_acc=0.0990\n",
      "Epoch 62: train_loss=2.3113, train_acc=0.1016, val_loss=2.3058, val_acc=0.1028\n",
      "Epoch 63: train_loss=2.3115, train_acc=0.1003, val_loss=2.3074, val_acc=0.0988\n",
      "Epoch 64: train_loss=2.3117, train_acc=0.1002, val_loss=2.3037, val_acc=0.1066\n",
      "Epoch 65: train_loss=2.3116, train_acc=0.0988, val_loss=2.3043, val_acc=0.0990\n",
      "Epoch 66: train_loss=2.3111, train_acc=0.1005, val_loss=2.3046, val_acc=0.1028\n",
      "Epoch 67: train_loss=2.3111, train_acc=0.0985, val_loss=2.3063, val_acc=0.0990\n",
      "Epoch 68: train_loss=2.3117, train_acc=0.1016, val_loss=2.3038, val_acc=0.1066\n",
      "Epoch 69: train_loss=2.3114, train_acc=0.1004, val_loss=2.3057, val_acc=0.0980\n",
      "Epoch 70: train_loss=2.3119, train_acc=0.1007, val_loss=2.3056, val_acc=0.0988\n",
      "Epoch 71: train_loss=2.3119, train_acc=0.0989, val_loss=2.3056, val_acc=0.0984\n",
      "Epoch 72: train_loss=2.3113, train_acc=0.1009, val_loss=2.3052, val_acc=0.0974\n",
      "Epoch 73: train_loss=2.3117, train_acc=0.1003, val_loss=2.3047, val_acc=0.1000\n",
      "Epoch 74: train_loss=2.3111, train_acc=0.1013, val_loss=2.3052, val_acc=0.1000\n",
      "Epoch 75: train_loss=2.3117, train_acc=0.1013, val_loss=2.3047, val_acc=0.0974\n",
      "Epoch 76: train_loss=2.3119, train_acc=0.0990, val_loss=2.3038, val_acc=0.0984\n",
      "Epoch 77: train_loss=2.3114, train_acc=0.0971, val_loss=2.3044, val_acc=0.0990\n",
      "Epoch 78: train_loss=2.3114, train_acc=0.0979, val_loss=2.3037, val_acc=0.0974\n",
      "Epoch 79: train_loss=2.3114, train_acc=0.0994, val_loss=2.3046, val_acc=0.0984\n",
      "Epoch 80: train_loss=2.3118, train_acc=0.0974, val_loss=2.3039, val_acc=0.0988\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.09745</td></tr><tr><td>train_loss</td><td>2.31175</td></tr><tr><td>val_acc</td><td>0.0988</td></tr><tr><td>val_loss</td><td>2.30391</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">gentle-sweep-10</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/joyskwq3' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/joyskwq3</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_225923-joyskwq3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l9p81mqb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.018919180797206215\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_233208-l9p81mqb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/l9p81mqb' target=\"_blank\">fast-sweep-11</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/l9p81mqb' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/l9p81mqb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.4099, train_acc=0.1892, val_loss=2.0050, val_acc=0.2942\n",
      "Epoch 2: train_loss=2.2330, train_acc=0.2564, val_loss=1.9192, val_acc=0.3224\n",
      "Epoch 3: train_loss=2.1548, train_acc=0.2879, val_loss=1.8783, val_acc=0.3332\n",
      "Epoch 4: train_loss=2.1010, train_acc=0.3073, val_loss=1.8323, val_acc=0.3470\n",
      "Epoch 5: train_loss=2.0549, train_acc=0.3215, val_loss=1.8057, val_acc=0.3568\n",
      "Epoch 6: train_loss=2.0226, train_acc=0.3349, val_loss=1.7914, val_acc=0.3624\n",
      "Epoch 7: train_loss=1.9983, train_acc=0.3411, val_loss=1.7699, val_acc=0.3710\n",
      "Epoch 8: train_loss=1.9682, train_acc=0.3530, val_loss=1.7499, val_acc=0.3704\n",
      "Epoch 9: train_loss=1.9463, train_acc=0.3583, val_loss=1.7380, val_acc=0.3806\n",
      "Epoch 10: train_loss=1.9239, train_acc=0.3635, val_loss=1.7234, val_acc=0.3846\n",
      "Epoch 11: train_loss=1.9062, train_acc=0.3696, val_loss=1.7114, val_acc=0.3892\n",
      "Epoch 12: train_loss=1.8917, train_acc=0.3722, val_loss=1.6998, val_acc=0.3932\n",
      "Epoch 13: train_loss=1.8700, train_acc=0.3770, val_loss=1.6921, val_acc=0.3978\n",
      "Epoch 14: train_loss=1.8564, train_acc=0.3836, val_loss=1.7071, val_acc=0.3924\n",
      "Epoch 15: train_loss=1.8537, train_acc=0.3834, val_loss=1.6763, val_acc=0.4006\n",
      "Epoch 16: train_loss=1.8309, train_acc=0.3888, val_loss=1.6706, val_acc=0.4020\n",
      "Epoch 17: train_loss=1.8178, train_acc=0.3946, val_loss=1.6615, val_acc=0.4070\n",
      "Epoch 18: train_loss=1.8045, train_acc=0.3938, val_loss=1.6549, val_acc=0.4132\n",
      "Epoch 19: train_loss=1.8001, train_acc=0.3947, val_loss=1.6536, val_acc=0.4080\n",
      "Epoch 20: train_loss=1.7844, train_acc=0.4014, val_loss=1.6461, val_acc=0.4118\n",
      "Epoch 21: train_loss=1.7766, train_acc=0.4004, val_loss=1.6404, val_acc=0.4146\n",
      "Epoch 22: train_loss=1.7683, train_acc=0.4034, val_loss=1.6465, val_acc=0.4110\n",
      "Epoch 23: train_loss=1.7595, train_acc=0.4048, val_loss=1.6493, val_acc=0.4080\n",
      "Epoch 24: train_loss=1.7496, train_acc=0.4077, val_loss=1.6314, val_acc=0.4190\n",
      "Epoch 25: train_loss=1.7401, train_acc=0.4101, val_loss=1.6413, val_acc=0.4106\n",
      "Epoch 26: train_loss=1.7378, train_acc=0.4088, val_loss=1.6415, val_acc=0.4144\n",
      "Epoch 27: train_loss=1.7361, train_acc=0.4102, val_loss=1.6208, val_acc=0.4182\n",
      "Epoch 28: train_loss=1.7190, train_acc=0.4152, val_loss=1.6131, val_acc=0.4246\n",
      "Epoch 29: train_loss=1.7125, train_acc=0.4152, val_loss=1.6168, val_acc=0.4190\n",
      "Epoch 30: train_loss=1.7093, train_acc=0.4171, val_loss=1.6248, val_acc=0.4210\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>l2_loss</td><td>0.47068</td></tr><tr><td>train_acc</td><td>0.41707</td></tr><tr><td>train_loss</td><td>1.70927</td></tr><tr><td>val_acc</td><td>0.421</td></tr><tr><td>val_loss</td><td>1.62484</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fast-sweep-11</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/l9p81mqb' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/l9p81mqb</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_233208-l9p81mqb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gr4ehrkg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.057521215443739025\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251109_234838-gr4ehrkg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gr4ehrkg' target=\"_blank\">classic-sweep-12</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gr4ehrkg' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gr4ehrkg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.9382, train_acc=0.3031, val_loss=1.7418, val_acc=0.3722\n",
      "Epoch 2: train_loss=1.7536, train_acc=0.3758, val_loss=1.6388, val_acc=0.4132\n",
      "Epoch 3: train_loss=1.6785, train_acc=0.4008, val_loss=1.6359, val_acc=0.4068\n",
      "Epoch 4: train_loss=1.6312, train_acc=0.4209, val_loss=1.6116, val_acc=0.4204\n",
      "Epoch 5: train_loss=1.5936, train_acc=0.4307, val_loss=1.5609, val_acc=0.4366\n",
      "Epoch 6: train_loss=1.5584, train_acc=0.4450, val_loss=1.5398, val_acc=0.4450\n",
      "Epoch 7: train_loss=1.5393, train_acc=0.4509, val_loss=1.5038, val_acc=0.4590\n",
      "Epoch 8: train_loss=1.5149, train_acc=0.4625, val_loss=1.5036, val_acc=0.4512\n",
      "Epoch 9: train_loss=1.4930, train_acc=0.4705, val_loss=1.4905, val_acc=0.4638\n",
      "Epoch 10: train_loss=1.4778, train_acc=0.4748, val_loss=1.5097, val_acc=0.4536\n",
      "Epoch 11: train_loss=1.4559, train_acc=0.4823, val_loss=1.4862, val_acc=0.4702\n",
      "Epoch 12: train_loss=1.4454, train_acc=0.4864, val_loss=1.4370, val_acc=0.4914\n",
      "Epoch 13: train_loss=1.4260, train_acc=0.4926, val_loss=1.4113, val_acc=0.4994\n",
      "Epoch 14: train_loss=1.4147, train_acc=0.4991, val_loss=1.4235, val_acc=0.4890\n",
      "Epoch 15: train_loss=1.3986, train_acc=0.5047, val_loss=1.4347, val_acc=0.4916\n",
      "Epoch 16: train_loss=1.3901, train_acc=0.5056, val_loss=1.4278, val_acc=0.4888\n",
      "Epoch 17: train_loss=1.3780, train_acc=0.5091, val_loss=1.4379, val_acc=0.4960\n",
      "Epoch 18: train_loss=1.3645, train_acc=0.5140, val_loss=1.4060, val_acc=0.5006\n",
      "Epoch 19: train_loss=1.3525, train_acc=0.5194, val_loss=1.3787, val_acc=0.5114\n",
      "Epoch 20: train_loss=1.3361, train_acc=0.5251, val_loss=1.4746, val_acc=0.4800\n",
      "Epoch 21: train_loss=1.3349, train_acc=0.5273, val_loss=1.4278, val_acc=0.4924\n",
      "Epoch 22: train_loss=1.3309, train_acc=0.5241, val_loss=1.3686, val_acc=0.5114\n",
      "Epoch 23: train_loss=1.3082, train_acc=0.5363, val_loss=1.4007, val_acc=0.5066\n",
      "Epoch 24: train_loss=1.3021, train_acc=0.5365, val_loss=1.3697, val_acc=0.5140\n",
      "Epoch 25: train_loss=1.2947, train_acc=0.5405, val_loss=1.3757, val_acc=0.5144\n",
      "Epoch 26: train_loss=1.2769, train_acc=0.5463, val_loss=1.4042, val_acc=0.5064\n",
      "Epoch 27: train_loss=1.2766, train_acc=0.5453, val_loss=1.3826, val_acc=0.5156\n",
      "Epoch 28: train_loss=1.2616, train_acc=0.5529, val_loss=1.3484, val_acc=0.5248\n",
      "Epoch 29: train_loss=1.2575, train_acc=0.5533, val_loss=1.3567, val_acc=0.5208\n",
      "Epoch 30: train_loss=1.2430, train_acc=0.5584, val_loss=1.3245, val_acc=0.5322\n",
      "Epoch 31: train_loss=1.2376, train_acc=0.5605, val_loss=1.3732, val_acc=0.5228\n",
      "Epoch 32: train_loss=1.2283, train_acc=0.5628, val_loss=1.3293, val_acc=0.5394\n",
      "Epoch 33: train_loss=1.2218, train_acc=0.5655, val_loss=1.3451, val_acc=0.5272\n",
      "Epoch 34: train_loss=1.2114, train_acc=0.5702, val_loss=1.3463, val_acc=0.5240\n",
      "Epoch 35: train_loss=1.2010, train_acc=0.5726, val_loss=1.3554, val_acc=0.5286\n",
      "Epoch 36: train_loss=1.1970, train_acc=0.5741, val_loss=1.3363, val_acc=0.5312\n",
      "Epoch 37: train_loss=1.1873, train_acc=0.5796, val_loss=1.3685, val_acc=0.5220\n",
      "Epoch 38: train_loss=1.1858, train_acc=0.5792, val_loss=1.3409, val_acc=0.5268\n",
      "Epoch 39: train_loss=1.1718, train_acc=0.5833, val_loss=1.3193, val_acc=0.5352\n",
      "Epoch 40: train_loss=1.1603, train_acc=0.5880, val_loss=1.3491, val_acc=0.5262\n",
      "Epoch 41: train_loss=1.1606, train_acc=0.5889, val_loss=1.3209, val_acc=0.5326\n",
      "Epoch 42: train_loss=1.1507, train_acc=0.5911, val_loss=1.3765, val_acc=0.5234\n",
      "Epoch 43: train_loss=1.1410, train_acc=0.5949, val_loss=1.3336, val_acc=0.5320\n",
      "Epoch 44: train_loss=1.1352, train_acc=0.5975, val_loss=1.3278, val_acc=0.5392\n",
      "Epoch 45: train_loss=1.1313, train_acc=0.5991, val_loss=1.3225, val_acc=0.5380\n",
      "Epoch 46: train_loss=1.1222, train_acc=0.6021, val_loss=1.3537, val_acc=0.5292\n",
      "Epoch 47: train_loss=1.1153, train_acc=0.6025, val_loss=1.3034, val_acc=0.5438\n",
      "Epoch 48: train_loss=1.1085, train_acc=0.6062, val_loss=1.2951, val_acc=0.5494\n",
      "Epoch 49: train_loss=1.1024, train_acc=0.6087, val_loss=1.3224, val_acc=0.5432\n",
      "Epoch 50: train_loss=1.0912, train_acc=0.6126, val_loss=1.3384, val_acc=0.5356\n",
      "Epoch 51: train_loss=1.0914, train_acc=0.6110, val_loss=1.3262, val_acc=0.5386\n",
      "Epoch 52: train_loss=1.0793, train_acc=0.6172, val_loss=1.3288, val_acc=0.5440\n",
      "Epoch 53: train_loss=1.0738, train_acc=0.6183, val_loss=1.3055, val_acc=0.5500\n",
      "Epoch 54: train_loss=1.0679, train_acc=0.6202, val_loss=1.3183, val_acc=0.5478\n",
      "Epoch 55: train_loss=1.0646, train_acc=0.6210, val_loss=1.3631, val_acc=0.5406\n",
      "Epoch 56: train_loss=1.0555, train_acc=0.6272, val_loss=1.3120, val_acc=0.5512\n",
      "Epoch 57: train_loss=1.0483, train_acc=0.6266, val_loss=1.3511, val_acc=0.5338\n",
      "Epoch 58: train_loss=1.0456, train_acc=0.6296, val_loss=1.3220, val_acc=0.5404\n",
      "Epoch 59: train_loss=1.0376, train_acc=0.6328, val_loss=1.3511, val_acc=0.5378\n",
      "Epoch 60: train_loss=1.0255, train_acc=0.6382, val_loss=1.3078, val_acc=0.5482\n",
      "Epoch 61: train_loss=1.0259, train_acc=0.6345, val_loss=1.3125, val_acc=0.5486\n",
      "Epoch 62: train_loss=1.0163, train_acc=0.6364, val_loss=1.3389, val_acc=0.5444\n",
      "Epoch 63: train_loss=1.0092, train_acc=0.6399, val_loss=1.3234, val_acc=0.5446\n",
      "Epoch 64: train_loss=1.0067, train_acc=0.6414, val_loss=1.3301, val_acc=0.5502\n",
      "Epoch 65: train_loss=1.0003, train_acc=0.6436, val_loss=1.3292, val_acc=0.5514\n",
      "Epoch 66: train_loss=0.9901, train_acc=0.6472, val_loss=1.3443, val_acc=0.5478\n",
      "Epoch 67: train_loss=0.9862, train_acc=0.6477, val_loss=1.3385, val_acc=0.5464\n",
      "Epoch 68: train_loss=0.9835, train_acc=0.6513, val_loss=1.3688, val_acc=0.5436\n",
      "Epoch 69: train_loss=0.9727, train_acc=0.6522, val_loss=1.3649, val_acc=0.5376\n",
      "Epoch 70: train_loss=0.9710, train_acc=0.6519, val_loss=1.3263, val_acc=0.5502\n",
      "Epoch 71: train_loss=0.9625, train_acc=0.6590, val_loss=1.3954, val_acc=0.5356\n",
      "Epoch 72: train_loss=0.9631, train_acc=0.6583, val_loss=1.3193, val_acc=0.5546\n",
      "Epoch 73: train_loss=0.9497, train_acc=0.6636, val_loss=1.3488, val_acc=0.5480\n",
      "Epoch 74: train_loss=0.9496, train_acc=0.6647, val_loss=1.3428, val_acc=0.5528\n",
      "Epoch 75: train_loss=0.9408, train_acc=0.6667, val_loss=1.3359, val_acc=0.5574\n",
      "Epoch 76: train_loss=0.9330, train_acc=0.6700, val_loss=1.3751, val_acc=0.5408\n",
      "Epoch 77: train_loss=0.9306, train_acc=0.6684, val_loss=1.3349, val_acc=0.5518\n",
      "Epoch 78: train_loss=0.9225, train_acc=0.6723, val_loss=1.3694, val_acc=0.5436\n",
      "Epoch 79: train_loss=0.9211, train_acc=0.6732, val_loss=1.3516, val_acc=0.5402\n",
      "Epoch 80: train_loss=0.9152, train_acc=0.6755, val_loss=1.3494, val_acc=0.5488\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.67552</td></tr><tr><td>train_loss</td><td>0.91521</td></tr><tr><td>val_acc</td><td>0.5488</td></tr><tr><td>val_loss</td><td>1.34943</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-sweep-12</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gr4ehrkg' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/gr4ehrkg</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251109_234838-gr4ehrkg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ar3by61z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01976164198165978\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_003912-ar3by61z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/ar3by61z' target=\"_blank\">dulcet-sweep-13</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/ar3by61z' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/ar3by61z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.4822, train_acc=0.0982, val_loss=4.8542, val_acc=0.0998\n",
      "Epoch 2: train_loss=2.4971, train_acc=0.0988, val_loss=3.1946, val_acc=0.0990\n",
      "Epoch 3: train_loss=2.4908, train_acc=0.1006, val_loss=5.9782, val_acc=0.0974\n",
      "Epoch 4: train_loss=2.5661, train_acc=0.1006, val_loss=6.0185, val_acc=0.1066\n",
      "Epoch 5: train_loss=2.5640, train_acc=0.0994, val_loss=4.0764, val_acc=0.0998\n",
      "Epoch 6: train_loss=2.5470, train_acc=0.1006, val_loss=7.1485, val_acc=0.0998\n",
      "Epoch 7: train_loss=2.5937, train_acc=0.1015, val_loss=4.8002, val_acc=0.0990\n",
      "Epoch 8: train_loss=2.5618, train_acc=0.1003, val_loss=5.7253, val_acc=0.0990\n",
      "Epoch 9: train_loss=2.6399, train_acc=0.1010, val_loss=6.7525, val_acc=0.0974\n",
      "Epoch 10: train_loss=2.6504, train_acc=0.1010, val_loss=3.8519, val_acc=0.0980\n",
      "Epoch 11: train_loss=2.5336, train_acc=0.0997, val_loss=5.7907, val_acc=0.0990\n",
      "Epoch 12: train_loss=2.5840, train_acc=0.0997, val_loss=4.4822, val_acc=0.0984\n",
      "Epoch 13: train_loss=2.5163, train_acc=0.0999, val_loss=6.1145, val_acc=0.0998\n",
      "Epoch 14: train_loss=2.5593, train_acc=0.1012, val_loss=4.2055, val_acc=0.0998\n",
      "Epoch 15: train_loss=2.5600, train_acc=0.0981, val_loss=3.3886, val_acc=0.0998\n",
      "Epoch 16: train_loss=2.5671, train_acc=0.1010, val_loss=5.2720, val_acc=0.0984\n",
      "Epoch 17: train_loss=2.6371, train_acc=0.1011, val_loss=6.0067, val_acc=0.0990\n",
      "Epoch 18: train_loss=2.5877, train_acc=0.0970, val_loss=6.0852, val_acc=0.0990\n",
      "Epoch 19: train_loss=2.6540, train_acc=0.0990, val_loss=3.9530, val_acc=0.0998\n",
      "Epoch 20: train_loss=2.5477, train_acc=0.0986, val_loss=5.1660, val_acc=0.0974\n",
      "Epoch 21: train_loss=2.5921, train_acc=0.1002, val_loss=6.1468, val_acc=0.0980\n",
      "Epoch 22: train_loss=2.5759, train_acc=0.1024, val_loss=3.9806, val_acc=0.0998\n",
      "Epoch 23: train_loss=2.5343, train_acc=0.0984, val_loss=5.4592, val_acc=0.0998\n",
      "Epoch 24: train_loss=2.5506, train_acc=0.1000, val_loss=4.9878, val_acc=0.1028\n",
      "Epoch 25: train_loss=2.5685, train_acc=0.1004, val_loss=3.8993, val_acc=0.1028\n",
      "Epoch 26: train_loss=2.5283, train_acc=0.1000, val_loss=4.2536, val_acc=0.1000\n",
      "Epoch 27: train_loss=2.5319, train_acc=0.1017, val_loss=6.4571, val_acc=0.1066\n",
      "Epoch 28: train_loss=2.6403, train_acc=0.0993, val_loss=4.1385, val_acc=0.1000\n",
      "Epoch 29: train_loss=2.5569, train_acc=0.0996, val_loss=5.9189, val_acc=0.0984\n",
      "Epoch 30: train_loss=2.5961, train_acc=0.1006, val_loss=4.9549, val_acc=0.1028\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>l2_loss</td><td>0.00708</td></tr><tr><td>train_acc</td><td>0.10055</td></tr><tr><td>train_loss</td><td>2.59606</td></tr><tr><td>val_acc</td><td>0.1028</td></tr><tr><td>val_loss</td><td>4.95491</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dulcet-sweep-13</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/ar3by61z' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/ar3by61z</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_003912-ar3by61z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: neyhofip with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0918068463986629\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_005116-neyhofip</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/neyhofip' target=\"_blank\">dark-sweep-14</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/neyhofip' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/neyhofip</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.1479, train_acc=0.2888, val_loss=1.9817, val_acc=0.2572\n",
      "Epoch 2: train_loss=2.0074, train_acc=0.3367, val_loss=1.7940, val_acc=0.3476\n",
      "Epoch 3: train_loss=1.8818, train_acc=0.3737, val_loss=1.7940, val_acc=0.3460\n",
      "Epoch 4: train_loss=1.8370, train_acc=0.3819, val_loss=1.9816, val_acc=0.2804\n",
      "Epoch 5: train_loss=1.8322, train_acc=0.3798, val_loss=1.7157, val_acc=0.3916\n",
      "Epoch 6: train_loss=1.7590, train_acc=0.4005, val_loss=1.7112, val_acc=0.3664\n",
      "Epoch 7: train_loss=1.7305, train_acc=0.4066, val_loss=1.6982, val_acc=0.3832\n",
      "Epoch 8: train_loss=1.7034, train_acc=0.4135, val_loss=1.7443, val_acc=0.3616\n",
      "Epoch 9: train_loss=1.7039, train_acc=0.4090, val_loss=1.7514, val_acc=0.3688\n",
      "Epoch 10: train_loss=1.6950, train_acc=0.4100, val_loss=1.6285, val_acc=0.4156\n",
      "Epoch 11: train_loss=1.6543, train_acc=0.4225, val_loss=1.9330, val_acc=0.3038\n",
      "Epoch 12: train_loss=1.7236, train_acc=0.3982, val_loss=1.7928, val_acc=0.3594\n",
      "Epoch 13: train_loss=1.6741, train_acc=0.4148, val_loss=1.9310, val_acc=0.3076\n",
      "Epoch 14: train_loss=1.7150, train_acc=0.3994, val_loss=1.7367, val_acc=0.3628\n",
      "Epoch 15: train_loss=1.6612, train_acc=0.4153, val_loss=1.6367, val_acc=0.4090\n",
      "Epoch 16: train_loss=1.6294, train_acc=0.4247, val_loss=1.7650, val_acc=0.3598\n",
      "Epoch 17: train_loss=1.6457, train_acc=0.4191, val_loss=1.8495, val_acc=0.3342\n",
      "Epoch 18: train_loss=1.6576, train_acc=0.4159, val_loss=1.7207, val_acc=0.3732\n",
      "Epoch 19: train_loss=1.6309, train_acc=0.4226, val_loss=1.6088, val_acc=0.4142\n",
      "Epoch 20: train_loss=1.6065, train_acc=0.4310, val_loss=1.7051, val_acc=0.3726\n",
      "Epoch 21: train_loss=1.6186, train_acc=0.4259, val_loss=1.7591, val_acc=0.3668\n",
      "Epoch 22: train_loss=1.6552, train_acc=0.4159, val_loss=2.0461, val_acc=0.3018\n",
      "Epoch 23: train_loss=1.6885, train_acc=0.4041, val_loss=1.6594, val_acc=0.4044\n",
      "Epoch 24: train_loss=1.6267, train_acc=0.4199, val_loss=1.8304, val_acc=0.3370\n",
      "Epoch 25: train_loss=1.6738, train_acc=0.4069, val_loss=1.8104, val_acc=0.3446\n",
      "Epoch 26: train_loss=1.6602, train_acc=0.4111, val_loss=1.7693, val_acc=0.3594\n",
      "Epoch 27: train_loss=1.6531, train_acc=0.4117, val_loss=1.6266, val_acc=0.4176\n",
      "Epoch 28: train_loss=1.6271, train_acc=0.4185, val_loss=1.6438, val_acc=0.4062\n",
      "Epoch 29: train_loss=1.6127, train_acc=0.4264, val_loss=1.6623, val_acc=0.4048\n",
      "Epoch 30: train_loss=1.6195, train_acc=0.4249, val_loss=1.7271, val_acc=0.3588\n",
      "Epoch 31: train_loss=1.6485, train_acc=0.4115, val_loss=1.6061, val_acc=0.4160\n",
      "Epoch 32: train_loss=1.6212, train_acc=0.4227, val_loss=1.6987, val_acc=0.3860\n",
      "Epoch 33: train_loss=1.6259, train_acc=0.4212, val_loss=1.6157, val_acc=0.4186\n",
      "Epoch 34: train_loss=1.6063, train_acc=0.4245, val_loss=1.6767, val_acc=0.3704\n",
      "Epoch 35: train_loss=1.6113, train_acc=0.4250, val_loss=1.6051, val_acc=0.4120\n",
      "Epoch 36: train_loss=1.5990, train_acc=0.4315, val_loss=1.7168, val_acc=0.3734\n",
      "Epoch 37: train_loss=1.6179, train_acc=0.4242, val_loss=1.5851, val_acc=0.4214\n",
      "Epoch 38: train_loss=1.6002, train_acc=0.4272, val_loss=2.4057, val_acc=0.2506\n",
      "Epoch 39: train_loss=1.6987, train_acc=0.4037, val_loss=1.8319, val_acc=0.3396\n",
      "Epoch 40: train_loss=1.6839, train_acc=0.4028, val_loss=1.6077, val_acc=0.4260\n",
      "Epoch 41: train_loss=1.6287, train_acc=0.4178, val_loss=1.6014, val_acc=0.4252\n",
      "Epoch 42: train_loss=1.6065, train_acc=0.4251, val_loss=1.6900, val_acc=0.3586\n",
      "Epoch 43: train_loss=1.6388, train_acc=0.4167, val_loss=2.1041, val_acc=0.2268\n",
      "Epoch 44: train_loss=1.6760, train_acc=0.4026, val_loss=1.6601, val_acc=0.4120\n",
      "Epoch 45: train_loss=1.6238, train_acc=0.4218, val_loss=1.6673, val_acc=0.3942\n",
      "Epoch 46: train_loss=1.6145, train_acc=0.4239, val_loss=1.6482, val_acc=0.3918\n",
      "Epoch 47: train_loss=1.6239, train_acc=0.4196, val_loss=1.5871, val_acc=0.4340\n",
      "Epoch 48: train_loss=1.5919, train_acc=0.4288, val_loss=1.6272, val_acc=0.4098\n",
      "Epoch 49: train_loss=1.6511, train_acc=0.4112, val_loss=1.7102, val_acc=0.3624\n",
      "Epoch 50: train_loss=1.6477, train_acc=0.4130, val_loss=1.7367, val_acc=0.3728\n",
      "Epoch 51: train_loss=1.6521, train_acc=0.4113, val_loss=1.6482, val_acc=0.4016\n",
      "Epoch 52: train_loss=1.6805, train_acc=0.3948, val_loss=1.7029, val_acc=0.3754\n",
      "Epoch 53: train_loss=1.6596, train_acc=0.4048, val_loss=1.6678, val_acc=0.3792\n",
      "Epoch 54: train_loss=1.6571, train_acc=0.4051, val_loss=1.6319, val_acc=0.4042\n",
      "Epoch 55: train_loss=1.6409, train_acc=0.4090, val_loss=1.6835, val_acc=0.3948\n",
      "Epoch 56: train_loss=1.6312, train_acc=0.4136, val_loss=1.6919, val_acc=0.3820\n",
      "Epoch 57: train_loss=1.6495, train_acc=0.4091, val_loss=1.6871, val_acc=0.3858\n",
      "Epoch 58: train_loss=1.6471, train_acc=0.4113, val_loss=1.6715, val_acc=0.3884\n",
      "Epoch 59: train_loss=1.6342, train_acc=0.4137, val_loss=1.6662, val_acc=0.3978\n",
      "Epoch 60: train_loss=1.6203, train_acc=0.4213, val_loss=1.6247, val_acc=0.4164\n",
      "Epoch 61: train_loss=1.6184, train_acc=0.4180, val_loss=1.6466, val_acc=0.4008\n",
      "Epoch 62: train_loss=1.6402, train_acc=0.4107, val_loss=1.7703, val_acc=0.3592\n",
      "Epoch 63: train_loss=1.6890, train_acc=0.3957, val_loss=1.6228, val_acc=0.4188\n",
      "Epoch 64: train_loss=1.6322, train_acc=0.4136, val_loss=1.6157, val_acc=0.4124\n",
      "Epoch 65: train_loss=1.6165, train_acc=0.4197, val_loss=1.6880, val_acc=0.3638\n",
      "Epoch 66: train_loss=1.6437, train_acc=0.4139, val_loss=1.7413, val_acc=0.3668\n",
      "Epoch 67: train_loss=1.6377, train_acc=0.4133, val_loss=1.6696, val_acc=0.3932\n",
      "Epoch 68: train_loss=1.6345, train_acc=0.4135, val_loss=1.6632, val_acc=0.3922\n",
      "Epoch 69: train_loss=1.6414, train_acc=0.4127, val_loss=1.6739, val_acc=0.3792\n",
      "Epoch 70: train_loss=1.6546, train_acc=0.4107, val_loss=1.6034, val_acc=0.4180\n",
      "Epoch 71: train_loss=1.6225, train_acc=0.4184, val_loss=1.6094, val_acc=0.4202\n",
      "Epoch 72: train_loss=1.6283, train_acc=0.4198, val_loss=1.5798, val_acc=0.4342\n",
      "Epoch 73: train_loss=1.6091, train_acc=0.4247, val_loss=1.6406, val_acc=0.3920\n",
      "Epoch 74: train_loss=1.6260, train_acc=0.4170, val_loss=1.6168, val_acc=0.4104\n",
      "Epoch 75: train_loss=1.6350, train_acc=0.4171, val_loss=1.7164, val_acc=0.3766\n",
      "Epoch 76: train_loss=1.6806, train_acc=0.4023, val_loss=1.6967, val_acc=0.3746\n",
      "Epoch 77: train_loss=1.6476, train_acc=0.4123, val_loss=1.7292, val_acc=0.3738\n",
      "Epoch 78: train_loss=1.6382, train_acc=0.4135, val_loss=1.6209, val_acc=0.4138\n",
      "Epoch 79: train_loss=1.6271, train_acc=0.4161, val_loss=1.7755, val_acc=0.3598\n",
      "Epoch 80: train_loss=1.7206, train_acc=0.3899, val_loss=1.7605, val_acc=0.3698\n",
      "Epoch 81: train_loss=1.6788, train_acc=0.3988, val_loss=1.6259, val_acc=0.4124\n",
      "Epoch 82: train_loss=1.6391, train_acc=0.4122, val_loss=1.6846, val_acc=0.3836\n",
      "Epoch 83: train_loss=1.6414, train_acc=0.4125, val_loss=1.7950, val_acc=0.3548\n",
      "Epoch 84: train_loss=1.6856, train_acc=0.3976, val_loss=1.6792, val_acc=0.3894\n",
      "Epoch 85: train_loss=1.6395, train_acc=0.4122, val_loss=1.6221, val_acc=0.4192\n",
      "Epoch 86: train_loss=1.6250, train_acc=0.4191, val_loss=1.7245, val_acc=0.3560\n",
      "Epoch 87: train_loss=1.7080, train_acc=0.3902, val_loss=1.8754, val_acc=0.3280\n",
      "Epoch 88: train_loss=1.7639, train_acc=0.3701, val_loss=1.7164, val_acc=0.3810\n",
      "Epoch 89: train_loss=1.7084, train_acc=0.3884, val_loss=1.7215, val_acc=0.3876\n",
      "Epoch 90: train_loss=1.6755, train_acc=0.4021, val_loss=1.6604, val_acc=0.4028\n",
      "Epoch 91: train_loss=1.6626, train_acc=0.4046, val_loss=1.7345, val_acc=0.3660\n",
      "Epoch 92: train_loss=1.6964, train_acc=0.3934, val_loss=1.6518, val_acc=0.4080\n",
      "Epoch 93: train_loss=1.6700, train_acc=0.4023, val_loss=1.6319, val_acc=0.4094\n",
      "Epoch 94: train_loss=1.6693, train_acc=0.3986, val_loss=1.8261, val_acc=0.3496\n",
      "Epoch 95: train_loss=1.6647, train_acc=0.4042, val_loss=1.6438, val_acc=0.4102\n",
      "Epoch 96: train_loss=1.6644, train_acc=0.4055, val_loss=1.9410, val_acc=0.3264\n",
      "Epoch 97: train_loss=1.6872, train_acc=0.3971, val_loss=1.6891, val_acc=0.3796\n",
      "Epoch 98: train_loss=1.6866, train_acc=0.3948, val_loss=1.9832, val_acc=0.3068\n",
      "Epoch 99: train_loss=1.7550, train_acc=0.3779, val_loss=1.8301, val_acc=0.3180\n",
      "Epoch 100: train_loss=1.6933, train_acc=0.3899, val_loss=1.6897, val_acc=0.3856\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>l2_loss</td><td>0.02265</td></tr><tr><td>train_acc</td><td>0.38994</td></tr><tr><td>train_loss</td><td>1.69327</td></tr><tr><td>val_acc</td><td>0.3856</td></tr><tr><td>val_loss</td><td>1.68974</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dark-sweep-14</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/neyhofip' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/neyhofip</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_005116-neyhofip/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5r4cwe7f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09832566213558794\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_014507-5r4cwe7f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/5r4cwe7f' target=\"_blank\">logical-sweep-15</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/5r4cwe7f' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/5r4cwe7f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=3.8142, train_acc=0.0984, val_loss=7.2050, val_acc=0.0984\n",
      "Epoch 2: train_loss=3.6872, train_acc=0.0997, val_loss=7.8587, val_acc=0.0998\n",
      "Epoch 3: train_loss=3.8464, train_acc=0.0999, val_loss=6.1594, val_acc=0.1066\n",
      "Epoch 4: train_loss=3.7246, train_acc=0.0972, val_loss=10.8537, val_acc=0.0980\n",
      "Epoch 5: train_loss=3.8532, train_acc=0.0998, val_loss=3.9172, val_acc=0.1066\n",
      "Epoch 6: train_loss=3.7874, train_acc=0.1001, val_loss=6.6556, val_acc=0.0990\n",
      "Epoch 7: train_loss=3.8005, train_acc=0.1010, val_loss=10.3576, val_acc=0.0974\n",
      "Epoch 8: train_loss=3.8190, train_acc=0.0991, val_loss=4.6600, val_acc=0.0974\n",
      "Epoch 9: train_loss=3.7979, train_acc=0.0990, val_loss=6.6158, val_acc=0.1028\n",
      "Epoch 10: train_loss=3.7535, train_acc=0.0990, val_loss=7.6825, val_acc=0.1028\n",
      "Epoch 11: train_loss=3.7512, train_acc=0.0990, val_loss=6.8126, val_acc=0.0980\n",
      "Epoch 12: train_loss=3.7771, train_acc=0.0990, val_loss=7.1089, val_acc=0.1000\n",
      "Epoch 13: train_loss=3.8810, train_acc=0.1012, val_loss=7.6877, val_acc=0.0980\n",
      "Epoch 14: train_loss=3.7359, train_acc=0.0991, val_loss=9.4477, val_acc=0.1028\n",
      "Epoch 15: train_loss=3.8233, train_acc=0.0991, val_loss=10.8624, val_acc=0.0984\n",
      "Epoch 16: train_loss=3.7954, train_acc=0.0997, val_loss=10.1375, val_acc=0.1000\n",
      "Epoch 17: train_loss=3.9025, train_acc=0.1003, val_loss=7.6385, val_acc=0.0980\n",
      "Epoch 18: train_loss=3.8124, train_acc=0.1009, val_loss=12.2745, val_acc=0.1028\n",
      "Epoch 19: train_loss=3.7510, train_acc=0.1007, val_loss=10.3013, val_acc=0.0990\n",
      "Epoch 20: train_loss=3.8000, train_acc=0.0973, val_loss=5.8095, val_acc=0.0990\n",
      "Epoch 21: train_loss=3.7138, train_acc=0.1027, val_loss=7.4692, val_acc=0.0990\n",
      "Epoch 22: train_loss=3.8303, train_acc=0.0990, val_loss=4.7850, val_acc=0.1028\n",
      "Epoch 23: train_loss=3.7217, train_acc=0.0995, val_loss=5.1847, val_acc=0.0974\n",
      "Epoch 24: train_loss=3.6721, train_acc=0.0988, val_loss=8.6544, val_acc=0.0990\n",
      "Epoch 25: train_loss=3.8043, train_acc=0.0986, val_loss=7.0612, val_acc=0.1000\n",
      "Epoch 26: train_loss=3.7570, train_acc=0.1018, val_loss=12.0852, val_acc=0.0980\n",
      "Epoch 27: train_loss=3.8459, train_acc=0.0981, val_loss=5.2745, val_acc=0.0984\n",
      "Epoch 28: train_loss=3.6363, train_acc=0.1038, val_loss=7.1673, val_acc=0.0990\n",
      "Epoch 29: train_loss=3.8222, train_acc=0.1006, val_loss=13.6413, val_acc=0.0990\n",
      "Epoch 30: train_loss=3.8222, train_acc=0.1004, val_loss=6.0863, val_acc=0.0980\n",
      "Epoch 31: train_loss=3.7827, train_acc=0.1028, val_loss=6.2790, val_acc=0.1066\n",
      "Epoch 32: train_loss=3.7928, train_acc=0.1006, val_loss=7.4916, val_acc=0.0974\n",
      "Epoch 33: train_loss=3.6965, train_acc=0.0987, val_loss=12.1111, val_acc=0.0990\n",
      "Epoch 34: train_loss=3.9005, train_acc=0.0994, val_loss=5.9697, val_acc=0.0980\n",
      "Epoch 35: train_loss=3.8280, train_acc=0.1002, val_loss=13.9360, val_acc=0.0990\n",
      "Epoch 36: train_loss=3.8109, train_acc=0.1006, val_loss=8.2799, val_acc=0.1000\n",
      "Epoch 37: train_loss=3.9541, train_acc=0.0971, val_loss=9.3939, val_acc=0.1000\n",
      "Epoch 38: train_loss=3.7537, train_acc=0.1015, val_loss=7.8813, val_acc=0.0998\n",
      "Epoch 39: train_loss=3.8652, train_acc=0.0985, val_loss=7.3062, val_acc=0.0990\n",
      "Epoch 40: train_loss=3.7544, train_acc=0.1012, val_loss=3.6672, val_acc=0.1028\n",
      "Epoch 41: train_loss=3.6972, train_acc=0.0987, val_loss=10.8491, val_acc=0.0990\n",
      "Epoch 42: train_loss=3.7690, train_acc=0.0991, val_loss=8.6612, val_acc=0.1066\n",
      "Epoch 43: train_loss=3.8570, train_acc=0.1001, val_loss=6.0796, val_acc=0.0974\n",
      "Epoch 44: train_loss=3.7713, train_acc=0.0969, val_loss=8.1299, val_acc=0.0990\n",
      "Epoch 45: train_loss=3.7828, train_acc=0.1010, val_loss=6.4801, val_acc=0.1066\n",
      "Epoch 46: train_loss=3.8282, train_acc=0.0985, val_loss=5.3352, val_acc=0.0974\n",
      "Epoch 47: train_loss=3.6509, train_acc=0.0998, val_loss=6.1800, val_acc=0.0984\n",
      "Epoch 48: train_loss=3.7996, train_acc=0.1006, val_loss=7.5971, val_acc=0.1000\n",
      "Epoch 49: train_loss=3.8231, train_acc=0.1006, val_loss=9.3617, val_acc=0.0990\n",
      "Epoch 50: train_loss=3.7264, train_acc=0.1012, val_loss=8.3172, val_acc=0.0980\n",
      "Epoch 51: train_loss=3.7823, train_acc=0.1008, val_loss=6.4071, val_acc=0.0990\n",
      "Epoch 52: train_loss=3.7158, train_acc=0.1007, val_loss=5.2196, val_acc=0.0990\n",
      "Epoch 53: train_loss=3.7311, train_acc=0.0997, val_loss=7.5162, val_acc=0.0990\n",
      "Epoch 54: train_loss=3.7601, train_acc=0.0992, val_loss=12.3989, val_acc=0.0980\n",
      "Epoch 55: train_loss=3.7898, train_acc=0.0981, val_loss=7.4656, val_acc=0.0990\n",
      "Epoch 56: train_loss=3.7931, train_acc=0.0989, val_loss=8.6893, val_acc=0.0990\n",
      "Epoch 57: train_loss=3.7367, train_acc=0.0998, val_loss=10.2202, val_acc=0.0990\n",
      "Epoch 58: train_loss=3.8112, train_acc=0.0994, val_loss=5.8680, val_acc=0.0984\n",
      "Epoch 59: train_loss=3.6747, train_acc=0.1014, val_loss=14.3974, val_acc=0.1066\n",
      "Epoch 60: train_loss=3.8834, train_acc=0.1002, val_loss=7.8822, val_acc=0.0980\n",
      "Epoch 61: train_loss=3.7750, train_acc=0.0998, val_loss=9.7920, val_acc=0.1000\n",
      "Epoch 62: train_loss=3.8503, train_acc=0.1012, val_loss=8.2454, val_acc=0.1028\n",
      "Epoch 63: train_loss=3.7521, train_acc=0.0989, val_loss=15.9179, val_acc=0.0980\n",
      "Epoch 64: train_loss=3.7857, train_acc=0.1001, val_loss=5.8797, val_acc=0.0990\n",
      "Epoch 65: train_loss=3.7646, train_acc=0.1015, val_loss=6.7543, val_acc=0.1028\n",
      "Epoch 66: train_loss=3.7798, train_acc=0.0989, val_loss=8.3425, val_acc=0.1066\n",
      "Epoch 67: train_loss=3.7995, train_acc=0.1007, val_loss=12.5419, val_acc=0.0998\n",
      "Epoch 68: train_loss=3.7691, train_acc=0.1014, val_loss=4.9916, val_acc=0.0990\n",
      "Epoch 69: train_loss=3.7863, train_acc=0.0986, val_loss=7.3336, val_acc=0.0990\n",
      "Epoch 70: train_loss=3.7889, train_acc=0.1039, val_loss=3.8438, val_acc=0.0980\n",
      "Epoch 71: train_loss=3.6857, train_acc=0.0994, val_loss=6.7043, val_acc=0.0990\n",
      "Epoch 72: train_loss=3.7071, train_acc=0.0992, val_loss=6.5500, val_acc=0.0990\n",
      "Epoch 73: train_loss=3.7852, train_acc=0.1013, val_loss=6.6135, val_acc=0.0990\n",
      "Epoch 74: train_loss=3.7345, train_acc=0.0973, val_loss=9.9114, val_acc=0.1066\n",
      "Epoch 75: train_loss=3.7836, train_acc=0.1006, val_loss=6.8314, val_acc=0.0980\n",
      "Epoch 76: train_loss=3.6809, train_acc=0.1001, val_loss=6.9791, val_acc=0.0990\n",
      "Epoch 77: train_loss=3.8050, train_acc=0.0984, val_loss=6.1774, val_acc=0.0998\n",
      "Epoch 78: train_loss=3.7534, train_acc=0.1008, val_loss=4.7570, val_acc=0.0984\n",
      "Epoch 79: train_loss=3.7573, train_acc=0.1013, val_loss=8.9903, val_acc=0.0984\n",
      "Epoch 80: train_loss=3.8062, train_acc=0.0997, val_loss=6.3347, val_acc=0.1000\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.09971</td></tr><tr><td>train_loss</td><td>3.80618</td></tr><tr><td>val_acc</td><td>0.1</td></tr><tr><td>val_loss</td><td>6.33468</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-15</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/5r4cwe7f' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/5r4cwe7f</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_014507-5r4cwe7f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b7ef2cue with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.030483146401742513\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_033723-b7ef2cue</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/b7ef2cue' target=\"_blank\">dauntless-sweep-16</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/b7ef2cue' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/b7ef2cue</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.0453, train_acc=0.2723, val_loss=1.7829, val_acc=0.3606\n",
      "Epoch 2: train_loss=1.8614, train_acc=0.3372, val_loss=1.7365, val_acc=0.3818\n",
      "Epoch 3: train_loss=1.7874, train_acc=0.3630, val_loss=1.6821, val_acc=0.4068\n",
      "Epoch 4: train_loss=1.7415, train_acc=0.3825, val_loss=1.6477, val_acc=0.4094\n",
      "Epoch 5: train_loss=1.7042, train_acc=0.3926, val_loss=1.6243, val_acc=0.4240\n",
      "Epoch 6: train_loss=1.6768, train_acc=0.4065, val_loss=1.6231, val_acc=0.4278\n",
      "Epoch 7: train_loss=1.6582, train_acc=0.4135, val_loss=1.5784, val_acc=0.4314\n",
      "Epoch 8: train_loss=1.6352, train_acc=0.4212, val_loss=1.5792, val_acc=0.4346\n",
      "Epoch 9: train_loss=1.6191, train_acc=0.4269, val_loss=1.5747, val_acc=0.4338\n",
      "Epoch 10: train_loss=1.6097, train_acc=0.4297, val_loss=1.5645, val_acc=0.4442\n",
      "Epoch 11: train_loss=1.5941, train_acc=0.4358, val_loss=1.5415, val_acc=0.4428\n",
      "Epoch 12: train_loss=1.5814, train_acc=0.4369, val_loss=1.5287, val_acc=0.4560\n",
      "Epoch 13: train_loss=1.5681, train_acc=0.4423, val_loss=1.5294, val_acc=0.4534\n",
      "Epoch 14: train_loss=1.5583, train_acc=0.4483, val_loss=1.5023, val_acc=0.4666\n",
      "Epoch 15: train_loss=1.5494, train_acc=0.4537, val_loss=1.4979, val_acc=0.4664\n",
      "Epoch 16: train_loss=1.5361, train_acc=0.4567, val_loss=1.4907, val_acc=0.4606\n",
      "Epoch 17: train_loss=1.5289, train_acc=0.4578, val_loss=1.4804, val_acc=0.4674\n",
      "Epoch 18: train_loss=1.5173, train_acc=0.4628, val_loss=1.4813, val_acc=0.4664\n",
      "Epoch 19: train_loss=1.5087, train_acc=0.4650, val_loss=1.4932, val_acc=0.4646\n",
      "Epoch 20: train_loss=1.5004, train_acc=0.4676, val_loss=1.4711, val_acc=0.4718\n",
      "Epoch 21: train_loss=1.4883, train_acc=0.4723, val_loss=1.5321, val_acc=0.4582\n",
      "Epoch 22: train_loss=1.4888, train_acc=0.4719, val_loss=1.4508, val_acc=0.4818\n",
      "Epoch 23: train_loss=1.4780, train_acc=0.4761, val_loss=1.4552, val_acc=0.4724\n",
      "Epoch 24: train_loss=1.4684, train_acc=0.4781, val_loss=1.4669, val_acc=0.4764\n",
      "Epoch 25: train_loss=1.4682, train_acc=0.4815, val_loss=1.4296, val_acc=0.4894\n",
      "Epoch 26: train_loss=1.4620, train_acc=0.4798, val_loss=1.4264, val_acc=0.4906\n",
      "Epoch 27: train_loss=1.4524, train_acc=0.4867, val_loss=1.4542, val_acc=0.4880\n",
      "Epoch 28: train_loss=1.4459, train_acc=0.4864, val_loss=1.4541, val_acc=0.4766\n",
      "Epoch 29: train_loss=1.4399, train_acc=0.4880, val_loss=1.4127, val_acc=0.4998\n",
      "Epoch 30: train_loss=1.4376, train_acc=0.4901, val_loss=1.4144, val_acc=0.4920\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.49011</td></tr><tr><td>train_loss</td><td>1.43757</td></tr><tr><td>val_acc</td><td>0.492</td></tr><tr><td>val_loss</td><td>1.41437</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dauntless-sweep-16</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/b7ef2cue' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/b7ef2cue</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_033723-b7ef2cue/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6jgv8uxv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06417811720370016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_040820-6jgv8uxv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6jgv8uxv' target=\"_blank\">bumbling-sweep-17</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6jgv8uxv' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6jgv8uxv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.9664, train_acc=0.0990, val_loss=10.5377, val_acc=0.1000\n",
      "Epoch 2: train_loss=3.1887, train_acc=0.1002, val_loss=14.2700, val_acc=0.0984\n",
      "Epoch 3: train_loss=3.4667, train_acc=0.1023, val_loss=8.2550, val_acc=0.0980\n",
      "Epoch 4: train_loss=2.8880, train_acc=0.1013, val_loss=5.7483, val_acc=0.0980\n",
      "Epoch 5: train_loss=2.8730, train_acc=0.1031, val_loss=15.9914, val_acc=0.1028\n",
      "Epoch 6: train_loss=3.3035, train_acc=0.1000, val_loss=15.5956, val_acc=0.0984\n",
      "Epoch 7: train_loss=3.2416, train_acc=0.0986, val_loss=7.1990, val_acc=0.0974\n",
      "Epoch 8: train_loss=2.9911, train_acc=0.1014, val_loss=12.5632, val_acc=0.0974\n",
      "Epoch 9: train_loss=3.1251, train_acc=0.0987, val_loss=9.2224, val_acc=0.0990\n",
      "Epoch 10: train_loss=2.9700, train_acc=0.1011, val_loss=15.0973, val_acc=0.0990\n",
      "Epoch 11: train_loss=3.1559, train_acc=0.0995, val_loss=15.5018, val_acc=0.0974\n",
      "Epoch 12: train_loss=3.1183, train_acc=0.1001, val_loss=12.0838, val_acc=0.0990\n",
      "Epoch 13: train_loss=3.0441, train_acc=0.0999, val_loss=7.2949, val_acc=0.0998\n",
      "Epoch 14: train_loss=2.9688, train_acc=0.0973, val_loss=10.0090, val_acc=0.1000\n",
      "Epoch 15: train_loss=3.0295, train_acc=0.0989, val_loss=11.3286, val_acc=0.1028\n",
      "Epoch 16: train_loss=3.0625, train_acc=0.0987, val_loss=7.5875, val_acc=0.0990\n",
      "Epoch 17: train_loss=3.0277, train_acc=0.1002, val_loss=15.0836, val_acc=0.0974\n",
      "Epoch 18: train_loss=3.4839, train_acc=0.0963, val_loss=10.3516, val_acc=0.0984\n",
      "Epoch 19: train_loss=2.9207, train_acc=0.1029, val_loss=10.2967, val_acc=0.0974\n",
      "Epoch 20: train_loss=3.0981, train_acc=0.0981, val_loss=10.5442, val_acc=0.0984\n",
      "Epoch 21: train_loss=3.1776, train_acc=0.0991, val_loss=16.2759, val_acc=0.0990\n",
      "Epoch 22: train_loss=3.3080, train_acc=0.1030, val_loss=14.8884, val_acc=0.0990\n",
      "Epoch 23: train_loss=3.2578, train_acc=0.0983, val_loss=12.7194, val_acc=0.0998\n",
      "Epoch 24: train_loss=3.0542, train_acc=0.1028, val_loss=18.7436, val_acc=0.0980\n",
      "Epoch 25: train_loss=3.1218, train_acc=0.1002, val_loss=10.9559, val_acc=0.0990\n",
      "Epoch 26: train_loss=3.1773, train_acc=0.0994, val_loss=10.2636, val_acc=0.1028\n",
      "Epoch 27: train_loss=2.9871, train_acc=0.0995, val_loss=11.6624, val_acc=0.0990\n",
      "Epoch 28: train_loss=3.0390, train_acc=0.0995, val_loss=11.3218, val_acc=0.1066\n",
      "Epoch 29: train_loss=2.9696, train_acc=0.0980, val_loss=10.9805, val_acc=0.1000\n",
      "Epoch 30: train_loss=3.0545, train_acc=0.1025, val_loss=15.7756, val_acc=0.0984\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>l2_loss</td><td>0.0422</td></tr><tr><td>train_acc</td><td>0.10246</td></tr><tr><td>train_loss</td><td>3.05453</td></tr><tr><td>val_acc</td><td>0.0984</td></tr><tr><td>val_loss</td><td>15.77559</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">bumbling-sweep-17</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6jgv8uxv' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6jgv8uxv</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_040820-6jgv8uxv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oxazhrbf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01628375179050562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_042227-oxazhrbf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/oxazhrbf' target=\"_blank\">firm-sweep-18</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/oxazhrbf' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/oxazhrbf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.5427, train_acc=0.0976, val_loss=2.3032, val_acc=0.0974\n",
      "Epoch 2: train_loss=2.3114, train_acc=0.1012, val_loss=2.3033, val_acc=0.0990\n",
      "Epoch 3: train_loss=2.3102, train_acc=0.1030, val_loss=2.3030, val_acc=0.0998\n",
      "Epoch 4: train_loss=2.3104, train_acc=0.0988, val_loss=2.3041, val_acc=0.0980\n",
      "Epoch 5: train_loss=2.3107, train_acc=0.0976, val_loss=2.3029, val_acc=0.0990\n",
      "Epoch 6: train_loss=2.3105, train_acc=0.0987, val_loss=2.3033, val_acc=0.0984\n",
      "Epoch 7: train_loss=2.3103, train_acc=0.0997, val_loss=2.3033, val_acc=0.0998\n",
      "Epoch 8: train_loss=2.3104, train_acc=0.1011, val_loss=2.3034, val_acc=0.0984\n",
      "Epoch 9: train_loss=2.3104, train_acc=0.0998, val_loss=2.3037, val_acc=0.0974\n",
      "Epoch 10: train_loss=2.3101, train_acc=0.1014, val_loss=2.3032, val_acc=0.1028\n",
      "Epoch 11: train_loss=2.3102, train_acc=0.1001, val_loss=2.3034, val_acc=0.0990\n",
      "Epoch 12: train_loss=2.3102, train_acc=0.1010, val_loss=2.3030, val_acc=0.0998\n",
      "Epoch 13: train_loss=2.3103, train_acc=0.0969, val_loss=2.3031, val_acc=0.0984\n",
      "Epoch 14: train_loss=2.3104, train_acc=0.0989, val_loss=2.3042, val_acc=0.0984\n",
      "Epoch 15: train_loss=2.3104, train_acc=0.0972, val_loss=2.3038, val_acc=0.0998\n",
      "Epoch 16: train_loss=2.3103, train_acc=0.0994, val_loss=2.3060, val_acc=0.0974\n",
      "Epoch 17: train_loss=2.3103, train_acc=0.1005, val_loss=2.3048, val_acc=0.0990\n",
      "Epoch 18: train_loss=2.3105, train_acc=0.1022, val_loss=2.3035, val_acc=0.0980\n",
      "Epoch 19: train_loss=2.3101, train_acc=0.1011, val_loss=2.3035, val_acc=0.0984\n",
      "Epoch 20: train_loss=2.3105, train_acc=0.0971, val_loss=2.3034, val_acc=0.0990\n",
      "Epoch 21: train_loss=2.3102, train_acc=0.1000, val_loss=2.3048, val_acc=0.0974\n",
      "Epoch 22: train_loss=2.3104, train_acc=0.0985, val_loss=2.3036, val_acc=0.0990\n",
      "Epoch 23: train_loss=2.3105, train_acc=0.0997, val_loss=2.3033, val_acc=0.0984\n",
      "Epoch 24: train_loss=2.3103, train_acc=0.0994, val_loss=2.3031, val_acc=0.0990\n",
      "Epoch 25: train_loss=2.3101, train_acc=0.1000, val_loss=2.3032, val_acc=0.0990\n",
      "Epoch 26: train_loss=2.3101, train_acc=0.1008, val_loss=2.3034, val_acc=0.0984\n",
      "Epoch 27: train_loss=2.3104, train_acc=0.1001, val_loss=2.3038, val_acc=0.0990\n",
      "Epoch 28: train_loss=2.3104, train_acc=0.0988, val_loss=2.3035, val_acc=0.0974\n",
      "Epoch 29: train_loss=2.3102, train_acc=0.1001, val_loss=2.3039, val_acc=0.0990\n",
      "Epoch 30: train_loss=2.3102, train_acc=0.0999, val_loss=2.3028, val_acc=0.0990\n",
      "Epoch 31: train_loss=2.3102, train_acc=0.1018, val_loss=2.3033, val_acc=0.0984\n",
      "Epoch 32: train_loss=2.3100, train_acc=0.1026, val_loss=2.3033, val_acc=0.0990\n",
      "Epoch 33: train_loss=2.3103, train_acc=0.0992, val_loss=2.3029, val_acc=0.0974\n",
      "Epoch 34: train_loss=2.3104, train_acc=0.0985, val_loss=2.3039, val_acc=0.0990\n",
      "Epoch 35: train_loss=2.3103, train_acc=0.0995, val_loss=2.3028, val_acc=0.1028\n",
      "Epoch 36: train_loss=2.3102, train_acc=0.1008, val_loss=2.3051, val_acc=0.0990\n",
      "Epoch 37: train_loss=2.3104, train_acc=0.0989, val_loss=2.3031, val_acc=0.0974\n",
      "Epoch 38: train_loss=2.3102, train_acc=0.1012, val_loss=2.3029, val_acc=0.0998\n",
      "Epoch 39: train_loss=2.3103, train_acc=0.0986, val_loss=2.3036, val_acc=0.0998\n",
      "Epoch 40: train_loss=2.3104, train_acc=0.0989, val_loss=2.3031, val_acc=0.1000\n",
      "Epoch 41: train_loss=2.3104, train_acc=0.1014, val_loss=2.3048, val_acc=0.0980\n",
      "Epoch 42: train_loss=2.3103, train_acc=0.0989, val_loss=2.3037, val_acc=0.0980\n",
      "Epoch 43: train_loss=2.3104, train_acc=0.0997, val_loss=2.3036, val_acc=0.0990\n",
      "Epoch 44: train_loss=2.3102, train_acc=0.1024, val_loss=2.3032, val_acc=0.0998\n",
      "Epoch 45: train_loss=2.3103, train_acc=0.1002, val_loss=2.3035, val_acc=0.0990\n",
      "Epoch 46: train_loss=2.3105, train_acc=0.0993, val_loss=2.3046, val_acc=0.1000\n",
      "Epoch 47: train_loss=2.3104, train_acc=0.1002, val_loss=2.3028, val_acc=0.1066\n",
      "Epoch 48: train_loss=2.3103, train_acc=0.0988, val_loss=2.3038, val_acc=0.0974\n",
      "Epoch 49: train_loss=2.3105, train_acc=0.0983, val_loss=2.3037, val_acc=0.0990\n",
      "Epoch 50: train_loss=2.3103, train_acc=0.1015, val_loss=2.3048, val_acc=0.0998\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>l2_loss</td><td>0.0</td></tr><tr><td>train_acc</td><td>0.10155</td></tr><tr><td>train_loss</td><td>2.31033</td></tr><tr><td>val_acc</td><td>0.0998</td></tr><tr><td>val_loss</td><td>2.30476</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">firm-sweep-18</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/oxazhrbf' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/oxazhrbf</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_042227-oxazhrbf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 14tpfi7w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.04977151760332706\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_045248-14tpfi7w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/14tpfi7w' target=\"_blank\">logical-sweep-19</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/14tpfi7w' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/14tpfi7w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.9394, train_acc=0.3021, val_loss=1.8023, val_acc=0.3592\n",
      "Epoch 2: train_loss=1.8229, train_acc=0.3552, val_loss=1.7731, val_acc=0.3704\n",
      "Epoch 3: train_loss=1.7723, train_acc=0.3717, val_loss=1.7637, val_acc=0.3750\n",
      "Epoch 4: train_loss=1.7398, train_acc=0.3837, val_loss=1.7148, val_acc=0.3884\n",
      "Epoch 5: train_loss=1.7058, train_acc=0.3978, val_loss=1.7117, val_acc=0.3850\n",
      "Epoch 6: train_loss=1.6786, train_acc=0.4079, val_loss=1.6476, val_acc=0.4160\n",
      "Epoch 7: train_loss=1.6528, train_acc=0.4132, val_loss=1.5949, val_acc=0.4282\n",
      "Epoch 8: train_loss=1.6368, train_acc=0.4209, val_loss=1.5964, val_acc=0.4244\n",
      "Epoch 9: train_loss=1.6190, train_acc=0.4262, val_loss=1.5570, val_acc=0.4442\n",
      "Epoch 10: train_loss=1.6012, train_acc=0.4331, val_loss=1.5570, val_acc=0.4442\n",
      "Epoch 11: train_loss=1.5827, train_acc=0.4405, val_loss=1.5483, val_acc=0.4436\n",
      "Epoch 12: train_loss=1.5696, train_acc=0.4443, val_loss=1.5355, val_acc=0.4510\n",
      "Epoch 13: train_loss=1.5599, train_acc=0.4458, val_loss=1.5679, val_acc=0.4422\n",
      "Epoch 14: train_loss=1.5439, train_acc=0.4537, val_loss=1.5182, val_acc=0.4620\n",
      "Epoch 15: train_loss=1.5283, train_acc=0.4571, val_loss=1.5126, val_acc=0.4518\n",
      "Epoch 16: train_loss=1.5214, train_acc=0.4597, val_loss=1.5045, val_acc=0.4570\n",
      "Epoch 17: train_loss=1.5138, train_acc=0.4617, val_loss=1.4789, val_acc=0.4672\n",
      "Epoch 18: train_loss=1.5015, train_acc=0.4678, val_loss=1.4893, val_acc=0.4664\n",
      "Epoch 19: train_loss=1.4927, train_acc=0.4696, val_loss=1.4604, val_acc=0.4754\n",
      "Epoch 20: train_loss=1.4811, train_acc=0.4760, val_loss=1.4506, val_acc=0.4726\n",
      "Epoch 21: train_loss=1.4753, train_acc=0.4769, val_loss=1.4333, val_acc=0.4830\n",
      "Epoch 22: train_loss=1.4634, train_acc=0.4792, val_loss=1.4426, val_acc=0.4840\n",
      "Epoch 23: train_loss=1.4582, train_acc=0.4816, val_loss=1.4243, val_acc=0.4940\n",
      "Epoch 24: train_loss=1.4507, train_acc=0.4848, val_loss=1.4287, val_acc=0.4880\n",
      "Epoch 25: train_loss=1.4505, train_acc=0.4870, val_loss=1.4180, val_acc=0.4982\n",
      "Epoch 26: train_loss=1.4344, train_acc=0.4909, val_loss=1.4621, val_acc=0.4856\n",
      "Epoch 27: train_loss=1.4320, train_acc=0.4897, val_loss=1.4123, val_acc=0.5000\n",
      "Epoch 28: train_loss=1.4191, train_acc=0.4970, val_loss=1.4090, val_acc=0.4910\n",
      "Epoch 29: train_loss=1.4137, train_acc=0.4978, val_loss=1.3974, val_acc=0.4960\n",
      "Epoch 30: train_loss=1.4064, train_acc=0.4998, val_loss=1.4078, val_acc=0.4972\n",
      "Epoch 31: train_loss=1.4056, train_acc=0.5004, val_loss=1.3882, val_acc=0.5004\n",
      "Epoch 32: train_loss=1.3979, train_acc=0.5043, val_loss=1.4009, val_acc=0.5010\n",
      "Epoch 33: train_loss=1.3932, train_acc=0.5046, val_loss=1.3724, val_acc=0.5100\n",
      "Epoch 34: train_loss=1.3871, train_acc=0.5074, val_loss=1.4145, val_acc=0.4908\n",
      "Epoch 35: train_loss=1.3810, train_acc=0.5098, val_loss=1.3715, val_acc=0.5096\n",
      "Epoch 36: train_loss=1.3767, train_acc=0.5129, val_loss=1.3928, val_acc=0.5032\n",
      "Epoch 37: train_loss=1.3686, train_acc=0.5142, val_loss=1.3923, val_acc=0.5008\n",
      "Epoch 38: train_loss=1.3638, train_acc=0.5152, val_loss=1.3645, val_acc=0.5062\n",
      "Epoch 39: train_loss=1.3578, train_acc=0.5172, val_loss=1.3670, val_acc=0.5100\n",
      "Epoch 40: train_loss=1.3530, train_acc=0.5198, val_loss=1.3785, val_acc=0.5064\n",
      "Epoch 41: train_loss=1.3500, train_acc=0.5205, val_loss=1.3507, val_acc=0.5228\n",
      "Epoch 42: train_loss=1.3410, train_acc=0.5254, val_loss=1.3524, val_acc=0.5166\n",
      "Epoch 43: train_loss=1.3295, train_acc=0.5300, val_loss=1.3516, val_acc=0.5156\n",
      "Epoch 44: train_loss=1.3291, train_acc=0.5261, val_loss=1.3446, val_acc=0.5194\n",
      "Epoch 45: train_loss=1.3227, train_acc=0.5310, val_loss=1.3979, val_acc=0.5044\n",
      "Epoch 46: train_loss=1.3186, train_acc=0.5303, val_loss=1.3425, val_acc=0.5180\n",
      "Epoch 47: train_loss=1.3133, train_acc=0.5318, val_loss=1.3429, val_acc=0.5252\n",
      "Epoch 48: train_loss=1.3102, train_acc=0.5351, val_loss=1.3348, val_acc=0.5286\n",
      "Epoch 49: train_loss=1.3059, train_acc=0.5362, val_loss=1.3309, val_acc=0.5270\n",
      "Epoch 50: train_loss=1.3013, train_acc=0.5368, val_loss=1.3480, val_acc=0.5154\n",
      "Epoch 51: train_loss=1.2981, train_acc=0.5384, val_loss=1.3268, val_acc=0.5280\n",
      "Epoch 52: train_loss=1.2896, train_acc=0.5431, val_loss=1.3294, val_acc=0.5230\n",
      "Epoch 53: train_loss=1.2862, train_acc=0.5442, val_loss=1.3304, val_acc=0.5284\n",
      "Epoch 54: train_loss=1.2786, train_acc=0.5464, val_loss=1.3130, val_acc=0.5316\n",
      "Epoch 55: train_loss=1.2716, train_acc=0.5485, val_loss=1.3222, val_acc=0.5324\n",
      "Epoch 56: train_loss=1.2718, train_acc=0.5488, val_loss=1.3260, val_acc=0.5232\n",
      "Epoch 57: train_loss=1.2638, train_acc=0.5514, val_loss=1.3278, val_acc=0.5266\n",
      "Epoch 58: train_loss=1.2675, train_acc=0.5515, val_loss=1.3232, val_acc=0.5274\n",
      "Epoch 59: train_loss=1.2597, train_acc=0.5534, val_loss=1.3275, val_acc=0.5332\n",
      "Epoch 60: train_loss=1.2544, train_acc=0.5550, val_loss=1.3289, val_acc=0.5292\n",
      "Epoch 61: train_loss=1.2505, train_acc=0.5555, val_loss=1.3227, val_acc=0.5342\n",
      "Epoch 62: train_loss=1.2480, train_acc=0.5606, val_loss=1.3070, val_acc=0.5284\n",
      "Epoch 63: train_loss=1.2456, train_acc=0.5606, val_loss=1.3292, val_acc=0.5310\n",
      "Epoch 64: train_loss=1.2399, train_acc=0.5589, val_loss=1.3103, val_acc=0.5328\n",
      "Epoch 65: train_loss=1.2284, train_acc=0.5616, val_loss=1.3193, val_acc=0.5308\n",
      "Epoch 66: train_loss=1.2305, train_acc=0.5617, val_loss=1.2987, val_acc=0.5360\n",
      "Epoch 67: train_loss=1.2274, train_acc=0.5669, val_loss=1.3072, val_acc=0.5368\n",
      "Epoch 68: train_loss=1.2227, train_acc=0.5649, val_loss=1.3515, val_acc=0.5156\n",
      "Epoch 69: train_loss=1.2162, train_acc=0.5692, val_loss=1.3035, val_acc=0.5332\n",
      "Epoch 70: train_loss=1.2130, train_acc=0.5695, val_loss=1.3077, val_acc=0.5388\n",
      "Epoch 71: train_loss=1.2102, train_acc=0.5715, val_loss=1.3138, val_acc=0.5376\n",
      "Epoch 72: train_loss=1.2119, train_acc=0.5698, val_loss=1.2987, val_acc=0.5404\n",
      "Epoch 73: train_loss=1.2019, train_acc=0.5737, val_loss=1.2881, val_acc=0.5472\n",
      "Epoch 74: train_loss=1.2029, train_acc=0.5738, val_loss=1.3030, val_acc=0.5430\n",
      "Epoch 75: train_loss=1.1959, train_acc=0.5743, val_loss=1.2966, val_acc=0.5386\n",
      "Epoch 76: train_loss=1.1954, train_acc=0.5757, val_loss=1.2926, val_acc=0.5478\n",
      "Epoch 77: train_loss=1.1869, train_acc=0.5802, val_loss=1.2914, val_acc=0.5424\n",
      "Epoch 78: train_loss=1.1832, train_acc=0.5799, val_loss=1.2974, val_acc=0.5402\n",
      "Epoch 79: train_loss=1.1795, train_acc=0.5822, val_loss=1.2975, val_acc=0.5438\n",
      "Epoch 80: train_loss=1.1731, train_acc=0.5847, val_loss=1.2759, val_acc=0.5552\n",
      "Epoch 81: train_loss=1.1708, train_acc=0.5838, val_loss=1.2783, val_acc=0.5510\n",
      "Epoch 82: train_loss=1.1718, train_acc=0.5843, val_loss=1.2823, val_acc=0.5486\n",
      "Epoch 83: train_loss=1.1660, train_acc=0.5846, val_loss=1.2898, val_acc=0.5472\n",
      "Epoch 84: train_loss=1.1609, train_acc=0.5882, val_loss=1.2774, val_acc=0.5526\n",
      "Epoch 85: train_loss=1.1570, train_acc=0.5882, val_loss=1.2952, val_acc=0.5456\n",
      "Epoch 86: train_loss=1.1632, train_acc=0.5889, val_loss=1.2832, val_acc=0.5480\n",
      "Epoch 87: train_loss=1.1560, train_acc=0.5889, val_loss=1.2920, val_acc=0.5504\n",
      "Epoch 88: train_loss=1.1504, train_acc=0.5921, val_loss=1.2840, val_acc=0.5468\n",
      "Epoch 89: train_loss=1.1519, train_acc=0.5900, val_loss=1.2707, val_acc=0.5566\n",
      "Epoch 90: train_loss=1.1446, train_acc=0.5917, val_loss=1.2783, val_acc=0.5492\n",
      "Epoch 91: train_loss=1.1342, train_acc=0.5971, val_loss=1.2799, val_acc=0.5508\n",
      "Epoch 92: train_loss=1.1346, train_acc=0.5983, val_loss=1.3151, val_acc=0.5404\n",
      "Epoch 93: train_loss=1.1349, train_acc=0.5983, val_loss=1.2808, val_acc=0.5526\n",
      "Epoch 94: train_loss=1.1266, train_acc=0.5993, val_loss=1.2783, val_acc=0.5538\n",
      "Epoch 95: train_loss=1.1253, train_acc=0.5987, val_loss=1.2973, val_acc=0.5488\n",
      "Epoch 96: train_loss=1.1210, train_acc=0.6020, val_loss=1.3075, val_acc=0.5390\n",
      "Epoch 97: train_loss=1.1184, train_acc=0.6018, val_loss=1.2958, val_acc=0.5548\n",
      "Epoch 98: train_loss=1.1172, train_acc=0.6039, val_loss=1.2862, val_acc=0.5534\n",
      "Epoch 99: train_loss=1.1138, train_acc=0.6038, val_loss=1.2711, val_acc=0.5542\n",
      "Epoch 100: train_loss=1.1044, train_acc=0.6064, val_loss=1.2770, val_acc=0.5524\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.60644</td></tr><tr><td>train_loss</td><td>1.10443</td></tr><tr><td>val_acc</td><td>0.5524</td></tr><tr><td>val_loss</td><td>1.27704</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-sweep-19</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/14tpfi7w' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/14tpfi7w</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_045248-14tpfi7w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2ktcv7t4 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.008583338653007016\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_063514-2ktcv7t4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/2ktcv7t4' target=\"_blank\">zany-sweep-20</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/2ktcv7t4' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/2ktcv7t4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.1895, train_acc=0.2007, val_loss=2.0719, val_acc=0.2718\n",
      "Epoch 2: train_loss=2.0384, train_acc=0.2782, val_loss=1.9845, val_acc=0.3098\n",
      "Epoch 3: train_loss=1.9683, train_acc=0.3086, val_loss=1.9315, val_acc=0.3300\n",
      "Epoch 4: train_loss=1.9248, train_acc=0.3286, val_loss=1.8943, val_acc=0.3384\n",
      "Epoch 5: train_loss=1.8943, train_acc=0.3402, val_loss=1.8738, val_acc=0.3472\n",
      "Epoch 6: train_loss=1.8717, train_acc=0.3482, val_loss=1.8498, val_acc=0.3590\n",
      "Epoch 7: train_loss=1.8571, train_acc=0.3551, val_loss=1.8358, val_acc=0.3590\n",
      "Epoch 8: train_loss=1.8409, train_acc=0.3589, val_loss=1.8242, val_acc=0.3624\n",
      "Epoch 9: train_loss=1.8266, train_acc=0.3645, val_loss=1.8123, val_acc=0.3674\n",
      "Epoch 10: train_loss=1.8171, train_acc=0.3667, val_loss=1.8044, val_acc=0.3734\n",
      "Epoch 11: train_loss=1.8074, train_acc=0.3737, val_loss=1.7921, val_acc=0.3758\n",
      "Epoch 12: train_loss=1.8000, train_acc=0.3729, val_loss=1.7856, val_acc=0.3768\n",
      "Epoch 13: train_loss=1.7908, train_acc=0.3793, val_loss=1.7809, val_acc=0.3852\n",
      "Epoch 14: train_loss=1.7844, train_acc=0.3788, val_loss=1.7770, val_acc=0.3790\n",
      "Epoch 15: train_loss=1.7779, train_acc=0.3852, val_loss=1.7658, val_acc=0.3820\n",
      "Epoch 16: train_loss=1.7715, train_acc=0.3848, val_loss=1.7644, val_acc=0.3892\n",
      "Epoch 17: train_loss=1.7679, train_acc=0.3853, val_loss=1.7568, val_acc=0.3832\n",
      "Epoch 18: train_loss=1.7607, train_acc=0.3888, val_loss=1.7532, val_acc=0.3912\n",
      "Epoch 19: train_loss=1.7572, train_acc=0.3892, val_loss=1.7493, val_acc=0.3882\n",
      "Epoch 20: train_loss=1.7524, train_acc=0.3914, val_loss=1.7435, val_acc=0.3892\n",
      "Epoch 21: train_loss=1.7498, train_acc=0.3917, val_loss=1.7437, val_acc=0.3928\n",
      "Epoch 22: train_loss=1.7415, train_acc=0.3951, val_loss=1.7395, val_acc=0.3924\n",
      "Epoch 23: train_loss=1.7409, train_acc=0.3936, val_loss=1.7319, val_acc=0.3970\n",
      "Epoch 24: train_loss=1.7344, train_acc=0.3948, val_loss=1.7357, val_acc=0.3902\n",
      "Epoch 25: train_loss=1.7288, train_acc=0.3998, val_loss=1.7274, val_acc=0.4010\n",
      "Epoch 26: train_loss=1.7291, train_acc=0.3996, val_loss=1.7182, val_acc=0.4014\n",
      "Epoch 27: train_loss=1.7221, train_acc=0.4013, val_loss=1.7237, val_acc=0.3994\n",
      "Epoch 28: train_loss=1.7195, train_acc=0.4009, val_loss=1.7172, val_acc=0.4048\n",
      "Epoch 29: train_loss=1.7199, train_acc=0.4049, val_loss=1.7077, val_acc=0.4092\n",
      "Epoch 30: train_loss=1.7102, train_acc=0.4075, val_loss=1.7171, val_acc=0.3982\n",
      "Epoch 31: train_loss=1.7125, train_acc=0.4026, val_loss=1.7066, val_acc=0.4018\n",
      "Epoch 32: train_loss=1.7062, train_acc=0.4061, val_loss=1.7036, val_acc=0.4056\n",
      "Epoch 33: train_loss=1.7012, train_acc=0.4095, val_loss=1.6975, val_acc=0.4078\n",
      "Epoch 34: train_loss=1.6989, train_acc=0.4099, val_loss=1.6966, val_acc=0.4078\n",
      "Epoch 35: train_loss=1.6950, train_acc=0.4116, val_loss=1.6915, val_acc=0.4098\n",
      "Epoch 36: train_loss=1.6909, train_acc=0.4120, val_loss=1.6912, val_acc=0.4066\n",
      "Epoch 37: train_loss=1.6865, train_acc=0.4136, val_loss=1.6850, val_acc=0.4138\n",
      "Epoch 38: train_loss=1.6865, train_acc=0.4115, val_loss=1.6812, val_acc=0.4136\n",
      "Epoch 39: train_loss=1.6808, train_acc=0.4173, val_loss=1.6934, val_acc=0.4064\n",
      "Epoch 40: train_loss=1.6787, train_acc=0.4183, val_loss=1.6713, val_acc=0.4166\n",
      "Epoch 41: train_loss=1.6772, train_acc=0.4153, val_loss=1.6674, val_acc=0.4176\n",
      "Epoch 42: train_loss=1.6712, train_acc=0.4167, val_loss=1.6775, val_acc=0.4104\n",
      "Epoch 43: train_loss=1.6684, train_acc=0.4210, val_loss=1.6632, val_acc=0.4176\n",
      "Epoch 44: train_loss=1.6669, train_acc=0.4228, val_loss=1.6585, val_acc=0.4212\n",
      "Epoch 45: train_loss=1.6595, train_acc=0.4212, val_loss=1.6601, val_acc=0.4212\n",
      "Epoch 46: train_loss=1.6577, train_acc=0.4236, val_loss=1.6552, val_acc=0.4238\n",
      "Epoch 47: train_loss=1.6570, train_acc=0.4235, val_loss=1.6569, val_acc=0.4178\n",
      "Epoch 48: train_loss=1.6519, train_acc=0.4262, val_loss=1.6465, val_acc=0.4276\n",
      "Epoch 49: train_loss=1.6483, train_acc=0.4279, val_loss=1.6488, val_acc=0.4270\n",
      "Epoch 50: train_loss=1.6456, train_acc=0.4268, val_loss=1.6427, val_acc=0.4214\n",
      "Epoch 51: train_loss=1.6449, train_acc=0.4256, val_loss=1.6553, val_acc=0.4216\n",
      "Epoch 52: train_loss=1.6450, train_acc=0.4278, val_loss=1.6379, val_acc=0.4222\n",
      "Epoch 53: train_loss=1.6420, train_acc=0.4289, val_loss=1.6368, val_acc=0.4310\n",
      "Epoch 54: train_loss=1.6342, train_acc=0.4298, val_loss=1.6330, val_acc=0.4292\n",
      "Epoch 55: train_loss=1.6345, train_acc=0.4302, val_loss=1.6272, val_acc=0.4272\n",
      "Epoch 56: train_loss=1.6306, train_acc=0.4338, val_loss=1.6246, val_acc=0.4318\n",
      "Epoch 57: train_loss=1.6300, train_acc=0.4327, val_loss=1.6194, val_acc=0.4342\n",
      "Epoch 58: train_loss=1.6262, train_acc=0.4338, val_loss=1.6192, val_acc=0.4344\n",
      "Epoch 59: train_loss=1.6247, train_acc=0.4318, val_loss=1.6217, val_acc=0.4288\n",
      "Epoch 60: train_loss=1.6228, train_acc=0.4359, val_loss=1.6174, val_acc=0.4296\n",
      "Epoch 61: train_loss=1.6189, train_acc=0.4356, val_loss=1.6262, val_acc=0.4282\n",
      "Epoch 62: train_loss=1.6165, train_acc=0.4372, val_loss=1.6161, val_acc=0.4340\n",
      "Epoch 63: train_loss=1.6098, train_acc=0.4399, val_loss=1.6082, val_acc=0.4412\n",
      "Epoch 64: train_loss=1.6091, train_acc=0.4392, val_loss=1.6069, val_acc=0.4380\n",
      "Epoch 65: train_loss=1.6104, train_acc=0.4375, val_loss=1.6018, val_acc=0.4360\n",
      "Epoch 66: train_loss=1.6061, train_acc=0.4421, val_loss=1.6175, val_acc=0.4294\n",
      "Epoch 67: train_loss=1.6074, train_acc=0.4401, val_loss=1.5981, val_acc=0.4420\n",
      "Epoch 68: train_loss=1.6011, train_acc=0.4415, val_loss=1.5949, val_acc=0.4444\n",
      "Epoch 69: train_loss=1.6030, train_acc=0.4398, val_loss=1.5953, val_acc=0.4476\n",
      "Epoch 70: train_loss=1.5991, train_acc=0.4434, val_loss=1.5940, val_acc=0.4388\n",
      "Epoch 71: train_loss=1.5955, train_acc=0.4433, val_loss=1.5893, val_acc=0.4434\n",
      "Epoch 72: train_loss=1.5959, train_acc=0.4420, val_loss=1.6053, val_acc=0.4280\n",
      "Epoch 73: train_loss=1.5984, train_acc=0.4432, val_loss=1.5897, val_acc=0.4430\n",
      "Epoch 74: train_loss=1.5909, train_acc=0.4441, val_loss=1.5856, val_acc=0.4430\n",
      "Epoch 75: train_loss=1.5851, train_acc=0.4451, val_loss=1.5828, val_acc=0.4430\n",
      "Epoch 76: train_loss=1.5855, train_acc=0.4460, val_loss=1.5865, val_acc=0.4394\n",
      "Epoch 77: train_loss=1.5857, train_acc=0.4473, val_loss=1.5775, val_acc=0.4436\n",
      "Epoch 78: train_loss=1.5800, train_acc=0.4462, val_loss=1.5862, val_acc=0.4456\n",
      "Epoch 79: train_loss=1.5837, train_acc=0.4474, val_loss=1.5750, val_acc=0.4478\n",
      "Epoch 80: train_loss=1.5776, train_acc=0.4505, val_loss=1.5795, val_acc=0.4434\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>l2_loss</td><td>0.0026</td></tr><tr><td>train_acc</td><td>0.45048</td></tr><tr><td>train_loss</td><td>1.57762</td></tr><tr><td>val_acc</td><td>0.4434</td></tr><tr><td>val_loss</td><td>1.57948</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zany-sweep-20</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/2ktcv7t4' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/2ktcv7t4</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_063514-2ktcv7t4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bq7lq4kk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.02927067320289128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_064758-bq7lq4kk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/bq7lq4kk' target=\"_blank\">pleasant-sweep-21</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/bq7lq4kk' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/bq7lq4kk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.8017, train_acc=0.1005, val_loss=4.5448, val_acc=0.0998\n",
      "Epoch 2: train_loss=2.7850, train_acc=0.0987, val_loss=3.3019, val_acc=0.1066\n",
      "Epoch 3: train_loss=2.8353, train_acc=0.1002, val_loss=4.9739, val_acc=0.0980\n",
      "Epoch 4: train_loss=2.6901, train_acc=0.1028, val_loss=3.0217, val_acc=0.0980\n",
      "Epoch 5: train_loss=2.6973, train_acc=0.0998, val_loss=4.2208, val_acc=0.0990\n",
      "Epoch 6: train_loss=2.7011, train_acc=0.1002, val_loss=3.7386, val_acc=0.0990\n",
      "Epoch 7: train_loss=2.6993, train_acc=0.0972, val_loss=4.1164, val_acc=0.1000\n",
      "Epoch 8: train_loss=2.6751, train_acc=0.1000, val_loss=5.0938, val_acc=0.1066\n",
      "Epoch 9: train_loss=2.7339, train_acc=0.1025, val_loss=4.0486, val_acc=0.0990\n",
      "Epoch 10: train_loss=2.6874, train_acc=0.0984, val_loss=4.1178, val_acc=0.0984\n",
      "Epoch 11: train_loss=2.6571, train_acc=0.1022, val_loss=4.5675, val_acc=0.0990\n",
      "Epoch 12: train_loss=2.7308, train_acc=0.1001, val_loss=3.3032, val_acc=0.0974\n",
      "Epoch 13: train_loss=2.6770, train_acc=0.0994, val_loss=3.1227, val_acc=0.0980\n",
      "Epoch 14: train_loss=2.6953, train_acc=0.1006, val_loss=4.7740, val_acc=0.0990\n",
      "Epoch 15: train_loss=2.6938, train_acc=0.1003, val_loss=3.7489, val_acc=0.0984\n",
      "Epoch 16: train_loss=2.7193, train_acc=0.0997, val_loss=5.8503, val_acc=0.1066\n",
      "Epoch 17: train_loss=2.6963, train_acc=0.1008, val_loss=5.0049, val_acc=0.0990\n",
      "Epoch 18: train_loss=2.6866, train_acc=0.0979, val_loss=3.0885, val_acc=0.0998\n",
      "Epoch 19: train_loss=2.6644, train_acc=0.1015, val_loss=3.3131, val_acc=0.1028\n",
      "Epoch 20: train_loss=2.6896, train_acc=0.1006, val_loss=2.7422, val_acc=0.0998\n",
      "Epoch 21: train_loss=2.6834, train_acc=0.1005, val_loss=2.9896, val_acc=0.1028\n",
      "Epoch 22: train_loss=2.6760, train_acc=0.1004, val_loss=3.3324, val_acc=0.1028\n",
      "Epoch 23: train_loss=2.6885, train_acc=0.1004, val_loss=3.5830, val_acc=0.0980\n",
      "Epoch 24: train_loss=2.6923, train_acc=0.0990, val_loss=3.7941, val_acc=0.0990\n",
      "Epoch 25: train_loss=2.6839, train_acc=0.1004, val_loss=3.2921, val_acc=0.0990\n",
      "Epoch 26: train_loss=2.6834, train_acc=0.1010, val_loss=3.4734, val_acc=0.0980\n",
      "Epoch 27: train_loss=2.6747, train_acc=0.0999, val_loss=3.7789, val_acc=0.1028\n",
      "Epoch 28: train_loss=2.6723, train_acc=0.0996, val_loss=3.5088, val_acc=0.0990\n",
      "Epoch 29: train_loss=2.6911, train_acc=0.1002, val_loss=3.1672, val_acc=0.0984\n",
      "Epoch 30: train_loss=2.6704, train_acc=0.0991, val_loss=3.3316, val_acc=0.0998\n",
      "Epoch 31: train_loss=2.6879, train_acc=0.0998, val_loss=3.3339, val_acc=0.1000\n",
      "Epoch 32: train_loss=2.6738, train_acc=0.1005, val_loss=3.8492, val_acc=0.0980\n",
      "Epoch 33: train_loss=2.6619, train_acc=0.1016, val_loss=3.9030, val_acc=0.1000\n",
      "Epoch 34: train_loss=2.6797, train_acc=0.1010, val_loss=4.8977, val_acc=0.0984\n",
      "Epoch 35: train_loss=2.7091, train_acc=0.1011, val_loss=3.5196, val_acc=0.0990\n",
      "Epoch 36: train_loss=2.6933, train_acc=0.0998, val_loss=3.2933, val_acc=0.1000\n",
      "Epoch 37: train_loss=2.6913, train_acc=0.1018, val_loss=4.9151, val_acc=0.0984\n",
      "Epoch 38: train_loss=2.7691, train_acc=0.1014, val_loss=6.3142, val_acc=0.0998\n",
      "Epoch 39: train_loss=2.6935, train_acc=0.0991, val_loss=4.5114, val_acc=0.1000\n",
      "Epoch 40: train_loss=2.6797, train_acc=0.1014, val_loss=3.7633, val_acc=0.1066\n",
      "Epoch 41: train_loss=2.6947, train_acc=0.1003, val_loss=4.2620, val_acc=0.0990\n",
      "Epoch 42: train_loss=2.6784, train_acc=0.0996, val_loss=4.1627, val_acc=0.0998\n",
      "Epoch 43: train_loss=2.6868, train_acc=0.1003, val_loss=3.7567, val_acc=0.0990\n",
      "Epoch 44: train_loss=2.7017, train_acc=0.0993, val_loss=3.6400, val_acc=0.0980\n",
      "Epoch 45: train_loss=2.6797, train_acc=0.1012, val_loss=4.8826, val_acc=0.0990\n",
      "Epoch 46: train_loss=2.6977, train_acc=0.1008, val_loss=3.7347, val_acc=0.0990\n",
      "Epoch 47: train_loss=2.6760, train_acc=0.0987, val_loss=3.0106, val_acc=0.0984\n",
      "Epoch 48: train_loss=2.6703, train_acc=0.1000, val_loss=5.3491, val_acc=0.0990\n",
      "Epoch 49: train_loss=2.6930, train_acc=0.1006, val_loss=3.0913, val_acc=0.0984\n",
      "Epoch 50: train_loss=2.6709, train_acc=0.0977, val_loss=2.9949, val_acc=0.0990\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>l2_loss</td><td>0.01911</td></tr><tr><td>train_acc</td><td>0.09773</td></tr><tr><td>train_loss</td><td>2.67094</td></tr><tr><td>val_acc</td><td>0.099</td></tr><tr><td>val_loss</td><td>2.99493</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pleasant-sweep-21</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/bq7lq4kk' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/bq7lq4kk</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_064758-bq7lq4kk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: i6mpjg4v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.031691422066139355\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_083556-i6mpjg4v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/i6mpjg4v' target=\"_blank\">neat-sweep-22</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/i6mpjg4v' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/i6mpjg4v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=3.4679, train_acc=0.1013, val_loss=4.4637, val_acc=0.0806\n",
      "Epoch 2: train_loss=2.9062, train_acc=0.1006, val_loss=3.0179, val_acc=0.0984\n",
      "Epoch 3: train_loss=2.6510, train_acc=0.1024, val_loss=5.3724, val_acc=0.1066\n",
      "Epoch 4: train_loss=4.1096, train_acc=0.1014, val_loss=2.7243, val_acc=0.0990\n",
      "Epoch 5: train_loss=2.4724, train_acc=0.1031, val_loss=2.4429, val_acc=0.1176\n",
      "Epoch 6: train_loss=2.5228, train_acc=0.1029, val_loss=2.9422, val_acc=0.1028\n",
      "Epoch 7: train_loss=3.6998, train_acc=0.0991, val_loss=4.8751, val_acc=0.0992\n",
      "Epoch 8: train_loss=2.9617, train_acc=0.0970, val_loss=2.7284, val_acc=0.1028\n",
      "Epoch 9: train_loss=2.4952, train_acc=0.1007, val_loss=2.5997, val_acc=0.1066\n",
      "Epoch 10: train_loss=2.5032, train_acc=0.1013, val_loss=2.4430, val_acc=0.0990\n",
      "Epoch 11: train_loss=2.5395, train_acc=0.0995, val_loss=2.6416, val_acc=0.0990\n",
      "Epoch 12: train_loss=2.5564, train_acc=0.0985, val_loss=2.9076, val_acc=0.0990\n",
      "Epoch 13: train_loss=4.1766, train_acc=0.1033, val_loss=3.7968, val_acc=0.0988\n",
      "Epoch 14: train_loss=2.6137, train_acc=0.1011, val_loss=2.4273, val_acc=0.1000\n",
      "Epoch 15: train_loss=2.5039, train_acc=0.1022, val_loss=2.5887, val_acc=0.1066\n",
      "Epoch 16: train_loss=2.5190, train_acc=0.1009, val_loss=2.8104, val_acc=0.0990\n",
      "Epoch 17: train_loss=2.5442, train_acc=0.1015, val_loss=3.2744, val_acc=0.0984\n",
      "Epoch 18: train_loss=2.5418, train_acc=0.1029, val_loss=2.5282, val_acc=0.1066\n",
      "Epoch 19: train_loss=2.6248, train_acc=0.1021, val_loss=2.6328, val_acc=0.0980\n",
      "Epoch 20: train_loss=2.5885, train_acc=0.0996, val_loss=3.0731, val_acc=0.0984\n",
      "Epoch 21: train_loss=2.6009, train_acc=0.0983, val_loss=2.7306, val_acc=0.0990\n",
      "Epoch 22: train_loss=2.6214, train_acc=0.1013, val_loss=2.9884, val_acc=0.0990\n",
      "Epoch 23: train_loss=2.5699, train_acc=0.1003, val_loss=2.6223, val_acc=0.1028\n",
      "Epoch 24: train_loss=2.6373, train_acc=0.1007, val_loss=2.5818, val_acc=0.0990\n",
      "Epoch 25: train_loss=2.6042, train_acc=0.1035, val_loss=2.5347, val_acc=0.0998\n",
      "Epoch 26: train_loss=2.5619, train_acc=0.1020, val_loss=2.9357, val_acc=0.0974\n",
      "Epoch 27: train_loss=2.6049, train_acc=0.0994, val_loss=2.9200, val_acc=0.0980\n",
      "Epoch 28: train_loss=4.6414, train_acc=0.1008, val_loss=2.6510, val_acc=0.1028\n",
      "Epoch 29: train_loss=2.5232, train_acc=0.0994, val_loss=2.6530, val_acc=0.0990\n",
      "Epoch 30: train_loss=2.5355, train_acc=0.1010, val_loss=2.4739, val_acc=0.1000\n",
      "Epoch 31: train_loss=2.5438, train_acc=0.1026, val_loss=2.9221, val_acc=0.0990\n",
      "Epoch 32: train_loss=2.5811, train_acc=0.0998, val_loss=2.6285, val_acc=0.0980\n",
      "Epoch 33: train_loss=2.5378, train_acc=0.1026, val_loss=2.5466, val_acc=0.0974\n",
      "Epoch 34: train_loss=2.5813, train_acc=0.1005, val_loss=2.7017, val_acc=0.0984\n",
      "Epoch 35: train_loss=2.5533, train_acc=0.1033, val_loss=3.0890, val_acc=0.0990\n",
      "Epoch 36: train_loss=2.6237, train_acc=0.1003, val_loss=2.6998, val_acc=0.0990\n",
      "Epoch 37: train_loss=2.5798, train_acc=0.1013, val_loss=2.9240, val_acc=0.1000\n",
      "Epoch 38: train_loss=2.5955, train_acc=0.1044, val_loss=2.8925, val_acc=0.0984\n",
      "Epoch 39: train_loss=2.5868, train_acc=0.1031, val_loss=3.2744, val_acc=0.1000\n",
      "Epoch 40: train_loss=2.5846, train_acc=0.1011, val_loss=2.4048, val_acc=0.0974\n",
      "Epoch 41: train_loss=2.5408, train_acc=0.0999, val_loss=2.8732, val_acc=0.0990\n",
      "Epoch 42: train_loss=2.5889, train_acc=0.0993, val_loss=2.7296, val_acc=0.0974\n",
      "Epoch 43: train_loss=2.7437, train_acc=0.0995, val_loss=2.6522, val_acc=0.1028\n",
      "Epoch 44: train_loss=2.5529, train_acc=0.1015, val_loss=2.5067, val_acc=0.0974\n",
      "Epoch 45: train_loss=2.6487, train_acc=0.0997, val_loss=2.7870, val_acc=0.0998\n",
      "Epoch 46: train_loss=2.5671, train_acc=0.1004, val_loss=2.6321, val_acc=0.0980\n",
      "Epoch 47: train_loss=2.5823, train_acc=0.1022, val_loss=2.5963, val_acc=0.1028\n",
      "Epoch 48: train_loss=2.6107, train_acc=0.0997, val_loss=2.7316, val_acc=0.0990\n",
      "Epoch 49: train_loss=2.5784, train_acc=0.1001, val_loss=2.5200, val_acc=0.1028\n",
      "Epoch 50: train_loss=2.5949, train_acc=0.1004, val_loss=2.4467, val_acc=0.1066\n",
      "Epoch 51: train_loss=2.7748, train_acc=0.1003, val_loss=2.7820, val_acc=0.0974\n",
      "Epoch 52: train_loss=2.5506, train_acc=0.1014, val_loss=2.9716, val_acc=0.1028\n",
      "Epoch 53: train_loss=2.5753, train_acc=0.0988, val_loss=3.0728, val_acc=0.1028\n",
      "Epoch 54: train_loss=2.5884, train_acc=0.1027, val_loss=2.7201, val_acc=0.0990\n",
      "Epoch 55: train_loss=2.5735, train_acc=0.0997, val_loss=2.5896, val_acc=0.1066\n",
      "Epoch 56: train_loss=2.6327, train_acc=0.0995, val_loss=2.8518, val_acc=0.0990\n",
      "Epoch 57: train_loss=2.5693, train_acc=0.1013, val_loss=2.6890, val_acc=0.0974\n",
      "Epoch 58: train_loss=2.5830, train_acc=0.1021, val_loss=2.8742, val_acc=0.0974\n",
      "Epoch 59: train_loss=2.6167, train_acc=0.1011, val_loss=2.7960, val_acc=0.0984\n",
      "Epoch 60: train_loss=2.6191, train_acc=0.0997, val_loss=2.8309, val_acc=0.0990\n",
      "Epoch 61: train_loss=2.6059, train_acc=0.1018, val_loss=2.6070, val_acc=0.0980\n",
      "Epoch 62: train_loss=2.6249, train_acc=0.0990, val_loss=2.8267, val_acc=0.0974\n",
      "Epoch 63: train_loss=2.5713, train_acc=0.1023, val_loss=2.5318, val_acc=0.0974\n",
      "Epoch 64: train_loss=2.5550, train_acc=0.0979, val_loss=2.8684, val_acc=0.0980\n",
      "Epoch 65: train_loss=2.5807, train_acc=0.1033, val_loss=2.5910, val_acc=0.0980\n",
      "Epoch 66: train_loss=2.5667, train_acc=0.0996, val_loss=3.0397, val_acc=0.0990\n",
      "Epoch 67: train_loss=2.6722, train_acc=0.0982, val_loss=2.6340, val_acc=0.1000\n",
      "Epoch 68: train_loss=2.5452, train_acc=0.0992, val_loss=2.8790, val_acc=0.0990\n",
      "Epoch 69: train_loss=2.6756, train_acc=0.0993, val_loss=2.8984, val_acc=0.0990\n",
      "Epoch 70: train_loss=2.5848, train_acc=0.1004, val_loss=3.0982, val_acc=0.0990\n",
      "Epoch 71: train_loss=2.6267, train_acc=0.1006, val_loss=3.2048, val_acc=0.0974\n",
      "Epoch 72: train_loss=2.5997, train_acc=0.0999, val_loss=2.7735, val_acc=0.1028\n",
      "Epoch 73: train_loss=2.5892, train_acc=0.0998, val_loss=2.6804, val_acc=0.0990\n",
      "Epoch 74: train_loss=2.6065, train_acc=0.0998, val_loss=2.6170, val_acc=0.0990\n",
      "Epoch 75: train_loss=2.6066, train_acc=0.1017, val_loss=2.7907, val_acc=0.1028\n",
      "Epoch 76: train_loss=2.5690, train_acc=0.1016, val_loss=2.6893, val_acc=0.1028\n",
      "Epoch 77: train_loss=2.6268, train_acc=0.1004, val_loss=2.7641, val_acc=0.0990\n",
      "Epoch 78: train_loss=2.6128, train_acc=0.1016, val_loss=2.9585, val_acc=0.0998\n",
      "Epoch 79: train_loss=2.5543, train_acc=0.1034, val_loss=2.4544, val_acc=0.0980\n",
      "Epoch 80: train_loss=2.6464, train_acc=0.0989, val_loss=2.6842, val_acc=0.0990\n",
      "Epoch 81: train_loss=2.5729, train_acc=0.0977, val_loss=2.5464, val_acc=0.1000\n",
      "Epoch 82: train_loss=2.6070, train_acc=0.1011, val_loss=2.7463, val_acc=0.0990\n",
      "Epoch 83: train_loss=2.5830, train_acc=0.0999, val_loss=2.5348, val_acc=0.0990\n",
      "Epoch 84: train_loss=2.5359, train_acc=0.1000, val_loss=2.6667, val_acc=0.0980\n",
      "Epoch 85: train_loss=2.5905, train_acc=0.1009, val_loss=2.6583, val_acc=0.0974\n",
      "Epoch 86: train_loss=2.6618, train_acc=0.1012, val_loss=2.8420, val_acc=0.0976\n",
      "Epoch 87: train_loss=4.0741, train_acc=0.0999, val_loss=2.3513, val_acc=0.0974\n",
      "Epoch 88: train_loss=2.5129, train_acc=0.0999, val_loss=2.7153, val_acc=0.0974\n",
      "Epoch 89: train_loss=2.5159, train_acc=0.1001, val_loss=2.7043, val_acc=0.0990\n",
      "Epoch 90: train_loss=2.5194, train_acc=0.1017, val_loss=2.6534, val_acc=0.1028\n",
      "Epoch 91: train_loss=2.5662, train_acc=0.1032, val_loss=2.4414, val_acc=0.1000\n",
      "Epoch 92: train_loss=2.5975, train_acc=0.1001, val_loss=3.0479, val_acc=0.1028\n",
      "Epoch 93: train_loss=2.5849, train_acc=0.0985, val_loss=2.7816, val_acc=0.0990\n",
      "Epoch 94: train_loss=2.5686, train_acc=0.1002, val_loss=2.7615, val_acc=0.0984\n",
      "Epoch 95: train_loss=2.5881, train_acc=0.1023, val_loss=3.0094, val_acc=0.0998\n",
      "Epoch 96: train_loss=2.5868, train_acc=0.0994, val_loss=2.8167, val_acc=0.1000\n",
      "Epoch 97: train_loss=2.5879, train_acc=0.0989, val_loss=2.6923, val_acc=0.0998\n",
      "Epoch 98: train_loss=2.5881, train_acc=0.1001, val_loss=2.4531, val_acc=0.0990\n",
      "Epoch 99: train_loss=2.5428, train_acc=0.0990, val_loss=2.5875, val_acc=0.0990\n",
      "Epoch 100: train_loss=2.5925, train_acc=0.0996, val_loss=2.8743, val_acc=0.0974\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>l2_loss</td><td>0.01422</td></tr><tr><td>train_acc</td><td>0.09962</td></tr><tr><td>train_loss</td><td>2.59254</td></tr><tr><td>val_acc</td><td>0.0974</td></tr><tr><td>val_loss</td><td>2.87425</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">neat-sweep-22</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/i6mpjg4v' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/i6mpjg4v</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_083556-i6mpjg4v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4blf810w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 80\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.08306581617029336\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_095402-4blf810w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/4blf810w' target=\"_blank\">zesty-sweep-23</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/4blf810w' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/4blf810w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=3.1984, train_acc=0.1000, val_loss=2.3045, val_acc=0.0998\n",
      "Epoch 2: train_loss=2.3230, train_acc=0.1016, val_loss=2.3033, val_acc=0.0990\n",
      "Epoch 3: train_loss=2.3190, train_acc=0.0990, val_loss=2.3078, val_acc=0.0984\n",
      "Epoch 4: train_loss=2.3197, train_acc=0.1027, val_loss=2.3048, val_acc=0.0990\n",
      "Epoch 5: train_loss=2.3193, train_acc=0.1008, val_loss=2.3046, val_acc=0.0990\n",
      "Epoch 6: train_loss=2.3187, train_acc=0.0992, val_loss=2.3045, val_acc=0.1000\n",
      "Epoch 7: train_loss=2.3211, train_acc=0.1006, val_loss=2.3065, val_acc=0.0984\n",
      "Epoch 8: train_loss=2.3217, train_acc=0.1011, val_loss=2.3052, val_acc=0.0980\n",
      "Epoch 9: train_loss=2.3213, train_acc=0.0978, val_loss=2.3042, val_acc=0.1028\n",
      "Epoch 10: train_loss=2.3196, train_acc=0.1000, val_loss=2.3050, val_acc=0.1028\n",
      "Epoch 11: train_loss=2.3194, train_acc=0.1002, val_loss=2.3075, val_acc=0.0990\n",
      "Epoch 12: train_loss=2.3184, train_acc=0.1018, val_loss=2.3053, val_acc=0.1000\n",
      "Epoch 13: train_loss=2.3198, train_acc=0.0985, val_loss=2.3043, val_acc=0.0990\n",
      "Epoch 14: train_loss=2.3192, train_acc=0.1012, val_loss=2.3051, val_acc=0.0974\n",
      "Epoch 15: train_loss=2.3194, train_acc=0.0998, val_loss=2.3035, val_acc=0.0990\n",
      "Epoch 16: train_loss=2.3198, train_acc=0.0971, val_loss=2.3029, val_acc=0.1028\n",
      "Epoch 17: train_loss=2.3190, train_acc=0.1012, val_loss=2.3073, val_acc=0.0990\n",
      "Epoch 18: train_loss=2.3204, train_acc=0.0976, val_loss=2.3083, val_acc=0.0990\n",
      "Epoch 19: train_loss=2.3193, train_acc=0.0984, val_loss=2.3038, val_acc=0.0990\n",
      "Epoch 20: train_loss=2.3211, train_acc=0.1013, val_loss=2.3035, val_acc=0.1066\n",
      "Epoch 21: train_loss=2.3190, train_acc=0.1012, val_loss=2.3068, val_acc=0.0990\n",
      "Epoch 22: train_loss=2.3193, train_acc=0.1001, val_loss=2.3058, val_acc=0.0990\n",
      "Epoch 23: train_loss=2.3198, train_acc=0.1024, val_loss=2.3096, val_acc=0.0974\n",
      "Epoch 24: train_loss=2.3192, train_acc=0.0990, val_loss=2.3047, val_acc=0.0998\n",
      "Epoch 25: train_loss=2.3191, train_acc=0.1022, val_loss=2.3039, val_acc=0.0998\n",
      "Epoch 26: train_loss=2.3191, train_acc=0.0982, val_loss=2.3043, val_acc=0.0990\n",
      "Epoch 27: train_loss=2.3199, train_acc=0.1003, val_loss=2.3093, val_acc=0.0984\n",
      "Epoch 28: train_loss=2.3202, train_acc=0.0994, val_loss=2.3063, val_acc=0.0984\n",
      "Epoch 29: train_loss=2.3188, train_acc=0.0989, val_loss=2.3076, val_acc=0.0974\n",
      "Epoch 30: train_loss=2.3202, train_acc=0.1007, val_loss=2.3056, val_acc=0.0974\n",
      "Epoch 31: train_loss=2.3190, train_acc=0.0995, val_loss=2.3051, val_acc=0.1028\n",
      "Epoch 32: train_loss=2.3197, train_acc=0.1016, val_loss=2.3056, val_acc=0.1000\n",
      "Epoch 33: train_loss=2.3200, train_acc=0.0987, val_loss=2.3068, val_acc=0.0990\n",
      "Epoch 34: train_loss=2.3205, train_acc=0.0974, val_loss=2.3063, val_acc=0.1000\n",
      "Epoch 35: train_loss=2.3200, train_acc=0.0995, val_loss=2.3067, val_acc=0.0980\n",
      "Epoch 36: train_loss=2.3203, train_acc=0.0996, val_loss=2.3062, val_acc=0.0998\n",
      "Epoch 37: train_loss=2.3193, train_acc=0.1008, val_loss=2.3073, val_acc=0.0990\n",
      "Epoch 38: train_loss=2.3191, train_acc=0.1015, val_loss=2.3040, val_acc=0.1028\n",
      "Epoch 39: train_loss=2.3195, train_acc=0.1001, val_loss=2.3042, val_acc=0.1066\n",
      "Epoch 40: train_loss=2.3194, train_acc=0.1006, val_loss=2.3051, val_acc=0.0984\n",
      "Epoch 41: train_loss=2.3211, train_acc=0.0997, val_loss=2.3048, val_acc=0.0980\n",
      "Epoch 42: train_loss=2.3189, train_acc=0.1015, val_loss=2.3061, val_acc=0.0990\n",
      "Epoch 43: train_loss=2.3188, train_acc=0.1005, val_loss=2.3056, val_acc=0.1000\n",
      "Epoch 44: train_loss=2.3192, train_acc=0.1008, val_loss=2.3050, val_acc=0.1000\n",
      "Epoch 45: train_loss=2.3198, train_acc=0.1006, val_loss=2.3058, val_acc=0.1028\n",
      "Epoch 46: train_loss=2.3200, train_acc=0.1004, val_loss=2.3049, val_acc=0.1066\n",
      "Epoch 47: train_loss=2.3195, train_acc=0.1004, val_loss=2.3063, val_acc=0.0984\n",
      "Epoch 48: train_loss=2.3198, train_acc=0.1020, val_loss=2.3033, val_acc=0.1066\n",
      "Epoch 49: train_loss=2.3189, train_acc=0.1002, val_loss=2.3044, val_acc=0.0990\n",
      "Epoch 50: train_loss=2.3201, train_acc=0.0994, val_loss=2.3108, val_acc=0.0974\n",
      "Epoch 51: train_loss=2.3195, train_acc=0.1003, val_loss=2.3107, val_acc=0.0974\n",
      "Epoch 52: train_loss=2.3202, train_acc=0.1024, val_loss=2.3111, val_acc=0.0990\n",
      "Epoch 53: train_loss=2.3199, train_acc=0.0991, val_loss=2.3125, val_acc=0.0990\n",
      "Epoch 54: train_loss=2.3194, train_acc=0.1008, val_loss=2.3101, val_acc=0.0998\n",
      "Epoch 55: train_loss=2.3190, train_acc=0.1019, val_loss=2.3133, val_acc=0.1066\n",
      "Epoch 56: train_loss=2.3196, train_acc=0.0988, val_loss=2.3106, val_acc=0.0990\n",
      "Epoch 57: train_loss=2.3198, train_acc=0.0994, val_loss=2.3127, val_acc=0.0974\n",
      "Epoch 58: train_loss=2.3195, train_acc=0.0988, val_loss=2.3118, val_acc=0.0974\n",
      "Epoch 59: train_loss=2.3193, train_acc=0.1011, val_loss=2.3150, val_acc=0.0980\n",
      "Epoch 60: train_loss=2.3202, train_acc=0.1007, val_loss=2.3122, val_acc=0.1000\n",
      "Epoch 61: train_loss=2.3197, train_acc=0.1021, val_loss=2.3095, val_acc=0.1028\n",
      "Epoch 62: train_loss=2.3193, train_acc=0.1019, val_loss=2.3090, val_acc=0.0990\n",
      "Epoch 63: train_loss=2.3186, train_acc=0.1025, val_loss=2.3138, val_acc=0.0974\n",
      "Epoch 64: train_loss=2.3190, train_acc=0.1010, val_loss=2.3093, val_acc=0.0974\n",
      "Epoch 65: train_loss=2.3193, train_acc=0.1003, val_loss=2.3095, val_acc=0.0990\n",
      "Epoch 66: train_loss=2.3200, train_acc=0.0979, val_loss=2.3113, val_acc=0.0980\n",
      "Epoch 67: train_loss=2.3196, train_acc=0.1013, val_loss=2.3106, val_acc=0.1066\n",
      "Epoch 68: train_loss=2.3195, train_acc=0.1027, val_loss=2.3107, val_acc=0.0988\n",
      "Epoch 69: train_loss=2.3193, train_acc=0.1021, val_loss=2.3103, val_acc=0.0984\n",
      "Epoch 70: train_loss=2.3197, train_acc=0.0991, val_loss=2.3117, val_acc=0.0998\n",
      "Epoch 71: train_loss=2.3200, train_acc=0.1018, val_loss=2.3122, val_acc=0.0980\n",
      "Epoch 72: train_loss=2.3190, train_acc=0.1006, val_loss=2.3108, val_acc=0.0980\n",
      "Epoch 73: train_loss=2.3193, train_acc=0.1002, val_loss=2.3093, val_acc=0.0990\n",
      "Epoch 74: train_loss=2.3201, train_acc=0.1004, val_loss=2.3108, val_acc=0.0984\n",
      "Epoch 75: train_loss=2.3197, train_acc=0.0993, val_loss=2.3141, val_acc=0.0980\n",
      "Epoch 76: train_loss=2.3193, train_acc=0.0983, val_loss=2.3149, val_acc=0.0998\n",
      "Epoch 77: train_loss=2.3199, train_acc=0.0995, val_loss=2.3152, val_acc=0.0984\n",
      "Epoch 78: train_loss=2.3196, train_acc=0.0994, val_loss=2.3168, val_acc=0.0974\n",
      "Epoch 79: train_loss=2.3195, train_acc=0.1027, val_loss=2.3170, val_acc=0.0974\n",
      "Epoch 80: train_loss=2.3191, train_acc=0.1021, val_loss=2.3186, val_acc=0.0990\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>80</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.10212</td></tr><tr><td>train_loss</td><td>2.31914</td></tr><tr><td>val_acc</td><td>0.099</td></tr><tr><td>val_loss</td><td>2.3186</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">zesty-sweep-23</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/4blf810w' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/4blf810w</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_095402-4blf810w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jvd5ghkx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0667988599268556\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: sgd\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_103030-jvd5ghkx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/jvd5ghkx' target=\"_blank\">restful-sweep-24</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/jvd5ghkx' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/jvd5ghkx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.2076, train_acc=0.2071, val_loss=1.9454, val_acc=0.3010\n",
      "Epoch 2: train_loss=1.9891, train_acc=0.2894, val_loss=1.8755, val_acc=0.3322\n",
      "Epoch 3: train_loss=1.9277, train_acc=0.3139, val_loss=1.9589, val_acc=0.3014\n",
      "Epoch 4: train_loss=1.8959, train_acc=0.3253, val_loss=1.8873, val_acc=0.3194\n",
      "Epoch 5: train_loss=1.8682, train_acc=0.3376, val_loss=1.8724, val_acc=0.3458\n",
      "Epoch 6: train_loss=1.8515, train_acc=0.3444, val_loss=1.8912, val_acc=0.3132\n",
      "Epoch 7: train_loss=1.8378, train_acc=0.3516, val_loss=1.8060, val_acc=0.3590\n",
      "Epoch 8: train_loss=1.8222, train_acc=0.3558, val_loss=1.9479, val_acc=0.3074\n",
      "Epoch 9: train_loss=1.8116, train_acc=0.3596, val_loss=1.9080, val_acc=0.3158\n",
      "Epoch 10: train_loss=1.8035, train_acc=0.3645, val_loss=1.8049, val_acc=0.3594\n",
      "Epoch 11: train_loss=1.7967, train_acc=0.3670, val_loss=1.8355, val_acc=0.3414\n",
      "Epoch 12: train_loss=1.7896, train_acc=0.3687, val_loss=1.8528, val_acc=0.3274\n",
      "Epoch 13: train_loss=1.7796, train_acc=0.3755, val_loss=1.8222, val_acc=0.3568\n",
      "Epoch 14: train_loss=1.7750, train_acc=0.3735, val_loss=1.8064, val_acc=0.3528\n",
      "Epoch 15: train_loss=1.7682, train_acc=0.3805, val_loss=2.1578, val_acc=0.2626\n",
      "Epoch 16: train_loss=1.7649, train_acc=0.3810, val_loss=1.8214, val_acc=0.3442\n",
      "Epoch 17: train_loss=1.7579, train_acc=0.3814, val_loss=1.7572, val_acc=0.3904\n",
      "Epoch 18: train_loss=1.7547, train_acc=0.3857, val_loss=1.7722, val_acc=0.3668\n",
      "Epoch 19: train_loss=1.7512, train_acc=0.3855, val_loss=1.7801, val_acc=0.3704\n",
      "Epoch 20: train_loss=1.7493, train_acc=0.3888, val_loss=1.8031, val_acc=0.3684\n",
      "Epoch 21: train_loss=1.7412, train_acc=0.3894, val_loss=1.7794, val_acc=0.3676\n",
      "Epoch 22: train_loss=1.7381, train_acc=0.3913, val_loss=1.7539, val_acc=0.3814\n",
      "Epoch 23: train_loss=1.7349, train_acc=0.3933, val_loss=1.9465, val_acc=0.3166\n",
      "Epoch 24: train_loss=1.7328, train_acc=0.3947, val_loss=1.8946, val_acc=0.3076\n",
      "Epoch 25: train_loss=1.7282, train_acc=0.3928, val_loss=1.7551, val_acc=0.3846\n",
      "Epoch 26: train_loss=1.7284, train_acc=0.3926, val_loss=1.7723, val_acc=0.3744\n",
      "Epoch 27: train_loss=1.7228, train_acc=0.3987, val_loss=1.7079, val_acc=0.3906\n",
      "Epoch 28: train_loss=1.7160, train_acc=0.3981, val_loss=1.7814, val_acc=0.3626\n",
      "Epoch 29: train_loss=1.7147, train_acc=0.4010, val_loss=1.9755, val_acc=0.2888\n",
      "Epoch 30: train_loss=1.7145, train_acc=0.4042, val_loss=1.7039, val_acc=0.4054\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.40418</td></tr><tr><td>train_loss</td><td>1.71447</td></tr><tr><td>val_acc</td><td>0.4054</td></tr><tr><td>val_loss</td><td>1.7039</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">restful-sweep-24</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/jvd5ghkx' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/jvd5ghkx</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_103030-jvd5ghkx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: q2a4hkbp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 100\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07390081903239329\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_103801-q2a4hkbp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/q2a4hkbp' target=\"_blank\">laced-sweep-25</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/q2a4hkbp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/q2a4hkbp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.2639, train_acc=0.1625, val_loss=2.1604, val_acc=0.2416\n",
      "Epoch 2: train_loss=2.1420, train_acc=0.2255, val_loss=2.0329, val_acc=0.2814\n",
      "Epoch 3: train_loss=2.0521, train_acc=0.2554, val_loss=1.9597, val_acc=0.3038\n",
      "Epoch 4: train_loss=1.9968, train_acc=0.2800, val_loss=1.9150, val_acc=0.3264\n",
      "Epoch 5: train_loss=1.9568, train_acc=0.3000, val_loss=1.8836, val_acc=0.3318\n",
      "Epoch 6: train_loss=1.9253, train_acc=0.3102, val_loss=1.8603, val_acc=0.3410\n",
      "Epoch 7: train_loss=1.8998, train_acc=0.3246, val_loss=1.8377, val_acc=0.3444\n",
      "Epoch 8: train_loss=1.8777, train_acc=0.3320, val_loss=1.8177, val_acc=0.3484\n",
      "Epoch 9: train_loss=1.8573, train_acc=0.3396, val_loss=1.7980, val_acc=0.3596\n",
      "Epoch 10: train_loss=1.8395, train_acc=0.3470, val_loss=1.7773, val_acc=0.3652\n",
      "Epoch 11: train_loss=1.8197, train_acc=0.3568, val_loss=1.7563, val_acc=0.3696\n",
      "Epoch 12: train_loss=1.8002, train_acc=0.3602, val_loss=1.7382, val_acc=0.3756\n",
      "Epoch 13: train_loss=1.7836, train_acc=0.3685, val_loss=1.7228, val_acc=0.3806\n",
      "Epoch 14: train_loss=1.7708, train_acc=0.3766, val_loss=1.7135, val_acc=0.3826\n",
      "Epoch 15: train_loss=1.7561, train_acc=0.3784, val_loss=1.6971, val_acc=0.3906\n",
      "Epoch 16: train_loss=1.7405, train_acc=0.3853, val_loss=1.6828, val_acc=0.3948\n",
      "Epoch 17: train_loss=1.7306, train_acc=0.3878, val_loss=1.6691, val_acc=0.3994\n",
      "Epoch 18: train_loss=1.7210, train_acc=0.3934, val_loss=1.6613, val_acc=0.4034\n",
      "Epoch 19: train_loss=1.7054, train_acc=0.3967, val_loss=1.6504, val_acc=0.4094\n",
      "Epoch 20: train_loss=1.6969, train_acc=0.3989, val_loss=1.6423, val_acc=0.4120\n",
      "Epoch 21: train_loss=1.6872, train_acc=0.4020, val_loss=1.6304, val_acc=0.4112\n",
      "Epoch 22: train_loss=1.6783, train_acc=0.4085, val_loss=1.6221, val_acc=0.4192\n",
      "Epoch 23: train_loss=1.6700, train_acc=0.4089, val_loss=1.6122, val_acc=0.4166\n",
      "Epoch 24: train_loss=1.6576, train_acc=0.4141, val_loss=1.6048, val_acc=0.4254\n",
      "Epoch 25: train_loss=1.6476, train_acc=0.4202, val_loss=1.5970, val_acc=0.4230\n",
      "Epoch 26: train_loss=1.6389, train_acc=0.4218, val_loss=1.5885, val_acc=0.4310\n",
      "Epoch 27: train_loss=1.6315, train_acc=0.4261, val_loss=1.5814, val_acc=0.4312\n",
      "Epoch 28: train_loss=1.6221, train_acc=0.4294, val_loss=1.5710, val_acc=0.4374\n",
      "Epoch 29: train_loss=1.6132, train_acc=0.4322, val_loss=1.5637, val_acc=0.4372\n",
      "Epoch 30: train_loss=1.6073, train_acc=0.4336, val_loss=1.5574, val_acc=0.4428\n",
      "Epoch 31: train_loss=1.5995, train_acc=0.4357, val_loss=1.5537, val_acc=0.4490\n",
      "Epoch 32: train_loss=1.5909, train_acc=0.4382, val_loss=1.5420, val_acc=0.4486\n",
      "Epoch 33: train_loss=1.5830, train_acc=0.4438, val_loss=1.5377, val_acc=0.4524\n",
      "Epoch 34: train_loss=1.5748, train_acc=0.4460, val_loss=1.5268, val_acc=0.4552\n",
      "Epoch 35: train_loss=1.5689, train_acc=0.4483, val_loss=1.5285, val_acc=0.4562\n",
      "Epoch 36: train_loss=1.5648, train_acc=0.4475, val_loss=1.5215, val_acc=0.4578\n",
      "Epoch 37: train_loss=1.5551, train_acc=0.4512, val_loss=1.5129, val_acc=0.4610\n",
      "Epoch 38: train_loss=1.5503, train_acc=0.4538, val_loss=1.5089, val_acc=0.4598\n",
      "Epoch 39: train_loss=1.5402, train_acc=0.4586, val_loss=1.5058, val_acc=0.4588\n",
      "Epoch 40: train_loss=1.5335, train_acc=0.4608, val_loss=1.4983, val_acc=0.4662\n",
      "Epoch 41: train_loss=1.5299, train_acc=0.4621, val_loss=1.4949, val_acc=0.4680\n",
      "Epoch 42: train_loss=1.5198, train_acc=0.4658, val_loss=1.4915, val_acc=0.4698\n",
      "Epoch 43: train_loss=1.5186, train_acc=0.4659, val_loss=1.4894, val_acc=0.4694\n",
      "Epoch 44: train_loss=1.5114, train_acc=0.4679, val_loss=1.4797, val_acc=0.4712\n",
      "Epoch 45: train_loss=1.5061, train_acc=0.4697, val_loss=1.4752, val_acc=0.4724\n",
      "Epoch 46: train_loss=1.4980, train_acc=0.4733, val_loss=1.4685, val_acc=0.4772\n",
      "Epoch 47: train_loss=1.4952, train_acc=0.4743, val_loss=1.4688, val_acc=0.4762\n",
      "Epoch 48: train_loss=1.4868, train_acc=0.4766, val_loss=1.4676, val_acc=0.4766\n",
      "Epoch 49: train_loss=1.4816, train_acc=0.4763, val_loss=1.4544, val_acc=0.4832\n",
      "Epoch 50: train_loss=1.4795, train_acc=0.4779, val_loss=1.4528, val_acc=0.4868\n",
      "Epoch 51: train_loss=1.4738, train_acc=0.4797, val_loss=1.4548, val_acc=0.4802\n",
      "Epoch 52: train_loss=1.4675, train_acc=0.4848, val_loss=1.4497, val_acc=0.4878\n",
      "Epoch 53: train_loss=1.4592, train_acc=0.4843, val_loss=1.4446, val_acc=0.4832\n",
      "Epoch 54: train_loss=1.4561, train_acc=0.4843, val_loss=1.4376, val_acc=0.4894\n",
      "Epoch 55: train_loss=1.4549, train_acc=0.4888, val_loss=1.4396, val_acc=0.4872\n",
      "Epoch 56: train_loss=1.4449, train_acc=0.4919, val_loss=1.4326, val_acc=0.4896\n",
      "Epoch 57: train_loss=1.4389, train_acc=0.4915, val_loss=1.4339, val_acc=0.4812\n",
      "Epoch 58: train_loss=1.4341, train_acc=0.4945, val_loss=1.4216, val_acc=0.4926\n",
      "Epoch 59: train_loss=1.4324, train_acc=0.4969, val_loss=1.4223, val_acc=0.4894\n",
      "Epoch 60: train_loss=1.4276, train_acc=0.4948, val_loss=1.4187, val_acc=0.4892\n",
      "Epoch 61: train_loss=1.4225, train_acc=0.4991, val_loss=1.4220, val_acc=0.4892\n",
      "Epoch 62: train_loss=1.4136, train_acc=0.5011, val_loss=1.4109, val_acc=0.4972\n",
      "Epoch 63: train_loss=1.4113, train_acc=0.5034, val_loss=1.4118, val_acc=0.4994\n",
      "Epoch 64: train_loss=1.4077, train_acc=0.5026, val_loss=1.4125, val_acc=0.5004\n",
      "Epoch 65: train_loss=1.4032, train_acc=0.5056, val_loss=1.4037, val_acc=0.4958\n",
      "Epoch 66: train_loss=1.3973, train_acc=0.5086, val_loss=1.4016, val_acc=0.4996\n",
      "Epoch 67: train_loss=1.3949, train_acc=0.5094, val_loss=1.4068, val_acc=0.4952\n",
      "Epoch 68: train_loss=1.3894, train_acc=0.5089, val_loss=1.4026, val_acc=0.4966\n",
      "Epoch 69: train_loss=1.3843, train_acc=0.5122, val_loss=1.3934, val_acc=0.5036\n",
      "Epoch 70: train_loss=1.3791, train_acc=0.5127, val_loss=1.3929, val_acc=0.4998\n",
      "Epoch 71: train_loss=1.3763, train_acc=0.5157, val_loss=1.3870, val_acc=0.5020\n",
      "Epoch 72: train_loss=1.3711, train_acc=0.5164, val_loss=1.3828, val_acc=0.5036\n",
      "Epoch 73: train_loss=1.3680, train_acc=0.5179, val_loss=1.3912, val_acc=0.5058\n",
      "Epoch 74: train_loss=1.3640, train_acc=0.5201, val_loss=1.3793, val_acc=0.5042\n",
      "Epoch 75: train_loss=1.3622, train_acc=0.5202, val_loss=1.3872, val_acc=0.4982\n",
      "Epoch 76: train_loss=1.3543, train_acc=0.5239, val_loss=1.3821, val_acc=0.4990\n",
      "Epoch 77: train_loss=1.3505, train_acc=0.5237, val_loss=1.3752, val_acc=0.5070\n",
      "Epoch 78: train_loss=1.3479, train_acc=0.5243, val_loss=1.3771, val_acc=0.5106\n",
      "Epoch 79: train_loss=1.3414, train_acc=0.5264, val_loss=1.3705, val_acc=0.5126\n",
      "Epoch 80: train_loss=1.3399, train_acc=0.5257, val_loss=1.3716, val_acc=0.5124\n",
      "Epoch 81: train_loss=1.3346, train_acc=0.5306, val_loss=1.3694, val_acc=0.5022\n",
      "Epoch 82: train_loss=1.3347, train_acc=0.5300, val_loss=1.3618, val_acc=0.5146\n",
      "Epoch 83: train_loss=1.3264, train_acc=0.5328, val_loss=1.3624, val_acc=0.5108\n",
      "Epoch 84: train_loss=1.3223, train_acc=0.5344, val_loss=1.3688, val_acc=0.5160\n",
      "Epoch 85: train_loss=1.3186, train_acc=0.5367, val_loss=1.3575, val_acc=0.5118\n",
      "Epoch 86: train_loss=1.3149, train_acc=0.5384, val_loss=1.3538, val_acc=0.5134\n",
      "Epoch 87: train_loss=1.3086, train_acc=0.5385, val_loss=1.3588, val_acc=0.5138\n",
      "Epoch 88: train_loss=1.3076, train_acc=0.5372, val_loss=1.3554, val_acc=0.5126\n",
      "Epoch 89: train_loss=1.2997, train_acc=0.5398, val_loss=1.3485, val_acc=0.5178\n",
      "Epoch 90: train_loss=1.2984, train_acc=0.5423, val_loss=1.3464, val_acc=0.5148\n",
      "Epoch 91: train_loss=1.2979, train_acc=0.5407, val_loss=1.3529, val_acc=0.5146\n",
      "Epoch 92: train_loss=1.2938, train_acc=0.5415, val_loss=1.3502, val_acc=0.5156\n",
      "Epoch 93: train_loss=1.2888, train_acc=0.5463, val_loss=1.3445, val_acc=0.5212\n",
      "Epoch 94: train_loss=1.2791, train_acc=0.5484, val_loss=1.3492, val_acc=0.5154\n",
      "Epoch 95: train_loss=1.2818, train_acc=0.5496, val_loss=1.3448, val_acc=0.5140\n",
      "Epoch 96: train_loss=1.2805, train_acc=0.5493, val_loss=1.3493, val_acc=0.5162\n",
      "Epoch 97: train_loss=1.2726, train_acc=0.5513, val_loss=1.3416, val_acc=0.5214\n",
      "Epoch 98: train_loss=1.2711, train_acc=0.5531, val_loss=1.3428, val_acc=0.5190\n",
      "Epoch 99: train_loss=1.2663, train_acc=0.5543, val_loss=1.3441, val_acc=0.5116\n",
      "Epoch 100: train_loss=1.2642, train_acc=0.5550, val_loss=1.3354, val_acc=0.5170\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>l2_loss</td><td>0.00648</td></tr><tr><td>train_acc</td><td>0.55501</td></tr><tr><td>train_loss</td><td>1.26418</td></tr><tr><td>val_acc</td><td>0.517</td></tr><tr><td>val_loss</td><td>1.33543</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-sweep-25</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/q2a4hkbp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/q2a4hkbp</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_103801-q2a4hkbp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6463dcsn with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.01\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005324291693790027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_110954-6463dcsn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6463dcsn' target=\"_blank\">smooth-sweep-26</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6463dcsn' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6463dcsn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.4645, train_acc=0.1254, val_loss=2.2178, val_acc=0.1926\n",
      "Epoch 2: train_loss=2.3509, train_acc=0.1613, val_loss=2.1354, val_acc=0.2236\n",
      "Epoch 3: train_loss=2.2866, train_acc=0.1886, val_loss=2.0785, val_acc=0.2516\n",
      "Epoch 4: train_loss=2.2373, train_acc=0.2065, val_loss=2.0365, val_acc=0.2662\n",
      "Epoch 5: train_loss=2.1993, train_acc=0.2223, val_loss=2.0042, val_acc=0.2854\n",
      "Epoch 6: train_loss=2.1645, train_acc=0.2403, val_loss=1.9756, val_acc=0.2966\n",
      "Epoch 7: train_loss=2.1377, train_acc=0.2506, val_loss=1.9544, val_acc=0.3062\n",
      "Epoch 8: train_loss=2.1134, train_acc=0.2587, val_loss=1.9347, val_acc=0.3180\n",
      "Epoch 9: train_loss=2.0956, train_acc=0.2699, val_loss=1.9181, val_acc=0.3266\n",
      "Epoch 10: train_loss=2.0725, train_acc=0.2813, val_loss=1.9066, val_acc=0.3300\n",
      "Epoch 11: train_loss=2.0609, train_acc=0.2853, val_loss=1.8913, val_acc=0.3372\n",
      "Epoch 12: train_loss=2.0471, train_acc=0.2894, val_loss=1.8824, val_acc=0.3384\n",
      "Epoch 13: train_loss=2.0372, train_acc=0.2912, val_loss=1.8707, val_acc=0.3442\n",
      "Epoch 14: train_loss=2.0241, train_acc=0.3009, val_loss=1.8642, val_acc=0.3458\n",
      "Epoch 15: train_loss=2.0139, train_acc=0.3052, val_loss=1.8561, val_acc=0.3486\n",
      "Epoch 16: train_loss=2.0011, train_acc=0.3103, val_loss=1.8501, val_acc=0.3500\n",
      "Epoch 17: train_loss=1.9937, train_acc=0.3113, val_loss=1.8426, val_acc=0.3560\n",
      "Epoch 18: train_loss=1.9881, train_acc=0.3149, val_loss=1.8363, val_acc=0.3582\n",
      "Epoch 19: train_loss=1.9779, train_acc=0.3210, val_loss=1.8307, val_acc=0.3614\n",
      "Epoch 20: train_loss=1.9727, train_acc=0.3180, val_loss=1.8249, val_acc=0.3646\n",
      "Epoch 21: train_loss=1.9641, train_acc=0.3289, val_loss=1.8229, val_acc=0.3590\n",
      "Epoch 22: train_loss=1.9587, train_acc=0.3319, val_loss=1.8159, val_acc=0.3662\n",
      "Epoch 23: train_loss=1.9514, train_acc=0.3302, val_loss=1.8129, val_acc=0.3650\n",
      "Epoch 24: train_loss=1.9480, train_acc=0.3325, val_loss=1.8096, val_acc=0.3690\n",
      "Epoch 25: train_loss=1.9412, train_acc=0.3348, val_loss=1.8057, val_acc=0.3678\n",
      "Epoch 26: train_loss=1.9387, train_acc=0.3378, val_loss=1.8022, val_acc=0.3706\n",
      "Epoch 27: train_loss=1.9326, train_acc=0.3400, val_loss=1.8001, val_acc=0.3678\n",
      "Epoch 28: train_loss=1.9305, train_acc=0.3401, val_loss=1.7955, val_acc=0.3724\n",
      "Epoch 29: train_loss=1.9266, train_acc=0.3429, val_loss=1.7932, val_acc=0.3716\n",
      "Epoch 30: train_loss=1.9173, train_acc=0.3423, val_loss=1.7918, val_acc=0.3730\n",
      "Epoch 31: train_loss=1.9147, train_acc=0.3456, val_loss=1.7888, val_acc=0.3728\n",
      "Epoch 32: train_loss=1.9092, train_acc=0.3477, val_loss=1.7857, val_acc=0.3756\n",
      "Epoch 33: train_loss=1.9104, train_acc=0.3479, val_loss=1.7816, val_acc=0.3748\n",
      "Epoch 34: train_loss=1.9049, train_acc=0.3488, val_loss=1.7806, val_acc=0.3754\n",
      "Epoch 35: train_loss=1.9000, train_acc=0.3509, val_loss=1.7797, val_acc=0.3750\n",
      "Epoch 36: train_loss=1.8984, train_acc=0.3523, val_loss=1.7762, val_acc=0.3776\n",
      "Epoch 37: train_loss=1.8919, train_acc=0.3549, val_loss=1.7735, val_acc=0.3748\n",
      "Epoch 38: train_loss=1.8893, train_acc=0.3571, val_loss=1.7720, val_acc=0.3810\n",
      "Epoch 39: train_loss=1.8888, train_acc=0.3550, val_loss=1.7702, val_acc=0.3808\n",
      "Epoch 40: train_loss=1.8867, train_acc=0.3573, val_loss=1.7677, val_acc=0.3820\n",
      "Epoch 41: train_loss=1.8833, train_acc=0.3570, val_loss=1.7672, val_acc=0.3806\n",
      "Epoch 42: train_loss=1.8818, train_acc=0.3582, val_loss=1.7649, val_acc=0.3820\n",
      "Epoch 43: train_loss=1.8768, train_acc=0.3620, val_loss=1.7646, val_acc=0.3814\n",
      "Epoch 44: train_loss=1.8766, train_acc=0.3620, val_loss=1.7610, val_acc=0.3832\n",
      "Epoch 45: train_loss=1.8717, train_acc=0.3641, val_loss=1.7592, val_acc=0.3850\n",
      "Epoch 46: train_loss=1.8701, train_acc=0.3647, val_loss=1.7579, val_acc=0.3858\n",
      "Epoch 47: train_loss=1.8662, train_acc=0.3642, val_loss=1.7565, val_acc=0.3858\n",
      "Epoch 48: train_loss=1.8650, train_acc=0.3668, val_loss=1.7545, val_acc=0.3828\n",
      "Epoch 49: train_loss=1.8616, train_acc=0.3670, val_loss=1.7525, val_acc=0.3878\n",
      "Epoch 50: train_loss=1.8584, train_acc=0.3667, val_loss=1.7516, val_acc=0.3922\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>l2_loss</td><td>0.10875</td></tr><tr><td>train_acc</td><td>0.36666</td></tr><tr><td>train_loss</td><td>1.85838</td></tr><tr><td>val_acc</td><td>0.3922</td></tr><tr><td>val_loss</td><td>1.75161</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smooth-sweep-26</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6463dcsn' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/6463dcsn</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_110954-6463dcsn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: lmy4dxb8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.09739693610533878\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: momentum\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_112443-lmy4dxb8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/lmy4dxb8' target=\"_blank\">leafy-sweep-27</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/lmy4dxb8' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/lmy4dxb8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=1.9857, train_acc=0.2836, val_loss=1.8277, val_acc=0.3504\n",
      "Epoch 2: train_loss=1.8578, train_acc=0.3371, val_loss=1.7920, val_acc=0.3580\n",
      "Epoch 3: train_loss=1.8118, train_acc=0.3540, val_loss=1.7379, val_acc=0.3744\n",
      "Epoch 4: train_loss=1.7757, train_acc=0.3697, val_loss=1.7009, val_acc=0.3932\n",
      "Epoch 5: train_loss=1.7551, train_acc=0.3763, val_loss=1.6780, val_acc=0.3956\n",
      "Epoch 6: train_loss=1.7297, train_acc=0.3865, val_loss=1.6906, val_acc=0.3958\n",
      "Epoch 7: train_loss=1.7140, train_acc=0.3903, val_loss=1.6360, val_acc=0.4126\n",
      "Epoch 8: train_loss=1.6927, train_acc=0.3969, val_loss=1.6134, val_acc=0.4240\n",
      "Epoch 9: train_loss=1.6799, train_acc=0.4038, val_loss=1.6126, val_acc=0.4216\n",
      "Epoch 10: train_loss=1.6639, train_acc=0.4111, val_loss=1.5960, val_acc=0.4246\n",
      "Epoch 11: train_loss=1.6490, train_acc=0.4145, val_loss=1.5873, val_acc=0.4254\n",
      "Epoch 12: train_loss=1.6391, train_acc=0.4221, val_loss=1.5655, val_acc=0.4316\n",
      "Epoch 13: train_loss=1.6293, train_acc=0.4218, val_loss=1.5614, val_acc=0.4400\n",
      "Epoch 14: train_loss=1.6151, train_acc=0.4265, val_loss=1.5701, val_acc=0.4280\n",
      "Epoch 15: train_loss=1.6109, train_acc=0.4293, val_loss=1.5416, val_acc=0.4466\n",
      "Epoch 16: train_loss=1.5980, train_acc=0.4340, val_loss=1.5572, val_acc=0.4412\n",
      "Epoch 17: train_loss=1.5873, train_acc=0.4359, val_loss=1.5137, val_acc=0.4574\n",
      "Epoch 18: train_loss=1.5787, train_acc=0.4402, val_loss=1.5158, val_acc=0.4568\n",
      "Epoch 19: train_loss=1.5739, train_acc=0.4395, val_loss=1.5186, val_acc=0.4542\n",
      "Epoch 20: train_loss=1.5653, train_acc=0.4430, val_loss=1.5103, val_acc=0.4550\n",
      "Epoch 21: train_loss=1.5537, train_acc=0.4490, val_loss=1.4806, val_acc=0.4672\n",
      "Epoch 22: train_loss=1.5521, train_acc=0.4496, val_loss=1.5016, val_acc=0.4640\n",
      "Epoch 23: train_loss=1.5483, train_acc=0.4511, val_loss=1.4947, val_acc=0.4638\n",
      "Epoch 24: train_loss=1.5386, train_acc=0.4540, val_loss=1.4897, val_acc=0.4672\n",
      "Epoch 25: train_loss=1.5347, train_acc=0.4548, val_loss=1.5027, val_acc=0.4596\n",
      "Epoch 26: train_loss=1.5293, train_acc=0.4590, val_loss=1.4699, val_acc=0.4690\n",
      "Epoch 27: train_loss=1.5249, train_acc=0.4591, val_loss=1.4794, val_acc=0.4718\n",
      "Epoch 28: train_loss=1.5200, train_acc=0.4624, val_loss=1.4730, val_acc=0.4688\n",
      "Epoch 29: train_loss=1.5136, train_acc=0.4650, val_loss=1.4812, val_acc=0.4686\n",
      "Epoch 30: train_loss=1.5077, train_acc=0.4642, val_loss=1.4519, val_acc=0.4826\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>l2_loss</td><td>0.0052</td></tr><tr><td>train_acc</td><td>0.46422</td></tr><tr><td>train_loss</td><td>1.50773</td></tr><tr><td>val_acc</td><td>0.4826</td></tr><tr><td>val_loss</td><td>1.4519</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">leafy-sweep-27</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/lmy4dxb8' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/lmy4dxb8</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_112443-lmy4dxb8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: f3r45yvb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 512, 256]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: he\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05667819976783744\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_114451-f3r45yvb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/f3r45yvb' target=\"_blank\">whole-sweep-28</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/f3r45yvb' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/f3r45yvb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.9604, train_acc=0.1009, val_loss=2.3050, val_acc=0.0990\n",
      "Epoch 2: train_loss=2.3337, train_acc=0.0982, val_loss=2.3050, val_acc=0.1028\n",
      "Epoch 3: train_loss=2.3266, train_acc=0.1003, val_loss=2.3037, val_acc=0.1000\n",
      "Epoch 4: train_loss=2.3391, train_acc=0.1022, val_loss=2.3041, val_acc=0.0990\n",
      "Epoch 5: train_loss=2.3239, train_acc=0.0996, val_loss=2.3060, val_acc=0.0984\n",
      "Epoch 6: train_loss=2.3189, train_acc=0.0997, val_loss=2.3054, val_acc=0.0974\n",
      "Epoch 7: train_loss=2.3937, train_acc=0.1010, val_loss=2.3068, val_acc=0.0990\n",
      "Epoch 8: train_loss=2.3179, train_acc=0.0993, val_loss=2.3055, val_acc=0.0984\n",
      "Epoch 9: train_loss=2.3205, train_acc=0.0994, val_loss=2.3090, val_acc=0.0984\n",
      "Epoch 10: train_loss=2.3163, train_acc=0.0982, val_loss=2.3077, val_acc=0.0998\n",
      "Epoch 11: train_loss=2.3159, train_acc=0.0983, val_loss=2.3067, val_acc=0.0974\n",
      "Epoch 12: train_loss=2.3147, train_acc=0.0999, val_loss=2.3050, val_acc=0.0984\n",
      "Epoch 13: train_loss=2.3146, train_acc=0.1003, val_loss=2.3040, val_acc=0.1028\n",
      "Epoch 14: train_loss=2.3147, train_acc=0.0984, val_loss=2.3037, val_acc=0.0990\n",
      "Epoch 15: train_loss=2.3146, train_acc=0.1021, val_loss=2.3068, val_acc=0.0984\n",
      "Epoch 16: train_loss=2.3146, train_acc=0.0987, val_loss=2.3051, val_acc=0.0980\n",
      "Epoch 17: train_loss=2.3142, train_acc=0.0979, val_loss=2.3049, val_acc=0.0980\n",
      "Epoch 18: train_loss=2.3135, train_acc=0.1029, val_loss=2.3052, val_acc=0.0990\n",
      "Epoch 19: train_loss=2.3134, train_acc=0.1027, val_loss=2.3054, val_acc=0.0974\n",
      "Epoch 20: train_loss=2.3136, train_acc=0.1022, val_loss=2.3059, val_acc=0.0998\n",
      "Epoch 21: train_loss=2.3139, train_acc=0.1005, val_loss=2.3080, val_acc=0.1000\n",
      "Epoch 22: train_loss=2.3133, train_acc=0.0967, val_loss=2.3056, val_acc=0.0980\n",
      "Epoch 23: train_loss=2.3134, train_acc=0.0981, val_loss=2.3050, val_acc=0.0998\n",
      "Epoch 24: train_loss=2.3135, train_acc=0.0988, val_loss=2.3061, val_acc=0.0980\n",
      "Epoch 25: train_loss=2.3129, train_acc=0.0993, val_loss=2.3078, val_acc=0.0974\n",
      "Epoch 26: train_loss=2.3128, train_acc=0.0991, val_loss=2.3081, val_acc=0.0974\n",
      "Epoch 27: train_loss=2.3125, train_acc=0.1007, val_loss=2.3044, val_acc=0.1066\n",
      "Epoch 28: train_loss=2.3125, train_acc=0.0991, val_loss=2.3039, val_acc=0.1066\n",
      "Epoch 29: train_loss=2.3130, train_acc=0.1016, val_loss=2.3055, val_acc=0.0990\n",
      "Epoch 30: train_loss=2.3129, train_acc=0.0987, val_loss=2.3094, val_acc=0.0980\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>30</td></tr><tr><td>l2_loss</td><td>0.0002</td></tr><tr><td>train_acc</td><td>0.09868</td></tr><tr><td>train_loss</td><td>2.31294</td></tr><tr><td>val_acc</td><td>0.098</td></tr><tr><td>val_loss</td><td>2.30942</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">whole-sweep-28</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/f3r45yvb' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/f3r45yvb</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_114451-f3r45yvb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: khf9xbqw with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: relu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.0001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0243344535524168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_120706-khf9xbqw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/khf9xbqw' target=\"_blank\">lunar-sweep-29</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/khf9xbqw' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/khf9xbqw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.5268, train_acc=0.1006, val_loss=2.3070, val_acc=0.0990\n",
      "Epoch 2: train_loss=2.3090, train_acc=0.1005, val_loss=2.3054, val_acc=0.1028\n",
      "Epoch 3: train_loss=2.3089, train_acc=0.1000, val_loss=2.3059, val_acc=0.0990\n",
      "Epoch 4: train_loss=2.3089, train_acc=0.0987, val_loss=2.3051, val_acc=0.0990\n",
      "Epoch 5: train_loss=2.3086, train_acc=0.0998, val_loss=2.3056, val_acc=0.1066\n",
      "Epoch 6: train_loss=2.3088, train_acc=0.0999, val_loss=2.3029, val_acc=0.1066\n",
      "Epoch 7: train_loss=2.3083, train_acc=0.0991, val_loss=2.3057, val_acc=0.1028\n",
      "Epoch 8: train_loss=2.3090, train_acc=0.1016, val_loss=2.3075, val_acc=0.0998\n",
      "Epoch 9: train_loss=2.3091, train_acc=0.0966, val_loss=2.3043, val_acc=0.0980\n",
      "Epoch 10: train_loss=2.3095, train_acc=0.0982, val_loss=2.3045, val_acc=0.0990\n",
      "Epoch 11: train_loss=2.3086, train_acc=0.0969, val_loss=2.3046, val_acc=0.1000\n",
      "Epoch 12: train_loss=2.3082, train_acc=0.1016, val_loss=2.3044, val_acc=0.0974\n",
      "Epoch 13: train_loss=2.3089, train_acc=0.0996, val_loss=2.3062, val_acc=0.0974\n",
      "Epoch 14: train_loss=2.3093, train_acc=0.0983, val_loss=2.3062, val_acc=0.0974\n",
      "Epoch 15: train_loss=2.3092, train_acc=0.1015, val_loss=2.3031, val_acc=0.0974\n",
      "Epoch 16: train_loss=2.3086, train_acc=0.1000, val_loss=2.3040, val_acc=0.0980\n",
      "Epoch 17: train_loss=2.3084, train_acc=0.1011, val_loss=2.3051, val_acc=0.0980\n",
      "Epoch 18: train_loss=2.3088, train_acc=0.0996, val_loss=2.3065, val_acc=0.0990\n",
      "Epoch 19: train_loss=2.3088, train_acc=0.0998, val_loss=2.3050, val_acc=0.0990\n",
      "Epoch 20: train_loss=2.3082, train_acc=0.0984, val_loss=2.3055, val_acc=0.1028\n",
      "Epoch 21: train_loss=2.3086, train_acc=0.0995, val_loss=2.3036, val_acc=0.0984\n",
      "Epoch 22: train_loss=2.3085, train_acc=0.0994, val_loss=2.3046, val_acc=0.0990\n",
      "Epoch 23: train_loss=2.3092, train_acc=0.0989, val_loss=2.3062, val_acc=0.0984\n",
      "Epoch 24: train_loss=2.3090, train_acc=0.1010, val_loss=2.3048, val_acc=0.1028\n",
      "Epoch 25: train_loss=2.3085, train_acc=0.0992, val_loss=2.3045, val_acc=0.0974\n",
      "Epoch 26: train_loss=2.3088, train_acc=0.0992, val_loss=2.3046, val_acc=0.1028\n",
      "Epoch 27: train_loss=2.3087, train_acc=0.0974, val_loss=2.3064, val_acc=0.0984\n",
      "Epoch 28: train_loss=2.3092, train_acc=0.0980, val_loss=2.3046, val_acc=0.1066\n",
      "Epoch 29: train_loss=2.3087, train_acc=0.0992, val_loss=2.3047, val_acc=0.0974\n",
      "Epoch 30: train_loss=2.3090, train_acc=0.0982, val_loss=2.3032, val_acc=0.0980\n",
      "Epoch 31: train_loss=2.3087, train_acc=0.0995, val_loss=2.3035, val_acc=0.1066\n",
      "Epoch 32: train_loss=2.3085, train_acc=0.0998, val_loss=2.3045, val_acc=0.0980\n",
      "Epoch 33: train_loss=2.3090, train_acc=0.0983, val_loss=2.3050, val_acc=0.0980\n",
      "Epoch 34: train_loss=2.3085, train_acc=0.0993, val_loss=2.3067, val_acc=0.0990\n",
      "Epoch 35: train_loss=2.3087, train_acc=0.1016, val_loss=2.3033, val_acc=0.0974\n",
      "Epoch 36: train_loss=2.3085, train_acc=0.0997, val_loss=2.3029, val_acc=0.0998\n",
      "Epoch 37: train_loss=2.3082, train_acc=0.1058, val_loss=2.3057, val_acc=0.0990\n",
      "Epoch 38: train_loss=2.3082, train_acc=0.1018, val_loss=2.3057, val_acc=0.0990\n",
      "Epoch 39: train_loss=2.3088, train_acc=0.0991, val_loss=2.3035, val_acc=0.0984\n",
      "Epoch 40: train_loss=2.3082, train_acc=0.1005, val_loss=2.3041, val_acc=0.1066\n",
      "Epoch 41: train_loss=2.3096, train_acc=0.0990, val_loss=2.3045, val_acc=0.0990\n",
      "Epoch 42: train_loss=2.3092, train_acc=0.0952, val_loss=2.3051, val_acc=0.0990\n",
      "Epoch 43: train_loss=2.3086, train_acc=0.0983, val_loss=2.3043, val_acc=0.0990\n",
      "Epoch 44: train_loss=2.3085, train_acc=0.1001, val_loss=2.3066, val_acc=0.0980\n",
      "Epoch 45: train_loss=2.3086, train_acc=0.1007, val_loss=2.3037, val_acc=0.0990\n",
      "Epoch 46: train_loss=2.3086, train_acc=0.0985, val_loss=2.3031, val_acc=0.1066\n",
      "Epoch 47: train_loss=2.3082, train_acc=0.1002, val_loss=2.3030, val_acc=0.0990\n",
      "Epoch 48: train_loss=2.3086, train_acc=0.0961, val_loss=2.3039, val_acc=0.0990\n",
      "Epoch 49: train_loss=2.3087, train_acc=0.0993, val_loss=2.3040, val_acc=0.1028\n",
      "Epoch 50: train_loss=2.3087, train_acc=0.1004, val_loss=2.3036, val_acc=0.0984\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>l2_loss</td><td>0</td></tr><tr><td>train_acc</td><td>0.10037</td></tr><tr><td>train_loss</td><td>2.30868</td></tr><tr><td>val_acc</td><td>0.0984</td></tr><tr><td>val_loss</td><td>2.30365</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-29</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/khf9xbqw' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/khf9xbqw</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_120706-khf9xbqw/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: e1mhsuxy with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tactivation: tanh\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout_rate: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 50\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layers: [512, 256, 128]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tinit_method: xavier\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tl2_lambda: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.06436015687167165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \toptimizer: adam\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Ignoring project 'cifar10_project' when running a sweep."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/patriserratosa/Desktop/DTU/DL/wandb/run-20251110_134110-e1mhsuxy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/e1mhsuxy' target=\"_blank\">likely-sweep-30</a></strong> to <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/sweeps/wupcovnp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/e1mhsuxy' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/e1mhsuxy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: train_loss=2.8974, train_acc=0.0985, val_loss=2.3577, val_acc=0.0594\n",
      "Epoch 2: train_loss=2.7883, train_acc=0.0993, val_loss=2.4995, val_acc=0.0998\n",
      "Epoch 3: train_loss=2.8532, train_acc=0.1014, val_loss=2.5968, val_acc=0.0998\n",
      "Epoch 4: train_loss=2.7886, train_acc=0.1018, val_loss=2.6064, val_acc=0.0984\n",
      "Epoch 5: train_loss=3.0110, train_acc=0.0988, val_loss=2.4195, val_acc=0.0998\n",
      "Epoch 6: train_loss=2.5309, train_acc=0.1001, val_loss=2.3733, val_acc=0.0980\n",
      "Epoch 7: train_loss=2.5259, train_acc=0.1004, val_loss=2.5213, val_acc=0.0990\n",
      "Epoch 8: train_loss=2.5408, train_acc=0.1001, val_loss=2.5137, val_acc=0.1066\n",
      "Epoch 9: train_loss=2.5785, train_acc=0.1001, val_loss=2.4075, val_acc=0.1030\n",
      "Epoch 10: train_loss=2.5249, train_acc=0.0985, val_loss=2.6032, val_acc=0.1000\n",
      "Epoch 11: train_loss=2.5581, train_acc=0.0995, val_loss=2.6257, val_acc=0.0984\n",
      "Epoch 12: train_loss=2.6849, train_acc=0.0985, val_loss=2.6895, val_acc=0.0982\n",
      "Epoch 13: train_loss=3.2640, train_acc=0.0999, val_loss=2.6830, val_acc=0.1064\n",
      "Epoch 14: train_loss=2.6358, train_acc=0.1015, val_loss=2.4892, val_acc=0.0990\n",
      "Epoch 15: train_loss=2.5341, train_acc=0.0997, val_loss=2.5250, val_acc=0.1028\n",
      "Epoch 16: train_loss=2.5510, train_acc=0.1002, val_loss=2.4752, val_acc=0.0990\n",
      "Epoch 17: train_loss=2.5319, train_acc=0.1008, val_loss=2.3496, val_acc=0.0980\n",
      "Epoch 18: train_loss=2.5068, train_acc=0.1020, val_loss=2.5158, val_acc=0.0980\n",
      "Epoch 19: train_loss=2.5936, train_acc=0.1000, val_loss=2.5375, val_acc=0.0990\n",
      "Epoch 20: train_loss=2.6269, train_acc=0.0993, val_loss=2.5410, val_acc=0.0984\n",
      "Epoch 21: train_loss=2.4960, train_acc=0.0988, val_loss=2.4909, val_acc=0.0980\n",
      "Epoch 22: train_loss=2.5313, train_acc=0.1000, val_loss=2.4795, val_acc=0.0974\n",
      "Epoch 23: train_loss=2.5847, train_acc=0.0982, val_loss=2.5708, val_acc=0.0984\n",
      "Epoch 24: train_loss=2.5447, train_acc=0.1027, val_loss=2.4421, val_acc=0.1066\n",
      "Epoch 25: train_loss=2.5677, train_acc=0.1007, val_loss=2.5395, val_acc=0.0998\n",
      "Epoch 26: train_loss=2.5517, train_acc=0.0978, val_loss=2.4994, val_acc=0.0980\n",
      "Epoch 27: train_loss=2.5956, train_acc=0.1011, val_loss=2.6025, val_acc=0.1066\n",
      "Epoch 28: train_loss=2.5912, train_acc=0.1009, val_loss=2.7763, val_acc=0.0990\n",
      "Epoch 29: train_loss=2.5482, train_acc=0.1016, val_loss=2.6362, val_acc=0.0998\n",
      "Epoch 30: train_loss=2.5738, train_acc=0.1006, val_loss=2.5118, val_acc=0.1000\n",
      "Epoch 31: train_loss=2.5302, train_acc=0.0997, val_loss=2.5091, val_acc=0.0990\n",
      "Epoch 32: train_loss=2.5268, train_acc=0.0980, val_loss=2.4312, val_acc=0.1066\n",
      "Epoch 33: train_loss=2.6982, train_acc=0.1023, val_loss=2.3463, val_acc=0.0990\n",
      "Epoch 34: train_loss=2.5281, train_acc=0.0987, val_loss=2.4601, val_acc=0.1028\n",
      "Epoch 35: train_loss=2.6681, train_acc=0.0981, val_loss=2.4257, val_acc=0.0974\n",
      "Epoch 36: train_loss=2.5408, train_acc=0.1007, val_loss=2.5685, val_acc=0.0984\n",
      "Epoch 37: train_loss=2.5404, train_acc=0.0993, val_loss=2.4781, val_acc=0.1066\n",
      "Epoch 38: train_loss=2.5792, train_acc=0.1013, val_loss=2.4494, val_acc=0.0980\n",
      "Epoch 39: train_loss=2.5871, train_acc=0.1009, val_loss=2.5020, val_acc=0.0990\n",
      "Epoch 40: train_loss=2.5163, train_acc=0.0982, val_loss=2.5220, val_acc=0.1000\n",
      "Epoch 41: train_loss=2.8304, train_acc=0.1009, val_loss=2.5835, val_acc=0.0980\n",
      "Epoch 42: train_loss=2.5136, train_acc=0.0993, val_loss=2.5547, val_acc=0.1066\n",
      "Epoch 43: train_loss=2.5130, train_acc=0.0988, val_loss=2.4892, val_acc=0.0990\n",
      "Epoch 44: train_loss=2.6883, train_acc=0.0996, val_loss=2.4428, val_acc=0.0990\n",
      "Epoch 45: train_loss=2.5575, train_acc=0.1013, val_loss=2.3946, val_acc=0.0998\n",
      "Epoch 46: train_loss=2.5523, train_acc=0.0988, val_loss=2.4985, val_acc=0.1028\n",
      "Epoch 47: train_loss=2.5191, train_acc=0.0991, val_loss=2.4308, val_acc=0.0998\n",
      "Epoch 48: train_loss=2.5543, train_acc=0.1016, val_loss=2.3684, val_acc=0.0998\n",
      "Epoch 49: train_loss=2.5539, train_acc=0.0978, val_loss=2.5307, val_acc=0.0990\n",
      "Epoch 50: train_loss=2.5193, train_acc=0.0991, val_loss=2.4515, val_acc=0.0980\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td></td></tr><tr><td>l2_loss</td><td></td></tr><tr><td>train_acc</td><td></td></tr><tr><td>train_loss</td><td></td></tr><tr><td>val_acc</td><td></td></tr><tr><td>val_loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>50</td></tr><tr><td>l2_loss</td><td>0.00065</td></tr><tr><td>train_acc</td><td>0.09912</td></tr><tr><td>train_loss</td><td>2.51928</td></tr><tr><td>val_acc</td><td>0.098</td></tr><tr><td>val_loss</td><td>2.45153</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">likely-sweep-30</strong> at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/e1mhsuxy' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project/runs/e1mhsuxy</a><br> View project at: <a href='https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project' target=\"_blank\">https://wandb.ai/s243323-danmarks-tekniske-universitet-dtu/cifar10_project</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_134110-e1mhsuxy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# batching \n",
    "def get_batch(X, y, batch_size):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        yield X[i:i+batch_size], y[i:i+batch_size]\n",
    "\n",
    "\n",
    "# Activation functions \n",
    "def relu(x): return np.maximum(x, 0)\n",
    "def relu_derivative(x): return np.where(x > 0, 1, 0)\n",
    "def tanh(x): return np.tanh(x)\n",
    "def tanh_derivative(x): return 1 - np.tanh(x)**2\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "# Dropout\n",
    "def apply_dropout(a, dropout_rate):\n",
    "    if dropout_rate <= 0: return a, np.ones_like(a)\n",
    "    mask = (np.random.rand(*a.shape) > dropout_rate).astype(np.float32)\n",
    "    return a * mask / (1 - dropout_rate), mask\n",
    "\n",
    "\n",
    "#Loss and accuracy\n",
    "def cross_entropy_loss(y_true, y_pred, eps=1e-12):\n",
    "    y_pred_clipped = np.clip(y_pred, eps, 1 - eps)\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred_clipped), axis=1))\n",
    "    dA = (y_pred - y_true) / y_true.shape[0]\n",
    "    return loss, dA\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.mean(np.argmax(y_pred, axis=1) == np.argmax(y_true, axis=1))\n",
    "\n",
    "\n",
    "#Weight initialization\n",
    "def init_weights_flexible(layer_sizes, method='he'):\n",
    "    params = []\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        in_dim, out_dim = layer_sizes[i], layer_sizes[i + 1]\n",
    "        if method == 'he':\n",
    "            scale = np.sqrt(2. / in_dim)\n",
    "        elif method == 'xavier':\n",
    "            scale = np.sqrt(1. / in_dim)\n",
    "        else:\n",
    "            scale = 0.01\n",
    "        W = np.random.randn(in_dim, out_dim) * scale\n",
    "        b = np.zeros((1, out_dim))\n",
    "        params.append((W, b))\n",
    "    return params\n",
    "\n",
    "\n",
    "# Forward + Dropout \n",
    "def forward_flexible(X, params, activation='relu', dropout_rate=0.0, train=True):\n",
    "    activations, pre_acts, dropout_masks = [X], [], []\n",
    "    for i, (W, b) in enumerate(params):\n",
    "        z = activations[-1] @ W + b\n",
    "        pre_acts.append(z)\n",
    "        if i < len(params) - 1:\n",
    "            if activation == 'relu':\n",
    "                a = relu(z)\n",
    "            elif activation == 'tanh':\n",
    "                a = tanh(z)\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported activation.\")\n",
    "            if train:\n",
    "                a, mask = apply_dropout(a, dropout_rate)\n",
    "            else:\n",
    "                mask = np.ones_like(a)\n",
    "            dropout_masks.append(mask)\n",
    "        else:\n",
    "            a = softmax(z)\n",
    "            dropout_masks.append(np.ones_like(a))\n",
    "        activations.append(a)\n",
    "    return pre_acts, activations, dropout_masks\n",
    "\n",
    "\n",
    "# Backward \n",
    "def backward_flexible(X, y, params, pre_acts, acts, dropout_masks, activation='relu', dA_last=None, l2_lambda=0.0):\n",
    "    grads = [None] * len(params)\n",
    "    m = X.shape[0]\n",
    "    delta = dA_last if dA_last is not None else (acts[-1] - y)\n",
    "    dW = acts[-2].T @ delta / m + l2_lambda * params[-1][0] / m\n",
    "    db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "    grads[-1] = (dW, db)\n",
    "\n",
    "    for l in reversed(range(len(params) - 1)):\n",
    "        W_next, _ = params[l + 1]\n",
    "        z = pre_acts[l]\n",
    "        delta = (delta @ W_next.T) * dropout_masks[l]\n",
    "        if activation == 'relu':\n",
    "            delta *= relu_derivative(z)\n",
    "        elif activation == 'tanh':\n",
    "            delta *= tanh_derivative(z)\n",
    "        dW = acts[l].T @ delta / m + l2_lambda * params[l][0] / m\n",
    "        db = np.sum(delta, axis=0, keepdims=True) / m\n",
    "        grads[l] = (dW, db)\n",
    "    return grads\n",
    "\n",
    "\n",
    "# Optimizers\n",
    "def init_optimizer_states(params, optimizer='sgd'):\n",
    "    if optimizer == 'momentum':\n",
    "        v = [(np.zeros_like(W), np.zeros_like(b)) for W, b in params]\n",
    "        return {'v': v}\n",
    "    elif optimizer == 'adam':\n",
    "        m = [(np.zeros_like(W), np.zeros_like(b)) for W, b in params]\n",
    "        v = [(np.zeros_like(W), np.zeros_like(b)) for W, b in params]\n",
    "        return {'m': m, 'v': v, 't': 0}\n",
    "    return {}\n",
    "\n",
    "def update_parameters_flexible(params, grads, lr, optimizer='sgd', opt_state=None,\n",
    "                               beta1=0.9, beta2=0.999, eps=1e-8, momentum=0.9):\n",
    "    new_params = []\n",
    "    if optimizer == 'sgd':\n",
    "        for (W, b), (dW, db) in zip(params, grads):\n",
    "            W -= lr * dW; b -= lr * db\n",
    "            new_params.append((W, b))\n",
    "    elif optimizer == 'momentum':\n",
    "        for i, ((W, b), (dW, db)) in enumerate(zip(params, grads)):\n",
    "            vW, vb = opt_state['v'][i]\n",
    "            vW = momentum * vW - lr * dW\n",
    "            vb = momentum * vb - lr * db\n",
    "            W += vW; b += vb\n",
    "            opt_state['v'][i] = (vW, vb)\n",
    "            new_params.append((W, b))\n",
    "    elif optimizer == 'adam':\n",
    "        opt_state['t'] += 1; t = opt_state['t']\n",
    "        for i, ((W, b), (dW, db)) in enumerate(zip(params, grads)):\n",
    "            mW, mb = opt_state['m'][i]; vW, vb = opt_state['v'][i]\n",
    "            mW = beta1 * mW + (1 - beta1) * dW\n",
    "            mb = beta1 * mb + (1 - beta1) * db\n",
    "            vW = beta2 * vW + (1 - beta2) * (dW ** 2)\n",
    "            vb = beta2 * vb + (1 - beta2) * (db ** 2)\n",
    "            mW_hat = mW / (1 - beta1 ** t); mb_hat = mb / (1 - beta1 ** t)\n",
    "            vW_hat = vW / (1 - beta2 ** t); vb_hat = vb / (1 - beta2 ** t)\n",
    "            W -= lr * mW_hat / (np.sqrt(vW_hat) + eps)\n",
    "            b -= lr * mb_hat / (np.sqrt(vb_hat) + eps)\n",
    "            opt_state['m'][i] = (mW, mb); opt_state['v'][i] = (vW, vb)\n",
    "            new_params.append((W, b))\n",
    "    return new_params, opt_state\n",
    "\n",
    "\n",
    "# W&B Sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric': {'name': 'val_acc', 'goal': 'maximize'},\n",
    "    'parameters': {\n",
    "        'learning_rate': {'min': 0.0005, 'max': 0.1},\n",
    "        'batch_size': {'values': [32, 64, 128, 256]},\n",
    "        'optimizer': {'values': ['sgd', 'momentum', 'adam']},\n",
    "        'init_method': {'values': ['he', 'xavier']},\n",
    "        'hidden_layers': {'values': [[256, 128], [512, 256, 128], [512, 512, 256]]},\n",
    "        'activation': {'values': ['relu', 'tanh']},\n",
    "        'dropout_rate': {'values': [0.0, 0.1, 0.2, 0.3]},\n",
    "        'l2_lambda': {'values': [0.0, 1e-4, 1e-3, 1e-2]},\n",
    "        'epochs': {'values': [30, 50, 80, 100]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# W&B training function\n",
    "def wandb_train():\n",
    "    wandb.init(project=\"cifar10_project\", config=sweep_config['parameters'])\n",
    "    config = wandb.config\n",
    "\n",
    "    layer_sizes = [3072] + config.hidden_layers + [10]\n",
    "    params = init_weights_flexible(layer_sizes, method=config.init_method)\n",
    "    opt_state = init_optimizer_states(params, config.optimizer)\n",
    "\n",
    "    for epoch in range(config.epochs):\n",
    "        perm = np.random.permutation(len(X_train))\n",
    "        X_train_shuffled, y_train_shuffled = X_train[perm], y_train[perm]\n",
    "        epoch_loss, epoch_acc = 0, 0\n",
    "\n",
    "        for X_batch, y_batch in get_batch(X_train_shuffled, y_train_shuffled, config.batch_size):\n",
    "            pre_acts, acts, masks = forward_flexible(X_batch, params,\n",
    "                                                    activation=config.activation,\n",
    "                                                    dropout_rate=config.dropout_rate)\n",
    "            y_pred = acts[-1]\n",
    "            base_loss, dA = cross_entropy_loss(y_batch, y_pred)\n",
    "            l2_loss = (config.l2_lambda / (2 * len(X_batch))) * sum(np.sum(W**2) for W, _ in params)\n",
    "            total_loss = base_loss + l2_loss\n",
    "\n",
    "            grads = backward_flexible(X_batch, y_batch, params, pre_acts, acts, masks,\n",
    "                                      activation=config.activation, dA_last=dA, l2_lambda=config.l2_lambda)\n",
    "            params, opt_state = update_parameters_flexible(params, grads, config.learning_rate,\n",
    "                                                           optimizer=config.optimizer, opt_state=opt_state)\n",
    "\n",
    "            epoch_loss += total_loss\n",
    "            epoch_acc += accuracy(y_batch, y_pred)\n",
    "\n",
    "        epoch_loss /= len(X_train) // config.batch_size\n",
    "        epoch_acc /= len(X_train) // config.batch_size\n",
    "\n",
    "        _, val_acts, _ = forward_flexible(X_val, params, activation=config.activation, dropout_rate=0.0, train=False)\n",
    "        y_val_pred = val_acts[-1]\n",
    "        val_loss, _ = cross_entropy_loss(y_val, y_val_pred)\n",
    "        val_acc = accuracy(y_val, y_val_pred)\n",
    "\n",
    "        wandb.log({\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': epoch_loss,\n",
    "            'train_acc': epoch_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'l2_loss': l2_loss\n",
    "        })\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: train_loss={epoch_loss:.4f}, train_acc={epoch_acc:.4f}, val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")\n",
    "\n",
    "    for i, (W, b) in enumerate(params):\n",
    "        wandb.log({f'W_layer_{i+1}': wandb.Histogram(W)})\n",
    "        wandb.log({f'b_layer_{i+1}': wandb.Histogram(b)})\n",
    "\n",
    "    np.savez(\"final_params.npz\", **{f\"W{i}\": W for i, (W, b) in enumerate(params)},\n",
    "                               **{f\"b{i}\": b for i, (W, b) in enumerate(params)})\n",
    "    wandb.save(\"final_params.npy\")\n",
    "    wandb.finish()\n",
    "\n",
    "\n",
    "# Start sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"cifar10_project\")\n",
    "wandb.agent(sweep_id, function=wandb_train, count=30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
